{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SHREC_coarse_1D_lite_try.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0o7qmHmvVfV"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "from keras.optimizers import *\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.layers.core import *\n",
        "from keras.layers.convolutional import *\n",
        "from keras import backend as K\n",
        "import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRUfSxfEw4nJ"
      },
      "source": [
        "# Temple resizing function\n",
        "import numpy as np\n",
        "#mport os\n",
        "#import pandas as pd\n",
        "#import random\n",
        "import scipy.ndimage.interpolation as inter\n",
        "from scipy.signal import medfilt \n",
        "\n",
        "#import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# utils.py\n",
        "###################################################################################\n",
        "    \n",
        "    \n",
        "#Rescale to be 64 frames\n",
        "def zoom(p,target_l=64,joints_num=25,joints_dim=3):\n",
        "    l = p.shape[0]\n",
        "    p_new = np.empty([target_l,joints_num,joints_dim]) \n",
        "    for m in range(joints_num):\n",
        "        for n in range(joints_dim):\n",
        "            p[:,m,n] = medfilt(p[:,m,n],3)\n",
        "            p_new[:,m,n] = inter.zoom(p[:,m,n],target_l/l)[:target_l]         \n",
        "    return p_new\n",
        "\n",
        "def sampling_frame(p,C):\n",
        "    full_l = p.shape[0] # full length\n",
        "    if random.uniform(0,1)<0.5: # aligment sampling\n",
        "        valid_l = np.round(np.random.uniform(0.9,1)*full_l)\n",
        "        s = random.randint(0, full_l-int(valid_l))\n",
        "        e = s+valid_l # sample end point\n",
        "        p = p[int(s):int(e),:,:]    \n",
        "    else: # without aligment sampling\n",
        "        valid_l = np.round(np.random.uniform(0.9,1)*full_l)\n",
        "        index = np.sort(np.random.choice(range(0,full_l),int(valid_l),replace=False))\n",
        "        p = p[index,:,:]\n",
        "    p = zoom(p,C.frame_l,C.joint_n,C.joint_d)\n",
        "    return p\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "def get_CG(p,C):\n",
        "    M = []\n",
        "    iu = np.triu_indices(C.joint_n,1,C.joint_n)\n",
        "    for f in range(C.frame_l):\n",
        "        #distance max \n",
        "        d_m = cdist(p[f],np.concatenate([p[f],np.zeros([1,C.joint_d])]),'euclidean')       \n",
        "        d_m = d_m[iu] \n",
        "        M.append(d_m)\n",
        "    M = np.stack(M)   \n",
        "    return M\n",
        "\n",
        "def normlize_range(p):\n",
        "    # normolize to start point, use the center for hand case\n",
        "    p[:,:,0] = p[:,:,0]-np.mean(p[:,:,0])\n",
        "    p[:,:,1] = p[:,:,1]-np.mean(p[:,:,1])\n",
        "    p[:,:,2] = p[:,:,2]-np.mean(p[:,:,2])\n",
        "    return p\n",
        "\n",
        "def cm_analysis(y_true, y_pred, filename, labels, ymap=None, figsize=(8,8)):\n",
        "    \"\"\"\n",
        "    Generate matrix plot of confusion matrix with pretty annotations.\n",
        "    The plot image is saved to disk.\n",
        "    args: \n",
        "      y_true:    true label of the data, with shape (nsamples,)\n",
        "      y_pred:    prediction of the data, with shape (nsamples,)\n",
        "      filename:  filename of figure file to save\n",
        "      labels:    string array, name the order of class labels in the confusion matrix.\n",
        "                 use `clf.classes_` if using scikit-learn models.\n",
        "                 with shape (nclass,).\n",
        "      ymap:      dict: any -> string, length == nclass.\n",
        "                 if not None, map the labels & ys to more understandable strings.\n",
        "                 Caution: original y_true, y_pred and labels must align.\n",
        "      figsize:   the size of the figure plotted.\n",
        "    \"\"\"\n",
        "    if ymap is not None:\n",
        "        y_pred = [ymap[yi] for yi in y_pred]\n",
        "        y_true = [ymap[yi] for yi in y_true]\n",
        "        labels = [ymap[yi] for yi in labels]\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "    cm_perc = cm / cm_sum.astype(float) * 100\n",
        "    annot = np.empty_like(cm).astype(str)\n",
        "    nrows, ncols = cm.shape\n",
        "    for i in range(nrows):\n",
        "        for j in range(ncols):\n",
        "            c = cm[i, j]\n",
        "            p = cm_perc[i, j]\n",
        "            if i == j:\n",
        "                s = cm_sum[i]\n",
        "                #annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
        "                annot[i, j] = '%.1f' % (p)\n",
        "            elif c == 0:\n",
        "                annot[i, j] = ''\n",
        "            else:\n",
        "                #annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
        "                annot[i, j] = '%.1f' % (p)\n",
        "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "    cm.index.name = 'Actual'\n",
        "    cm.columns.name = 'Predicted'\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(cm, annot=annot, fmt='', ax=ax, cbar=False, cmap=\"YlGnBu\")\n",
        "    plt.savefig(filename)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LpToZqSxRNs"
      },
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--BRM1B4yFIy"
      },
      "source": [
        "\n",
        "random.seed(123)\n",
        "\n",
        "class Config():\n",
        "    def __init__(self):\n",
        "        self.frame_l = 32 # the length of frames\n",
        "        self.joint_n = 12 # the number of joints\n",
        "        self.joint_n = 22 # the number of joints\n",
        "        self.joint_d = 3 # the dimension of joints\n",
        "        self.clc_coarse = 14 # the number of coarse class\n",
        "        self.clc_fine = 28 # the number of fine-grained class\n",
        "        self.feat_d = 231\n",
        "        self.filters = 16 # ?? In the python notebook is 64, here is 16...\n",
        "        self.data_dir = '/content/SHREC'\n",
        "C = Config()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV1BcKY7yKlw"
      },
      "source": [
        "def poses_diff(x):\n",
        "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
        "    x = tf.subtract(x[:,1:,...],x[:,:-1,...]) #tensorflow method \n",
        "    x = tf.image.resize(x,size=[H,W]) \n",
        "    return x\n",
        "\n",
        "#calculate M_k_slow and M_k_fast\n",
        "def pose_motion(P,frame_l):\n",
        "    print(\"P type is:\")\n",
        "    print(type(P))\n",
        "    P_diff_slow = Lambda(lambda x: poses_diff(x))(P)\n",
        "    P_diff_slow = Reshape((frame_l,-1))(P_diff_slow)  #M_slow_[1,2,...,K - 1]\n",
        "    P_fast = Lambda(lambda x: x[:,::2,...])(P) # S_0, S_2, S_5 ,... is P 1D?\n",
        "    P_diff_fast = Lambda(lambda x: poses_diff(x))(P_fast)\n",
        "    P_diff_fast = Reshape((int(frame_l/2),-1))(P_diff_fast) #M_fast_[1,2,...,K/2 - 1]\n",
        "    return P_diff_slow,P_diff_fast\n",
        "    \n",
        "def c1D(x,filters,kernel):\n",
        "    x = Conv1D(filters, kernel_size=kernel,padding='same',use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    return x\n",
        "\n",
        "def block(x,filters):\n",
        "    x = c1D(x,filters,3)\n",
        "    x = c1D(x,filters,3)\n",
        "    return x\n",
        "    \n",
        "def d1D(x,filters):\n",
        "    x = Dense(filters,use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    return x\n",
        "\n",
        "def build_FM(frame_l=32,joint_n=22,joint_d=2,feat_d=231,filters=16):   \n",
        "    M = Input(shape=(frame_l,feat_d))\n",
        "    P = Input(shape=(frame_l,joint_n,joint_d))\n",
        "    \n",
        "    diff_slow,diff_fast = pose_motion(P,frame_l)\n",
        "    \n",
        "    # Modeling Joint Correlations by an Embedding\n",
        "    x = c1D(M,filters*2,1)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = c1D(x,filters,3)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = c1D(x,filters,1)\n",
        "    x = MaxPooling1D(2)(x)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "\n",
        "    x_d_slow = c1D(diff_slow,filters*2,1)\n",
        "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
        "    x_d_slow = c1D(x_d_slow,filters,3)\n",
        "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
        "    x_d_slow = c1D(x_d_slow,filters,1)\n",
        "    x_d_slow = MaxPool1D(2)(x_d_slow)\n",
        "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
        "        \n",
        "    x_d_fast = c1D(diff_fast,filters*2,1)\n",
        "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
        "    x_d_fast = c1D(x_d_fast,filters,3) \n",
        "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
        "    x_d_fast = c1D(x_d_fast,filters,1) \n",
        "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
        "   \n",
        "    x = concatenate([x,x_d_slow,x_d_fast])\n",
        "    x = block(x,filters*2)\n",
        "    x = MaxPool1D(2)(x)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    \n",
        "    x = block(x,filters*4)\n",
        "    x = MaxPool1D(2)(x)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "\n",
        "    x = block(x,filters*8)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    \n",
        "    return Model(inputs=[M,P],outputs=x)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yis-lhRAZq0X"
      },
      "source": [
        "def build_DD_Net(frame_l=32,joint_n=22,joint_d=3,feat_d=231,clc_num=14,filters=16):\n",
        "    M = Input(name='M', shape=(frame_l,feat_d))  \n",
        "    P = Input(name='P', shape=(frame_l,joint_n,joint_d)) \n",
        "    \n",
        "    FM = build_FM(frame_l,joint_n,joint_d,feat_d,filters)\n",
        "    \n",
        "    x = FM([M,P])\n",
        "\n",
        "    x = GlobalMaxPool1D()(x)\n",
        "    \n",
        "    x = d1D(x,128)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = d1D(x,128)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(clc_num, activation='softmax')(x)\n",
        "    \n",
        "    ######################Self-supervised part\n",
        "    model = Model(inputs=[M,P],outputs=x)\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rllCl_sHZwzz",
        "outputId": "ece0726e-d5c2-41f0-9b37-4c1c9337bf74"
      },
      "source": [
        "DD_Net = build_DD_Net(C.frame_l,C.joint_n,C.joint_d,C.feat_d,C.clc_coarse,C.filters)\n",
        "DD_Net.summary()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P type is:\n",
            "<class 'tensorflow.python.keras.engine.keras_tensor.KerasTensor'>\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "M (InputLayer)                  [(None, 32, 231)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "P (InputLayer)                  [(None, 32, 22, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model (Functional)              (None, 4, 128)       119392      M[0][0]                          \n",
            "                                                                 P[0][0]                          \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           model[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          16384       global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 128)          512         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, 128)          0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 128)          0           leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          16384       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 128)          512         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 128)          0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128)          0           leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 14)           1806        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 154,990\n",
            "Trainable params: 153,198\n",
            "Non-trainable params: 1,792\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzIu88krdjnR"
      },
      "source": [
        "\n",
        "Train = pickle.load(open(\"/content/sample_data/train.pkl\", \"rb\"))\n",
        "Test = pickle.load(open(\"/content/sample_data/test.pkl\", \"rb\"))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnY_tmNDdrIc",
        "outputId": "5f6929d7-fcd9-4550-f8e3-f124179d8ced"
      },
      "source": [
        "X_0 = []\n",
        "X_1 = []\n",
        "Y = []\n",
        "for i in tqdm(range(len(Train['pose']))): \n",
        "    p = np.copy(Train['pose'][i]).reshape([-1,22,3])\n",
        "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
        "    p = normlize_range(p)\n",
        "    \n",
        "    label = np.zeros(C.clc_coarse)\n",
        "    label[Train['coarse_label'][i]-1] = 1   \n",
        "\n",
        "    M = get_CG(p,C)\n",
        "\n",
        "    X_0.append(M)\n",
        "    X_1.append(p)\n",
        "    Y.append(label)\n",
        "\n",
        "X_0 = np.stack(X_0)  \n",
        "X_1 = np.stack(X_1) \n",
        "Y = np.stack(Y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1960/1960 [00:16<00:00, 120.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8EpSMN-d2Hj",
        "outputId": "4531bf83-9f5c-47a1-bdcc-5dec9281e0f2"
      },
      "source": [
        "X_test_0 = []\n",
        "X_test_1 = []\n",
        "Y_test = []\n",
        "for i in tqdm(range(len(Test['pose']))): \n",
        "    p = np.copy(Test['pose'][i]).reshape([-1,22,3])\n",
        "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
        "    p = normlize_range(p)\n",
        "    \n",
        "    label = np.zeros(C.clc_coarse)\n",
        "    label[Test['coarse_label'][i]-1] = 1   \n",
        "\n",
        "    M = get_CG(p,C)\n",
        "\n",
        "    X_test_0.append(M)\n",
        "    X_test_1.append(p)\n",
        "    Y_test.append(label)\n",
        "\n",
        "X_test_0 = np.stack(X_test_0) \n",
        "X_test_1 = np.stack(X_test_1)  \n",
        "Y_test = np.stack(Y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 840/840 [00:06<00:00, 121.72it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9rUOVUNd_WC",
        "outputId": "680d4cf2-7dd2-4ae8-c823-1dd24fc2b42c"
      },
      "source": [
        "lr = 1e-3\n",
        "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=keras.optimizers.Adam(lr),metrics=['accuracy'])\n",
        "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
        "history = DD_Net.fit([X_0,X_1],Y,\n",
        "                    batch_size=len(Y),\n",
        "                    epochs=600,\n",
        "                    verbose=True,\n",
        "                    shuffle=True,\n",
        "                    callbacks=[lrScheduler],\n",
        "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
        "                    )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.1261 - accuracy: 0.9679 - val_loss: 1.0709 - val_accuracy: 0.6690\n",
            "Epoch 2/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.1574 - accuracy: 0.9566 - val_loss: 1.2607 - val_accuracy: 0.6250\n",
            "Epoch 3/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1408 - accuracy: 0.9577 - val_loss: 1.4156 - val_accuracy: 0.5905\n",
            "Epoch 4/600\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.1409 - accuracy: 0.9602 - val_loss: 1.4450 - val_accuracy: 0.5952\n",
            "Epoch 5/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.1424 - accuracy: 0.9628 - val_loss: 1.3709 - val_accuracy: 0.6071\n",
            "Epoch 6/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.1475 - accuracy: 0.9566 - val_loss: 1.2580 - val_accuracy: 0.6274\n",
            "Epoch 7/600\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.1411 - accuracy: 0.9597 - val_loss: 1.2253 - val_accuracy: 0.6369\n",
            "Epoch 8/600\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.1464 - accuracy: 0.9612 - val_loss: 1.2046 - val_accuracy: 0.6464\n",
            "Epoch 9/600\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.1421 - accuracy: 0.9617 - val_loss: 1.1954 - val_accuracy: 0.6500\n",
            "Epoch 10/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1286 - accuracy: 0.9658 - val_loss: 1.1958 - val_accuracy: 0.6512\n",
            "Epoch 11/600\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.1151 - accuracy: 0.9709 - val_loss: 1.1910 - val_accuracy: 0.6512\n",
            "Epoch 12/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.1404 - accuracy: 0.9582 - val_loss: 1.1824 - val_accuracy: 0.6548\n",
            "Epoch 13/600\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.1247 - accuracy: 0.9653 - val_loss: 1.1616 - val_accuracy: 0.6583\n",
            "Epoch 14/600\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.1180 - accuracy: 0.9673 - val_loss: 1.1429 - val_accuracy: 0.6679\n",
            "Epoch 15/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.1267 - accuracy: 0.9679 - val_loss: 1.1202 - val_accuracy: 0.6714\n",
            "Epoch 16/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.1213 - accuracy: 0.9694 - val_loss: 1.0948 - val_accuracy: 0.6750\n",
            "Epoch 17/600\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.1126 - accuracy: 0.9689 - val_loss: 1.0771 - val_accuracy: 0.6798\n",
            "Epoch 18/600\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.1307 - accuracy: 0.9622 - val_loss: 1.0580 - val_accuracy: 0.6869\n",
            "Epoch 19/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1153 - accuracy: 0.9694 - val_loss: 1.0394 - val_accuracy: 0.6917\n",
            "Epoch 20/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.1181 - accuracy: 0.9628 - val_loss: 1.0234 - val_accuracy: 0.6976\n",
            "Epoch 21/600\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.1137 - accuracy: 0.9730 - val_loss: 1.0115 - val_accuracy: 0.7000\n",
            "Epoch 22/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.1190 - accuracy: 0.9658 - val_loss: 1.0004 - val_accuracy: 0.7048\n",
            "Epoch 23/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.1227 - accuracy: 0.9679 - val_loss: 0.9919 - val_accuracy: 0.7071\n",
            "Epoch 24/600\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.1057 - accuracy: 0.9719 - val_loss: 0.9898 - val_accuracy: 0.7048\n",
            "Epoch 25/600\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0955 - accuracy: 0.9770 - val_loss: 0.9858 - val_accuracy: 0.7060\n",
            "Epoch 26/600\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.1212 - accuracy: 0.9679 - val_loss: 0.9836 - val_accuracy: 0.7083\n",
            "Epoch 27/600\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.1148 - accuracy: 0.9694 - val_loss: 0.9827 - val_accuracy: 0.7095\n",
            "Epoch 28/600\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.1087 - accuracy: 0.9699 - val_loss: 0.9789 - val_accuracy: 0.7107\n",
            "Epoch 29/600\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.1073 - accuracy: 0.9719 - val_loss: 0.9748 - val_accuracy: 0.7167\n",
            "Epoch 30/600\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.1145 - accuracy: 0.9689 - val_loss: 0.9709 - val_accuracy: 0.7190\n",
            "Epoch 31/600\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.1019 - accuracy: 0.9755 - val_loss: 0.9642 - val_accuracy: 0.7179\n",
            "Epoch 32/600\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.1065 - accuracy: 0.9699 - val_loss: 0.9563 - val_accuracy: 0.7179\n",
            "Epoch 33/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.1059 - accuracy: 0.9689 - val_loss: 0.9491 - val_accuracy: 0.7262\n",
            "Epoch 34/600\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.1078 - accuracy: 0.9719 - val_loss: 0.9411 - val_accuracy: 0.7310\n",
            "Epoch 35/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.1166 - accuracy: 0.9730 - val_loss: 0.9325 - val_accuracy: 0.7333\n",
            "Epoch 36/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.1054 - accuracy: 0.9730 - val_loss: 0.9236 - val_accuracy: 0.7369\n",
            "Epoch 37/600\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.1036 - accuracy: 0.9709 - val_loss: 0.9130 - val_accuracy: 0.7417\n",
            "Epoch 38/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.1161 - accuracy: 0.9643 - val_loss: 0.9034 - val_accuracy: 0.7440\n",
            "Epoch 39/600\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.0980 - accuracy: 0.9709 - val_loss: 0.8912 - val_accuracy: 0.7452\n",
            "Epoch 40/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0985 - accuracy: 0.9724 - val_loss: 0.8814 - val_accuracy: 0.7464\n",
            "Epoch 41/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.1092 - accuracy: 0.9709 - val_loss: 0.8714 - val_accuracy: 0.7512\n",
            "Epoch 42/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0946 - accuracy: 0.9735 - val_loss: 0.8614 - val_accuracy: 0.7548\n",
            "Epoch 43/600\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.1159 - accuracy: 0.9668 - val_loss: 0.8514 - val_accuracy: 0.7560\n",
            "Epoch 44/600\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.0941 - accuracy: 0.9745 - val_loss: 0.8410 - val_accuracy: 0.7619\n",
            "Epoch 45/600\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.1078 - accuracy: 0.9689 - val_loss: 0.8303 - val_accuracy: 0.7702\n",
            "Epoch 46/600\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.1023 - accuracy: 0.9694 - val_loss: 0.8198 - val_accuracy: 0.7714\n",
            "Epoch 47/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1035 - accuracy: 0.9694 - val_loss: 0.8084 - val_accuracy: 0.7750\n",
            "Epoch 48/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.1088 - accuracy: 0.9673 - val_loss: 0.7977 - val_accuracy: 0.7750\n",
            "Epoch 49/600\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.1007 - accuracy: 0.9735 - val_loss: 0.7875 - val_accuracy: 0.7774\n",
            "Epoch 50/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1106 - accuracy: 0.9699 - val_loss: 0.7780 - val_accuracy: 0.7798\n",
            "Epoch 51/600\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.1043 - accuracy: 0.9714 - val_loss: 0.7682 - val_accuracy: 0.7786\n",
            "Epoch 52/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1083 - accuracy: 0.9689 - val_loss: 0.7586 - val_accuracy: 0.7821\n",
            "Epoch 53/600\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.1121 - accuracy: 0.9679 - val_loss: 0.7493 - val_accuracy: 0.7857\n",
            "Epoch 54/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.1136 - accuracy: 0.9679 - val_loss: 0.7398 - val_accuracy: 0.7869\n",
            "Epoch 55/600\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.1098 - accuracy: 0.9694 - val_loss: 0.7309 - val_accuracy: 0.7893\n",
            "Epoch 56/600\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.0876 - accuracy: 0.9765 - val_loss: 0.7218 - val_accuracy: 0.7929\n",
            "Epoch 57/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1022 - accuracy: 0.9724 - val_loss: 0.7130 - val_accuracy: 0.7976\n",
            "Epoch 58/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.1140 - accuracy: 0.9648 - val_loss: 0.7036 - val_accuracy: 0.7976\n",
            "Epoch 59/600\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.0987 - accuracy: 0.9709 - val_loss: 0.6947 - val_accuracy: 0.8000\n",
            "Epoch 60/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.1019 - accuracy: 0.9740 - val_loss: 0.6859 - val_accuracy: 0.8012\n",
            "Epoch 61/600\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.1005 - accuracy: 0.9714 - val_loss: 0.6774 - val_accuracy: 0.8024\n",
            "Epoch 62/600\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.1220 - accuracy: 0.9633 - val_loss: 0.6699 - val_accuracy: 0.8071\n",
            "Epoch 63/600\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.1123 - accuracy: 0.9704 - val_loss: 0.6626 - val_accuracy: 0.8095\n",
            "Epoch 64/600\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0947 - accuracy: 0.9745 - val_loss: 0.6556 - val_accuracy: 0.8119\n",
            "Epoch 65/600\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.1051 - accuracy: 0.9765 - val_loss: 0.6482 - val_accuracy: 0.8143\n",
            "Epoch 66/600\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.1099 - accuracy: 0.9673 - val_loss: 0.6411 - val_accuracy: 0.8155\n",
            "Epoch 67/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1260 - accuracy: 0.9648 - val_loss: 0.6338 - val_accuracy: 0.8155\n",
            "Epoch 68/600\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.1092 - accuracy: 0.9724 - val_loss: 0.6268 - val_accuracy: 0.8167\n",
            "Epoch 69/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.1035 - accuracy: 0.9776 - val_loss: 0.6201 - val_accuracy: 0.8179\n",
            "Epoch 70/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.1039 - accuracy: 0.9735 - val_loss: 0.6137 - val_accuracy: 0.8190\n",
            "Epoch 71/600\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.0975 - accuracy: 0.9745 - val_loss: 0.6073 - val_accuracy: 0.8226\n",
            "Epoch 72/600\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.0900 - accuracy: 0.9811 - val_loss: 0.6010 - val_accuracy: 0.8226\n",
            "Epoch 73/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.1139 - accuracy: 0.9684 - val_loss: 0.5948 - val_accuracy: 0.8262\n",
            "Epoch 74/600\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.1049 - accuracy: 0.9694 - val_loss: 0.5887 - val_accuracy: 0.8286\n",
            "Epoch 75/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.0999 - accuracy: 0.9694 - val_loss: 0.5827 - val_accuracy: 0.8298\n",
            "Epoch 76/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.0995 - accuracy: 0.9719 - val_loss: 0.5768 - val_accuracy: 0.8298\n",
            "Epoch 77/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.1062 - accuracy: 0.9694 - val_loss: 0.5709 - val_accuracy: 0.8310\n",
            "Epoch 78/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.1132 - accuracy: 0.9689 - val_loss: 0.5651 - val_accuracy: 0.8333\n",
            "Epoch 79/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1045 - accuracy: 0.9684 - val_loss: 0.5594 - val_accuracy: 0.8345\n",
            "Epoch 80/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.0957 - accuracy: 0.9765 - val_loss: 0.5537 - val_accuracy: 0.8357\n",
            "Epoch 81/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.0992 - accuracy: 0.9704 - val_loss: 0.5481 - val_accuracy: 0.8369\n",
            "Epoch 82/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0942 - accuracy: 0.9760 - val_loss: 0.5426 - val_accuracy: 0.8381\n",
            "Epoch 83/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.1225 - accuracy: 0.9643 - val_loss: 0.5373 - val_accuracy: 0.8393\n",
            "Epoch 84/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.1064 - accuracy: 0.9684 - val_loss: 0.5320 - val_accuracy: 0.8405\n",
            "Epoch 85/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0966 - accuracy: 0.9755 - val_loss: 0.5269 - val_accuracy: 0.8440\n",
            "Epoch 86/600\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.1023 - accuracy: 0.9730 - val_loss: 0.5216 - val_accuracy: 0.8440\n",
            "Epoch 87/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.0978 - accuracy: 0.9776 - val_loss: 0.5163 - val_accuracy: 0.8452\n",
            "Epoch 88/600\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.1031 - accuracy: 0.9730 - val_loss: 0.5113 - val_accuracy: 0.8488\n",
            "Epoch 89/600\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.1089 - accuracy: 0.9719 - val_loss: 0.5065 - val_accuracy: 0.8548\n",
            "Epoch 90/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.0931 - accuracy: 0.9719 - val_loss: 0.5016 - val_accuracy: 0.8560\n",
            "Epoch 91/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.1065 - accuracy: 0.9730 - val_loss: 0.4968 - val_accuracy: 0.8583\n",
            "Epoch 92/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.0995 - accuracy: 0.9724 - val_loss: 0.4922 - val_accuracy: 0.8595\n",
            "Epoch 93/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.0922 - accuracy: 0.9770 - val_loss: 0.4875 - val_accuracy: 0.8619\n",
            "Epoch 94/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.1035 - accuracy: 0.9724 - val_loss: 0.4829 - val_accuracy: 0.8631\n",
            "Epoch 95/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0994 - accuracy: 0.9719 - val_loss: 0.4783 - val_accuracy: 0.8643\n",
            "Epoch 96/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1147 - accuracy: 0.9679 - val_loss: 0.4737 - val_accuracy: 0.8667\n",
            "Epoch 97/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1092 - accuracy: 0.9679 - val_loss: 0.4690 - val_accuracy: 0.8690\n",
            "Epoch 98/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0969 - accuracy: 0.9755 - val_loss: 0.4646 - val_accuracy: 0.8690\n",
            "Epoch 99/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.1083 - accuracy: 0.9714 - val_loss: 0.4602 - val_accuracy: 0.8690\n",
            "Epoch 100/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.0934 - accuracy: 0.9750 - val_loss: 0.4559 - val_accuracy: 0.8702\n",
            "Epoch 101/600\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.0987 - accuracy: 0.9755 - val_loss: 0.4514 - val_accuracy: 0.8714\n",
            "Epoch 102/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.1010 - accuracy: 0.9724 - val_loss: 0.4471 - val_accuracy: 0.8714\n",
            "Epoch 103/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.1129 - accuracy: 0.9735 - val_loss: 0.4428 - val_accuracy: 0.8714\n",
            "Epoch 104/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.0942 - accuracy: 0.9776 - val_loss: 0.4386 - val_accuracy: 0.8714\n",
            "Epoch 105/600\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.0920 - accuracy: 0.9740 - val_loss: 0.4345 - val_accuracy: 0.8738\n",
            "Epoch 106/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.1181 - accuracy: 0.9653 - val_loss: 0.4304 - val_accuracy: 0.8738\n",
            "Epoch 107/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.0945 - accuracy: 0.9760 - val_loss: 0.4265 - val_accuracy: 0.8762\n",
            "Epoch 108/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1080 - accuracy: 0.9745 - val_loss: 0.4225 - val_accuracy: 0.8762\n",
            "Epoch 109/600\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.0997 - accuracy: 0.9694 - val_loss: 0.4186 - val_accuracy: 0.8762\n",
            "Epoch 110/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.1130 - accuracy: 0.9704 - val_loss: 0.4146 - val_accuracy: 0.8774\n",
            "Epoch 111/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.1147 - accuracy: 0.9658 - val_loss: 0.4108 - val_accuracy: 0.8774\n",
            "Epoch 112/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0998 - accuracy: 0.9730 - val_loss: 0.4071 - val_accuracy: 0.8786\n",
            "Epoch 113/600\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.0925 - accuracy: 0.9745 - val_loss: 0.4034 - val_accuracy: 0.8786\n",
            "Epoch 114/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.1076 - accuracy: 0.9689 - val_loss: 0.3998 - val_accuracy: 0.8786\n",
            "Epoch 115/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1026 - accuracy: 0.9719 - val_loss: 0.3962 - val_accuracy: 0.8798\n",
            "Epoch 116/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0937 - accuracy: 0.9791 - val_loss: 0.3927 - val_accuracy: 0.8810\n",
            "Epoch 117/600\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.0950 - accuracy: 0.9745 - val_loss: 0.3892 - val_accuracy: 0.8810\n",
            "Epoch 118/600\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.1033 - accuracy: 0.9765 - val_loss: 0.3858 - val_accuracy: 0.8810\n",
            "Epoch 119/600\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.0971 - accuracy: 0.9730 - val_loss: 0.3824 - val_accuracy: 0.8821\n",
            "Epoch 120/600\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.1099 - accuracy: 0.9730 - val_loss: 0.3791 - val_accuracy: 0.8833\n",
            "Epoch 121/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0905 - accuracy: 0.9750 - val_loss: 0.3758 - val_accuracy: 0.8833\n",
            "Epoch 122/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.1030 - accuracy: 0.9709 - val_loss: 0.3725 - val_accuracy: 0.8857\n",
            "Epoch 123/600\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.0990 - accuracy: 0.9755 - val_loss: 0.3693 - val_accuracy: 0.8881\n",
            "Epoch 124/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.0998 - accuracy: 0.9735 - val_loss: 0.3661 - val_accuracy: 0.8917\n",
            "Epoch 125/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.0913 - accuracy: 0.9765 - val_loss: 0.3629 - val_accuracy: 0.8940\n",
            "Epoch 126/600\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.0926 - accuracy: 0.9740 - val_loss: 0.3598 - val_accuracy: 0.8976\n",
            "Epoch 127/600\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.1106 - accuracy: 0.9694 - val_loss: 0.3568 - val_accuracy: 0.8988\n",
            "Epoch 128/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.1020 - accuracy: 0.9719 - val_loss: 0.3537 - val_accuracy: 0.9012\n",
            "Epoch 129/600\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0953 - accuracy: 0.9735 - val_loss: 0.3508 - val_accuracy: 0.9012\n",
            "Epoch 130/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.1119 - accuracy: 0.9694 - val_loss: 0.3478 - val_accuracy: 0.9012\n",
            "Epoch 131/600\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.1034 - accuracy: 0.9694 - val_loss: 0.3448 - val_accuracy: 0.9012\n",
            "Epoch 132/600\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.1009 - accuracy: 0.9699 - val_loss: 0.3419 - val_accuracy: 0.9024\n",
            "Epoch 133/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.0962 - accuracy: 0.9709 - val_loss: 0.3390 - val_accuracy: 0.9036\n",
            "Epoch 134/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.1057 - accuracy: 0.9730 - val_loss: 0.3362 - val_accuracy: 0.9036\n",
            "Epoch 135/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1011 - accuracy: 0.9740 - val_loss: 0.3333 - val_accuracy: 0.9071\n",
            "Epoch 136/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.1071 - accuracy: 0.9704 - val_loss: 0.3306 - val_accuracy: 0.9071\n",
            "Epoch 137/600\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.0806 - accuracy: 0.9806 - val_loss: 0.3279 - val_accuracy: 0.9083\n",
            "Epoch 138/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.0904 - accuracy: 0.9765 - val_loss: 0.3252 - val_accuracy: 0.9095\n",
            "Epoch 139/600\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.0993 - accuracy: 0.9730 - val_loss: 0.3227 - val_accuracy: 0.9107\n",
            "Epoch 140/600\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.1031 - accuracy: 0.9709 - val_loss: 0.3200 - val_accuracy: 0.9107\n",
            "Epoch 141/600\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.0979 - accuracy: 0.9745 - val_loss: 0.3175 - val_accuracy: 0.9107\n",
            "Epoch 142/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.0920 - accuracy: 0.9755 - val_loss: 0.3150 - val_accuracy: 0.9107\n",
            "Epoch 143/600\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.0955 - accuracy: 0.9714 - val_loss: 0.3126 - val_accuracy: 0.9107\n",
            "Epoch 144/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.1101 - accuracy: 0.9673 - val_loss: 0.3103 - val_accuracy: 0.9107\n",
            "Epoch 145/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.0935 - accuracy: 0.9730 - val_loss: 0.3080 - val_accuracy: 0.9131\n",
            "Epoch 146/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.0986 - accuracy: 0.9740 - val_loss: 0.3056 - val_accuracy: 0.9131\n",
            "Epoch 147/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0903 - accuracy: 0.9770 - val_loss: 0.3034 - val_accuracy: 0.9143\n",
            "Epoch 148/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0948 - accuracy: 0.9745 - val_loss: 0.3011 - val_accuracy: 0.9143\n",
            "Epoch 149/600\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.0946 - accuracy: 0.9781 - val_loss: 0.2989 - val_accuracy: 0.9155\n",
            "Epoch 150/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.1019 - accuracy: 0.9791 - val_loss: 0.2967 - val_accuracy: 0.9155\n",
            "Epoch 151/600\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.0927 - accuracy: 0.9755 - val_loss: 0.2946 - val_accuracy: 0.9167\n",
            "Epoch 152/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.1231 - accuracy: 0.9684 - val_loss: 0.2923 - val_accuracy: 0.9167\n",
            "Epoch 153/600\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.1120 - accuracy: 0.9699 - val_loss: 0.2901 - val_accuracy: 0.9190\n",
            "Epoch 154/600\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.1036 - accuracy: 0.9724 - val_loss: 0.2881 - val_accuracy: 0.9190\n",
            "Epoch 155/600\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.1064 - accuracy: 0.9730 - val_loss: 0.2859 - val_accuracy: 0.9214\n",
            "Epoch 156/600\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.1026 - accuracy: 0.9765 - val_loss: 0.2838 - val_accuracy: 0.9226\n",
            "Epoch 157/600\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.0983 - accuracy: 0.9745 - val_loss: 0.2817 - val_accuracy: 0.9226\n",
            "Epoch 158/600\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.0960 - accuracy: 0.9745 - val_loss: 0.2797 - val_accuracy: 0.9226\n",
            "Epoch 159/600\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.0927 - accuracy: 0.9750 - val_loss: 0.2777 - val_accuracy: 0.9226\n",
            "Epoch 160/600\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.0973 - accuracy: 0.9770 - val_loss: 0.2758 - val_accuracy: 0.9238\n",
            "Epoch 161/600\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.0967 - accuracy: 0.9745 - val_loss: 0.2738 - val_accuracy: 0.9238\n",
            "Epoch 162/600\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.1025 - accuracy: 0.9724 - val_loss: 0.2719 - val_accuracy: 0.9250\n",
            "Epoch 163/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.1024 - accuracy: 0.9765 - val_loss: 0.2701 - val_accuracy: 0.9262\n",
            "Epoch 164/600\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.0922 - accuracy: 0.9760 - val_loss: 0.2682 - val_accuracy: 0.9262\n",
            "Epoch 165/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.1061 - accuracy: 0.9760 - val_loss: 0.2664 - val_accuracy: 0.9262\n",
            "Epoch 166/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.1003 - accuracy: 0.9714 - val_loss: 0.2647 - val_accuracy: 0.9262\n",
            "Epoch 167/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.1132 - accuracy: 0.9658 - val_loss: 0.2629 - val_accuracy: 0.9250\n",
            "Epoch 168/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0985 - accuracy: 0.9781 - val_loss: 0.2612 - val_accuracy: 0.9250\n",
            "Epoch 169/600\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.1011 - accuracy: 0.9730 - val_loss: 0.2594 - val_accuracy: 0.9262\n",
            "Epoch 170/600\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.1062 - accuracy: 0.9699 - val_loss: 0.2578 - val_accuracy: 0.9286\n",
            "Epoch 171/600\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.0939 - accuracy: 0.9719 - val_loss: 0.2562 - val_accuracy: 0.9286\n",
            "Epoch 172/600\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.1027 - accuracy: 0.9750 - val_loss: 0.2546 - val_accuracy: 0.9286\n",
            "Epoch 173/600\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.0975 - accuracy: 0.9684 - val_loss: 0.2530 - val_accuracy: 0.9298\n",
            "Epoch 174/600\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.1007 - accuracy: 0.9760 - val_loss: 0.2515 - val_accuracy: 0.9298\n",
            "Epoch 175/600\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.0955 - accuracy: 0.9719 - val_loss: 0.2501 - val_accuracy: 0.9298\n",
            "Epoch 176/600\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.1076 - accuracy: 0.9724 - val_loss: 0.2486 - val_accuracy: 0.9298\n",
            "Epoch 177/600\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.0937 - accuracy: 0.9740 - val_loss: 0.2472 - val_accuracy: 0.9298\n",
            "Epoch 178/600\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.0963 - accuracy: 0.9714 - val_loss: 0.2458 - val_accuracy: 0.9298\n",
            "Epoch 179/600\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.0913 - accuracy: 0.9750 - val_loss: 0.2444 - val_accuracy: 0.9298\n",
            "Epoch 180/600\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.1075 - accuracy: 0.9709 - val_loss: 0.2430 - val_accuracy: 0.9298\n",
            "Epoch 181/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1170 - accuracy: 0.9689 - val_loss: 0.2417 - val_accuracy: 0.9286\n",
            "Epoch 182/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1068 - accuracy: 0.9684 - val_loss: 0.2403 - val_accuracy: 0.9286\n",
            "Epoch 183/600\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.0964 - accuracy: 0.9796 - val_loss: 0.2391 - val_accuracy: 0.9286\n",
            "Epoch 184/600\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0980 - accuracy: 0.9735 - val_loss: 0.2378 - val_accuracy: 0.9286\n",
            "Epoch 185/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.1077 - accuracy: 0.9719 - val_loss: 0.2365 - val_accuracy: 0.9286\n",
            "Epoch 186/600\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.0998 - accuracy: 0.9745 - val_loss: 0.2352 - val_accuracy: 0.9298\n",
            "Epoch 187/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.1051 - accuracy: 0.9714 - val_loss: 0.2340 - val_accuracy: 0.9298\n",
            "Epoch 188/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.0918 - accuracy: 0.9796 - val_loss: 0.2327 - val_accuracy: 0.9298\n",
            "Epoch 189/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.1051 - accuracy: 0.9699 - val_loss: 0.2316 - val_accuracy: 0.9310\n",
            "Epoch 190/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.0953 - accuracy: 0.9735 - val_loss: 0.2304 - val_accuracy: 0.9310\n",
            "Epoch 191/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.1101 - accuracy: 0.9689 - val_loss: 0.2293 - val_accuracy: 0.9310\n",
            "Epoch 192/600\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.0981 - accuracy: 0.9740 - val_loss: 0.2282 - val_accuracy: 0.9310\n",
            "Epoch 193/600\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.1002 - accuracy: 0.9740 - val_loss: 0.2271 - val_accuracy: 0.9321\n",
            "Epoch 194/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.0869 - accuracy: 0.9781 - val_loss: 0.2261 - val_accuracy: 0.9321\n",
            "Epoch 195/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.1088 - accuracy: 0.9704 - val_loss: 0.2250 - val_accuracy: 0.9321\n",
            "Epoch 196/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.0932 - accuracy: 0.9760 - val_loss: 0.2239 - val_accuracy: 0.9321\n",
            "Epoch 197/600\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.1104 - accuracy: 0.9684 - val_loss: 0.2229 - val_accuracy: 0.9333\n",
            "Epoch 198/600\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.1005 - accuracy: 0.9719 - val_loss: 0.2219 - val_accuracy: 0.9333\n",
            "Epoch 199/600\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.0935 - accuracy: 0.9760 - val_loss: 0.2208 - val_accuracy: 0.9333\n",
            "Epoch 200/600\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.0947 - accuracy: 0.9760 - val_loss: 0.2198 - val_accuracy: 0.9333\n",
            "Epoch 201/600\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.1094 - accuracy: 0.9689 - val_loss: 0.2188 - val_accuracy: 0.9345\n",
            "Epoch 202/600\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.1088 - accuracy: 0.9719 - val_loss: 0.2179 - val_accuracy: 0.9345\n",
            "Epoch 203/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0926 - accuracy: 0.9745 - val_loss: 0.2170 - val_accuracy: 0.9357\n",
            "Epoch 204/600\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.1068 - accuracy: 0.9730 - val_loss: 0.2161 - val_accuracy: 0.9357\n",
            "Epoch 205/600\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.1042 - accuracy: 0.9740 - val_loss: 0.2152 - val_accuracy: 0.9369\n",
            "Epoch 206/600\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.0952 - accuracy: 0.9730 - val_loss: 0.2143 - val_accuracy: 0.9369\n",
            "Epoch 207/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.1069 - accuracy: 0.9740 - val_loss: 0.2134 - val_accuracy: 0.9369\n",
            "Epoch 208/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.1160 - accuracy: 0.9663 - val_loss: 0.2125 - val_accuracy: 0.9369\n",
            "Epoch 209/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.0972 - accuracy: 0.9755 - val_loss: 0.2116 - val_accuracy: 0.9393\n",
            "Epoch 210/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.0880 - accuracy: 0.9750 - val_loss: 0.2108 - val_accuracy: 0.9393\n",
            "Epoch 211/600\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.1145 - accuracy: 0.9719 - val_loss: 0.2099 - val_accuracy: 0.9393\n",
            "Epoch 212/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.0938 - accuracy: 0.9745 - val_loss: 0.2090 - val_accuracy: 0.9405\n",
            "Epoch 213/600\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.1111 - accuracy: 0.9704 - val_loss: 0.2082 - val_accuracy: 0.9405\n",
            "Epoch 214/600\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.1039 - accuracy: 0.9699 - val_loss: 0.2074 - val_accuracy: 0.9417\n",
            "Epoch 215/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.0954 - accuracy: 0.9740 - val_loss: 0.2066 - val_accuracy: 0.9440\n",
            "Epoch 216/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.1025 - accuracy: 0.9714 - val_loss: 0.2057 - val_accuracy: 0.9440\n",
            "Epoch 217/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.1124 - accuracy: 0.9709 - val_loss: 0.2050 - val_accuracy: 0.9440\n",
            "Epoch 218/600\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.1001 - accuracy: 0.9745 - val_loss: 0.2042 - val_accuracy: 0.9440\n",
            "Epoch 219/600\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.1014 - accuracy: 0.9755 - val_loss: 0.2035 - val_accuracy: 0.9440\n",
            "Epoch 220/600\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.0968 - accuracy: 0.9724 - val_loss: 0.2028 - val_accuracy: 0.9440\n",
            "Epoch 221/600\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.1104 - accuracy: 0.9658 - val_loss: 0.2021 - val_accuracy: 0.9440\n",
            "Epoch 222/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.1018 - accuracy: 0.9735 - val_loss: 0.2015 - val_accuracy: 0.9440\n",
            "Epoch 223/600\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.0901 - accuracy: 0.9740 - val_loss: 0.2008 - val_accuracy: 0.9440\n",
            "Epoch 224/600\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.0947 - accuracy: 0.9755 - val_loss: 0.2002 - val_accuracy: 0.9440\n",
            "Epoch 225/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.1152 - accuracy: 0.9658 - val_loss: 0.1996 - val_accuracy: 0.9440\n",
            "Epoch 226/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.0900 - accuracy: 0.9730 - val_loss: 0.1990 - val_accuracy: 0.9452\n",
            "Epoch 227/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0960 - accuracy: 0.9724 - val_loss: 0.1984 - val_accuracy: 0.9452\n",
            "Epoch 228/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.0948 - accuracy: 0.9704 - val_loss: 0.1979 - val_accuracy: 0.9452\n",
            "Epoch 229/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.1151 - accuracy: 0.9694 - val_loss: 0.1974 - val_accuracy: 0.9464\n",
            "Epoch 230/600\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.1005 - accuracy: 0.9709 - val_loss: 0.1968 - val_accuracy: 0.9464\n",
            "Epoch 231/600\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.1016 - accuracy: 0.9735 - val_loss: 0.1964 - val_accuracy: 0.9464\n",
            "Epoch 232/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.0984 - accuracy: 0.9760 - val_loss: 0.1958 - val_accuracy: 0.9464\n",
            "Epoch 233/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.1045 - accuracy: 0.9689 - val_loss: 0.1953 - val_accuracy: 0.9464\n",
            "Epoch 234/600\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.1020 - accuracy: 0.9704 - val_loss: 0.1948 - val_accuracy: 0.9464\n",
            "Epoch 235/600\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.1032 - accuracy: 0.9714 - val_loss: 0.1943 - val_accuracy: 0.9464\n",
            "Epoch 236/600\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.1044 - accuracy: 0.9673 - val_loss: 0.1938 - val_accuracy: 0.9452\n",
            "Epoch 237/600\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.0985 - accuracy: 0.9719 - val_loss: 0.1933 - val_accuracy: 0.9452\n",
            "Epoch 238/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.0969 - accuracy: 0.9730 - val_loss: 0.1928 - val_accuracy: 0.9464\n",
            "Epoch 239/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.0980 - accuracy: 0.9704 - val_loss: 0.1923 - val_accuracy: 0.9464\n",
            "Epoch 240/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.1091 - accuracy: 0.9730 - val_loss: 0.1919 - val_accuracy: 0.9464\n",
            "Epoch 241/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.0933 - accuracy: 0.9740 - val_loss: 0.1914 - val_accuracy: 0.9476\n",
            "Epoch 242/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.1134 - accuracy: 0.9673 - val_loss: 0.1910 - val_accuracy: 0.9476\n",
            "Epoch 243/600\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0913 - accuracy: 0.9709 - val_loss: 0.1906 - val_accuracy: 0.9476\n",
            "Epoch 244/600\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.0971 - accuracy: 0.9765 - val_loss: 0.1902 - val_accuracy: 0.9476\n",
            "Epoch 245/600\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.0998 - accuracy: 0.9760 - val_loss: 0.1898 - val_accuracy: 0.9488\n",
            "Epoch 246/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.0873 - accuracy: 0.9760 - val_loss: 0.1894 - val_accuracy: 0.9488\n",
            "Epoch 247/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.0998 - accuracy: 0.9730 - val_loss: 0.1890 - val_accuracy: 0.9488\n",
            "Epoch 248/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0939 - accuracy: 0.9714 - val_loss: 0.1886 - val_accuracy: 0.9476\n",
            "Epoch 249/600\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.0883 - accuracy: 0.9791 - val_loss: 0.1882 - val_accuracy: 0.9476\n",
            "Epoch 250/600\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.1146 - accuracy: 0.9673 - val_loss: 0.1878 - val_accuracy: 0.9476\n",
            "Epoch 251/600\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.0859 - accuracy: 0.9786 - val_loss: 0.1874 - val_accuracy: 0.9476\n",
            "Epoch 252/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.1034 - accuracy: 0.9709 - val_loss: 0.1871 - val_accuracy: 0.9488\n",
            "Epoch 253/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.1154 - accuracy: 0.9684 - val_loss: 0.1867 - val_accuracy: 0.9488\n",
            "Epoch 254/600\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.1006 - accuracy: 0.9740 - val_loss: 0.1864 - val_accuracy: 0.9488\n",
            "Epoch 255/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.1044 - accuracy: 0.9724 - val_loss: 0.1860 - val_accuracy: 0.9488\n",
            "Epoch 256/600\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.0993 - accuracy: 0.9694 - val_loss: 0.1857 - val_accuracy: 0.9488\n",
            "Epoch 257/600\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.0917 - accuracy: 0.9745 - val_loss: 0.1854 - val_accuracy: 0.9488\n",
            "Epoch 258/600\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.0876 - accuracy: 0.9781 - val_loss: 0.1851 - val_accuracy: 0.9488\n",
            "Epoch 259/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.1070 - accuracy: 0.9719 - val_loss: 0.1849 - val_accuracy: 0.9488\n",
            "Epoch 260/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0985 - accuracy: 0.9704 - val_loss: 0.1846 - val_accuracy: 0.9488\n",
            "Epoch 261/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.1090 - accuracy: 0.9709 - val_loss: 0.1843 - val_accuracy: 0.9488\n",
            "Epoch 262/600\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.1054 - accuracy: 0.9730 - val_loss: 0.1841 - val_accuracy: 0.9488\n",
            "Epoch 263/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.0963 - accuracy: 0.9770 - val_loss: 0.1838 - val_accuracy: 0.9488\n",
            "Epoch 264/600\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.0941 - accuracy: 0.9765 - val_loss: 0.1835 - val_accuracy: 0.9488\n",
            "Epoch 265/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.0928 - accuracy: 0.9760 - val_loss: 0.1833 - val_accuracy: 0.9488\n",
            "Epoch 266/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.0900 - accuracy: 0.9765 - val_loss: 0.1830 - val_accuracy: 0.9500\n",
            "Epoch 267/600\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.1005 - accuracy: 0.9704 - val_loss: 0.1828 - val_accuracy: 0.9500\n",
            "Epoch 268/600\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.1080 - accuracy: 0.9689 - val_loss: 0.1826 - val_accuracy: 0.9500\n",
            "Epoch 269/600\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.1077 - accuracy: 0.9699 - val_loss: 0.1823 - val_accuracy: 0.9500\n",
            "Epoch 270/600\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0939 - accuracy: 0.9781 - val_loss: 0.1821 - val_accuracy: 0.9512\n",
            "Epoch 271/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.1061 - accuracy: 0.9719 - val_loss: 0.1819 - val_accuracy: 0.9512\n",
            "Epoch 272/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.1069 - accuracy: 0.9704 - val_loss: 0.1817 - val_accuracy: 0.9512\n",
            "Epoch 273/600\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.1134 - accuracy: 0.9724 - val_loss: 0.1814 - val_accuracy: 0.9512\n",
            "Epoch 274/600\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.1116 - accuracy: 0.9724 - val_loss: 0.1812 - val_accuracy: 0.9512\n",
            "Epoch 275/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.0903 - accuracy: 0.9765 - val_loss: 0.1810 - val_accuracy: 0.9512\n",
            "Epoch 276/600\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.1048 - accuracy: 0.9709 - val_loss: 0.1807 - val_accuracy: 0.9512\n",
            "Epoch 277/600\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.0948 - accuracy: 0.9765 - val_loss: 0.1806 - val_accuracy: 0.9512\n",
            "Epoch 278/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.0896 - accuracy: 0.9740 - val_loss: 0.1804 - val_accuracy: 0.9512\n",
            "Epoch 279/600\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.1051 - accuracy: 0.9724 - val_loss: 0.1802 - val_accuracy: 0.9512\n",
            "Epoch 280/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.1015 - accuracy: 0.9750 - val_loss: 0.1800 - val_accuracy: 0.9512\n",
            "Epoch 281/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.1005 - accuracy: 0.9694 - val_loss: 0.1798 - val_accuracy: 0.9512\n",
            "Epoch 282/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0938 - accuracy: 0.9755 - val_loss: 0.1797 - val_accuracy: 0.9512\n",
            "Epoch 283/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1037 - accuracy: 0.9724 - val_loss: 0.1795 - val_accuracy: 0.9512\n",
            "Epoch 284/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.1022 - accuracy: 0.9699 - val_loss: 0.1793 - val_accuracy: 0.9512\n",
            "Epoch 285/600\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.1058 - accuracy: 0.9714 - val_loss: 0.1792 - val_accuracy: 0.9500\n",
            "Epoch 286/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.0920 - accuracy: 0.9776 - val_loss: 0.1790 - val_accuracy: 0.9500\n",
            "Epoch 287/600\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.0876 - accuracy: 0.9791 - val_loss: 0.1788 - val_accuracy: 0.9500\n",
            "Epoch 288/600\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.0930 - accuracy: 0.9740 - val_loss: 0.1787 - val_accuracy: 0.9500\n",
            "Epoch 289/600\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.1027 - accuracy: 0.9709 - val_loss: 0.1785 - val_accuracy: 0.9500\n",
            "Epoch 290/600\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.0930 - accuracy: 0.9786 - val_loss: 0.1784 - val_accuracy: 0.9500\n",
            "Epoch 291/600\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0943 - accuracy: 0.9786 - val_loss: 0.1783 - val_accuracy: 0.9500\n",
            "Epoch 292/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.0972 - accuracy: 0.9806 - val_loss: 0.1781 - val_accuracy: 0.9500\n",
            "Epoch 293/600\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.1006 - accuracy: 0.9730 - val_loss: 0.1780 - val_accuracy: 0.9500\n",
            "Epoch 294/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.0955 - accuracy: 0.9709 - val_loss: 0.1779 - val_accuracy: 0.9500\n",
            "Epoch 295/600\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.0989 - accuracy: 0.9724 - val_loss: 0.1778 - val_accuracy: 0.9500\n",
            "Epoch 296/600\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.1029 - accuracy: 0.9689 - val_loss: 0.1777 - val_accuracy: 0.9500\n",
            "Epoch 297/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.1007 - accuracy: 0.9735 - val_loss: 0.1776 - val_accuracy: 0.9500\n",
            "Epoch 298/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.0956 - accuracy: 0.9755 - val_loss: 0.1775 - val_accuracy: 0.9488\n",
            "Epoch 299/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.0924 - accuracy: 0.9740 - val_loss: 0.1774 - val_accuracy: 0.9488\n",
            "Epoch 300/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0980 - accuracy: 0.9750 - val_loss: 0.1773 - val_accuracy: 0.9488\n",
            "Epoch 301/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1003 - accuracy: 0.9735 - val_loss: 0.1772 - val_accuracy: 0.9488\n",
            "Epoch 302/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.1142 - accuracy: 0.9704 - val_loss: 0.1771 - val_accuracy: 0.9488\n",
            "Epoch 303/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.1028 - accuracy: 0.9709 - val_loss: 0.1770 - val_accuracy: 0.9488\n",
            "Epoch 304/600\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.0874 - accuracy: 0.9776 - val_loss: 0.1769 - val_accuracy: 0.9476\n",
            "Epoch 305/600\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.1131 - accuracy: 0.9673 - val_loss: 0.1768 - val_accuracy: 0.9476\n",
            "Epoch 306/600\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.0880 - accuracy: 0.9791 - val_loss: 0.1767 - val_accuracy: 0.9476\n",
            "Epoch 307/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.1017 - accuracy: 0.9724 - val_loss: 0.1767 - val_accuracy: 0.9476\n",
            "Epoch 308/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0990 - accuracy: 0.9704 - val_loss: 0.1766 - val_accuracy: 0.9476\n",
            "Epoch 309/600\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.0958 - accuracy: 0.9730 - val_loss: 0.1765 - val_accuracy: 0.9476\n",
            "Epoch 310/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.1000 - accuracy: 0.9765 - val_loss: 0.1764 - val_accuracy: 0.9476\n",
            "Epoch 311/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0987 - accuracy: 0.9755 - val_loss: 0.1764 - val_accuracy: 0.9488\n",
            "Epoch 312/600\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.0982 - accuracy: 0.9776 - val_loss: 0.1763 - val_accuracy: 0.9488\n",
            "Epoch 313/600\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.0841 - accuracy: 0.9786 - val_loss: 0.1763 - val_accuracy: 0.9488\n",
            "Epoch 314/600\n",
            "1/1 [==============================] - 1s 999ms/step - loss: 0.0953 - accuracy: 0.9745 - val_loss: 0.1762 - val_accuracy: 0.9488\n",
            "Epoch 315/600\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.0923 - accuracy: 0.9745 - val_loss: 0.1762 - val_accuracy: 0.9488\n",
            "Epoch 316/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.1003 - accuracy: 0.9714 - val_loss: 0.1761 - val_accuracy: 0.9500\n",
            "Epoch 317/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.0958 - accuracy: 0.9760 - val_loss: 0.1761 - val_accuracy: 0.9500\n",
            "Epoch 318/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.0887 - accuracy: 0.9765 - val_loss: 0.1760 - val_accuracy: 0.9500\n",
            "Epoch 319/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.0917 - accuracy: 0.9781 - val_loss: 0.1760 - val_accuracy: 0.9500\n",
            "Epoch 320/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.1000 - accuracy: 0.9724 - val_loss: 0.1760 - val_accuracy: 0.9488\n",
            "Epoch 321/600\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0977 - accuracy: 0.9745 - val_loss: 0.1759 - val_accuracy: 0.9488\n",
            "Epoch 322/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.1032 - accuracy: 0.9755 - val_loss: 0.1759 - val_accuracy: 0.9488\n",
            "Epoch 323/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.0867 - accuracy: 0.9781 - val_loss: 0.1759 - val_accuracy: 0.9488\n",
            "Epoch 324/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.0996 - accuracy: 0.9709 - val_loss: 0.1759 - val_accuracy: 0.9488\n",
            "Epoch 325/600\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.1182 - accuracy: 0.9653 - val_loss: 0.1758 - val_accuracy: 0.9488\n",
            "Epoch 326/600\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.0924 - accuracy: 0.9765 - val_loss: 0.1758 - val_accuracy: 0.9488\n",
            "Epoch 327/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.1109 - accuracy: 0.9668 - val_loss: 0.1758 - val_accuracy: 0.9476\n",
            "Epoch 328/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1099 - accuracy: 0.9724 - val_loss: 0.1758 - val_accuracy: 0.9476\n",
            "Epoch 329/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.1014 - accuracy: 0.9679 - val_loss: 0.1758 - val_accuracy: 0.9476\n",
            "Epoch 330/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.0956 - accuracy: 0.9740 - val_loss: 0.1758 - val_accuracy: 0.9476\n",
            "Epoch 331/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.0915 - accuracy: 0.9740 - val_loss: 0.1757 - val_accuracy: 0.9476\n",
            "Epoch 332/600\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.1008 - accuracy: 0.9689 - val_loss: 0.1757 - val_accuracy: 0.9476\n",
            "Epoch 333/600\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.0899 - accuracy: 0.9776 - val_loss: 0.1757 - val_accuracy: 0.9476\n",
            "Epoch 334/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.0919 - accuracy: 0.9750 - val_loss: 0.1756 - val_accuracy: 0.9476\n",
            "Epoch 335/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1050 - accuracy: 0.9689 - val_loss: 0.1756 - val_accuracy: 0.9476\n",
            "Epoch 336/600\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.0940 - accuracy: 0.9735 - val_loss: 0.1755 - val_accuracy: 0.9476\n",
            "Epoch 337/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.1004 - accuracy: 0.9730 - val_loss: 0.1755 - val_accuracy: 0.9476\n",
            "Epoch 338/600\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.0978 - accuracy: 0.9740 - val_loss: 0.1755 - val_accuracy: 0.9476\n",
            "Epoch 339/600\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.1078 - accuracy: 0.9653 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
            "Epoch 340/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.1053 - accuracy: 0.9735 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
            "Epoch 341/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.1060 - accuracy: 0.9714 - val_loss: 0.1753 - val_accuracy: 0.9476\n",
            "Epoch 342/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.1120 - accuracy: 0.9699 - val_loss: 0.1753 - val_accuracy: 0.9476\n",
            "Epoch 343/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.0959 - accuracy: 0.9750 - val_loss: 0.1753 - val_accuracy: 0.9476\n",
            "Epoch 344/600\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.0978 - accuracy: 0.9770 - val_loss: 0.1753 - val_accuracy: 0.9476\n",
            "Epoch 345/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.1119 - accuracy: 0.9679 - val_loss: 0.1753 - val_accuracy: 0.9476\n",
            "Epoch 346/600\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.0946 - accuracy: 0.9735 - val_loss: 0.1752 - val_accuracy: 0.9476\n",
            "Epoch 347/600\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.0830 - accuracy: 0.9791 - val_loss: 0.1752 - val_accuracy: 0.9476\n",
            "Epoch 348/600\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.1073 - accuracy: 0.9709 - val_loss: 0.1752 - val_accuracy: 0.9476\n",
            "Epoch 349/600\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1006 - accuracy: 0.9740 - val_loss: 0.1752 - val_accuracy: 0.9476\n",
            "Epoch 350/600\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0873 - accuracy: 0.9735 - val_loss: 0.1751 - val_accuracy: 0.9476\n",
            "Epoch 351/600\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1156 - accuracy: 0.9719 - val_loss: 0.1751 - val_accuracy: 0.9476\n",
            "Epoch 352/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.1019 - accuracy: 0.9724 - val_loss: 0.1751 - val_accuracy: 0.9476\n",
            "Epoch 353/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.1010 - accuracy: 0.9724 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 354/600\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.1069 - accuracy: 0.9689 - val_loss: 0.1750 - val_accuracy: 0.9464\n",
            "Epoch 355/600\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.0903 - accuracy: 0.9745 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 356/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.1029 - accuracy: 0.9724 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 357/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.0950 - accuracy: 0.9714 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 358/600\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.1103 - accuracy: 0.9709 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 359/600\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.0928 - accuracy: 0.9735 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 360/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.0960 - accuracy: 0.9750 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 361/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.1026 - accuracy: 0.9735 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 362/600\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.1075 - accuracy: 0.9709 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 363/600\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.0974 - accuracy: 0.9750 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 364/600\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.0965 - accuracy: 0.9730 - val_loss: 0.1749 - val_accuracy: 0.9476\n",
            "Epoch 365/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0943 - accuracy: 0.9770 - val_loss: 0.1749 - val_accuracy: 0.9476\n",
            "Epoch 366/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.0864 - accuracy: 0.9796 - val_loss: 0.1749 - val_accuracy: 0.9476\n",
            "Epoch 367/600\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.0893 - accuracy: 0.9740 - val_loss: 0.1749 - val_accuracy: 0.9476\n",
            "Epoch 368/600\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.1097 - accuracy: 0.9679 - val_loss: 0.1749 - val_accuracy: 0.9476\n",
            "Epoch 369/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.1013 - accuracy: 0.9724 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
            "Epoch 370/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0952 - accuracy: 0.9765 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
            "Epoch 371/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.1010 - accuracy: 0.9740 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
            "Epoch 372/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1036 - accuracy: 0.9709 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
            "Epoch 373/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.1006 - accuracy: 0.9684 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
            "Epoch 374/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.0977 - accuracy: 0.9714 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
            "Epoch 375/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0888 - accuracy: 0.9791 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
            "Epoch 376/600\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.1101 - accuracy: 0.9663 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
            "Epoch 377/600\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0887 - accuracy: 0.9740 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
            "Epoch 378/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0965 - accuracy: 0.9765 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
            "Epoch 379/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.1032 - accuracy: 0.9719 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
            "Epoch 380/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.1036 - accuracy: 0.9699 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
            "Epoch 381/600\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.0996 - accuracy: 0.9709 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
            "Epoch 382/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.0989 - accuracy: 0.9750 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
            "Epoch 383/600\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.1093 - accuracy: 0.9689 - val_loss: 0.1749 - val_accuracy: 0.9476\n",
            "Epoch 384/600\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.0985 - accuracy: 0.9740 - val_loss: 0.1749 - val_accuracy: 0.9476\n",
            "Epoch 385/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0985 - accuracy: 0.9709 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 386/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.0972 - accuracy: 0.9776 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 387/600\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.0937 - accuracy: 0.9724 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 388/600\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.1033 - accuracy: 0.9740 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 389/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.1069 - accuracy: 0.9704 - val_loss: 0.1751 - val_accuracy: 0.9476\n",
            "Epoch 390/600\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.1021 - accuracy: 0.9714 - val_loss: 0.1751 - val_accuracy: 0.9476\n",
            "Epoch 391/600\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.0993 - accuracy: 0.9760 - val_loss: 0.1751 - val_accuracy: 0.9476\n",
            "Epoch 392/600\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.1063 - accuracy: 0.9704 - val_loss: 0.1752 - val_accuracy: 0.9476\n",
            "Epoch 393/600\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.0930 - accuracy: 0.9770 - val_loss: 0.1752 - val_accuracy: 0.9476\n",
            "Epoch 394/600\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.1014 - accuracy: 0.9694 - val_loss: 0.1753 - val_accuracy: 0.9476\n",
            "Epoch 395/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0909 - accuracy: 0.9755 - val_loss: 0.1753 - val_accuracy: 0.9476\n",
            "Epoch 396/600\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.0999 - accuracy: 0.9719 - val_loss: 0.1753 - val_accuracy: 0.9476\n",
            "Epoch 397/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.1025 - accuracy: 0.9684 - val_loss: 0.1753 - val_accuracy: 0.9476\n",
            "Epoch 398/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.0891 - accuracy: 0.9765 - val_loss: 0.1753 - val_accuracy: 0.9476\n",
            "Epoch 399/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.1037 - accuracy: 0.9709 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
            "Epoch 400/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.0989 - accuracy: 0.9740 - val_loss: 0.1753 - val_accuracy: 0.9476\n",
            "Epoch 401/600\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.0903 - accuracy: 0.9770 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
            "Epoch 402/600\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.0920 - accuracy: 0.9755 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
            "Epoch 403/600\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.1005 - accuracy: 0.9704 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
            "Epoch 404/600\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.0921 - accuracy: 0.9730 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
            "Epoch 405/600\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.1023 - accuracy: 0.9735 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
            "Epoch 406/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.0963 - accuracy: 0.9776 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
            "Epoch 407/600\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.1048 - accuracy: 0.9719 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
            "Epoch 408/600\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.0946 - accuracy: 0.9760 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
            "Epoch 409/600\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.0974 - accuracy: 0.9750 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
            "Epoch 410/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0925 - accuracy: 0.9745 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
            "Epoch 411/600\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.0830 - accuracy: 0.9755 - val_loss: 0.1754 - val_accuracy: 0.9476\n",
            "Epoch 412/600\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.0877 - accuracy: 0.9740 - val_loss: 0.1754 - val_accuracy: 0.9488\n",
            "Epoch 413/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1034 - accuracy: 0.9730 - val_loss: 0.1754 - val_accuracy: 0.9488\n",
            "Epoch 414/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.1065 - accuracy: 0.9699 - val_loss: 0.1755 - val_accuracy: 0.9488\n",
            "Epoch 415/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0950 - accuracy: 0.9770 - val_loss: 0.1755 - val_accuracy: 0.9488\n",
            "Epoch 416/600\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.0874 - accuracy: 0.9801 - val_loss: 0.1755 - val_accuracy: 0.9488\n",
            "Epoch 417/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1095 - accuracy: 0.9689 - val_loss: 0.1755 - val_accuracy: 0.9488\n",
            "Epoch 418/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1048 - accuracy: 0.9719 - val_loss: 0.1755 - val_accuracy: 0.9488\n",
            "Epoch 419/600\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.1037 - accuracy: 0.9694 - val_loss: 0.1756 - val_accuracy: 0.9488\n",
            "Epoch 420/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.0954 - accuracy: 0.9735 - val_loss: 0.1756 - val_accuracy: 0.9488\n",
            "Epoch 421/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.0949 - accuracy: 0.9730 - val_loss: 0.1757 - val_accuracy: 0.9488\n",
            "Epoch 422/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.0852 - accuracy: 0.9760 - val_loss: 0.1757 - val_accuracy: 0.9488\n",
            "Epoch 423/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0942 - accuracy: 0.9755 - val_loss: 0.1757 - val_accuracy: 0.9488\n",
            "Epoch 424/600\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.0844 - accuracy: 0.9796 - val_loss: 0.1758 - val_accuracy: 0.9488\n",
            "Epoch 425/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.1015 - accuracy: 0.9755 - val_loss: 0.1758 - val_accuracy: 0.9488\n",
            "Epoch 426/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.0988 - accuracy: 0.9765 - val_loss: 0.1758 - val_accuracy: 0.9488\n",
            "Epoch 427/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.0916 - accuracy: 0.9714 - val_loss: 0.1758 - val_accuracy: 0.9488\n",
            "Epoch 428/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0981 - accuracy: 0.9745 - val_loss: 0.1759 - val_accuracy: 0.9488\n",
            "Epoch 429/600\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.0900 - accuracy: 0.9791 - val_loss: 0.1759 - val_accuracy: 0.9488\n",
            "Epoch 430/600\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.1038 - accuracy: 0.9704 - val_loss: 0.1760 - val_accuracy: 0.9488\n",
            "Epoch 431/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.1055 - accuracy: 0.9679 - val_loss: 0.1760 - val_accuracy: 0.9488\n",
            "Epoch 432/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.0897 - accuracy: 0.9786 - val_loss: 0.1760 - val_accuracy: 0.9488\n",
            "Epoch 433/600\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.0949 - accuracy: 0.9745 - val_loss: 0.1761 - val_accuracy: 0.9488\n",
            "Epoch 434/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.1012 - accuracy: 0.9689 - val_loss: 0.1761 - val_accuracy: 0.9488\n",
            "Epoch 435/600\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.1193 - accuracy: 0.9622 - val_loss: 0.1762 - val_accuracy: 0.9488\n",
            "Epoch 436/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.1048 - accuracy: 0.9740 - val_loss: 0.1762 - val_accuracy: 0.9488\n",
            "Epoch 437/600\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.1013 - accuracy: 0.9694 - val_loss: 0.1762 - val_accuracy: 0.9488\n",
            "Epoch 438/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0883 - accuracy: 0.9796 - val_loss: 0.1763 - val_accuracy: 0.9488\n",
            "Epoch 439/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.0980 - accuracy: 0.9704 - val_loss: 0.1763 - val_accuracy: 0.9488\n",
            "Epoch 440/600\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.0957 - accuracy: 0.9755 - val_loss: 0.1764 - val_accuracy: 0.9488\n",
            "Epoch 441/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1042 - accuracy: 0.9760 - val_loss: 0.1764 - val_accuracy: 0.9488\n",
            "Epoch 442/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.1000 - accuracy: 0.9740 - val_loss: 0.1764 - val_accuracy: 0.9488\n",
            "Epoch 443/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.0938 - accuracy: 0.9755 - val_loss: 0.1765 - val_accuracy: 0.9488\n",
            "Epoch 444/600\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.0971 - accuracy: 0.9714 - val_loss: 0.1765 - val_accuracy: 0.9488\n",
            "Epoch 445/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.1030 - accuracy: 0.9714 - val_loss: 0.1765 - val_accuracy: 0.9488\n",
            "Epoch 446/600\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.0921 - accuracy: 0.9796 - val_loss: 0.1765 - val_accuracy: 0.9488\n",
            "Epoch 447/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.1060 - accuracy: 0.9673 - val_loss: 0.1766 - val_accuracy: 0.9488\n",
            "Epoch 448/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.1023 - accuracy: 0.9704 - val_loss: 0.1766 - val_accuracy: 0.9488\n",
            "Epoch 449/600\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.0994 - accuracy: 0.9719 - val_loss: 0.1766 - val_accuracy: 0.9488\n",
            "Epoch 450/600\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.0907 - accuracy: 0.9735 - val_loss: 0.1766 - val_accuracy: 0.9488\n",
            "Epoch 451/600\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.1043 - accuracy: 0.9724 - val_loss: 0.1767 - val_accuracy: 0.9488\n",
            "Epoch 452/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0907 - accuracy: 0.9740 - val_loss: 0.1767 - val_accuracy: 0.9488\n",
            "Epoch 453/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.0895 - accuracy: 0.9765 - val_loss: 0.1768 - val_accuracy: 0.9476\n",
            "Epoch 454/600\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.0842 - accuracy: 0.9781 - val_loss: 0.1768 - val_accuracy: 0.9476\n",
            "Epoch 455/600\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.0970 - accuracy: 0.9765 - val_loss: 0.1768 - val_accuracy: 0.9476\n",
            "Epoch 456/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1009 - accuracy: 0.9770 - val_loss: 0.1768 - val_accuracy: 0.9476\n",
            "Epoch 457/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.0876 - accuracy: 0.9765 - val_loss: 0.1768 - val_accuracy: 0.9488\n",
            "Epoch 458/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.1005 - accuracy: 0.9719 - val_loss: 0.1768 - val_accuracy: 0.9488\n",
            "Epoch 459/600\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.1020 - accuracy: 0.9730 - val_loss: 0.1769 - val_accuracy: 0.9488\n",
            "Epoch 460/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0963 - accuracy: 0.9745 - val_loss: 0.1769 - val_accuracy: 0.9488\n",
            "Epoch 461/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.0973 - accuracy: 0.9724 - val_loss: 0.1770 - val_accuracy: 0.9488\n",
            "Epoch 462/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.0951 - accuracy: 0.9755 - val_loss: 0.1770 - val_accuracy: 0.9488\n",
            "Epoch 463/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.0918 - accuracy: 0.9765 - val_loss: 0.1770 - val_accuracy: 0.9500\n",
            "Epoch 464/600\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.0974 - accuracy: 0.9704 - val_loss: 0.1770 - val_accuracy: 0.9500\n",
            "Epoch 465/600\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.0912 - accuracy: 0.9730 - val_loss: 0.1770 - val_accuracy: 0.9500\n",
            "Epoch 466/600\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.0984 - accuracy: 0.9765 - val_loss: 0.1770 - val_accuracy: 0.9500\n",
            "Epoch 467/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1058 - accuracy: 0.9714 - val_loss: 0.1770 - val_accuracy: 0.9500\n",
            "Epoch 468/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.0922 - accuracy: 0.9724 - val_loss: 0.1770 - val_accuracy: 0.9500\n",
            "Epoch 469/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.1016 - accuracy: 0.9709 - val_loss: 0.1770 - val_accuracy: 0.9500\n",
            "Epoch 470/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.0891 - accuracy: 0.9770 - val_loss: 0.1770 - val_accuracy: 0.9500\n",
            "Epoch 471/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.1051 - accuracy: 0.9724 - val_loss: 0.1770 - val_accuracy: 0.9500\n",
            "Epoch 472/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.0840 - accuracy: 0.9811 - val_loss: 0.1770 - val_accuracy: 0.9500\n",
            "Epoch 473/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.0813 - accuracy: 0.9811 - val_loss: 0.1771 - val_accuracy: 0.9500\n",
            "Epoch 474/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.0897 - accuracy: 0.9781 - val_loss: 0.1771 - val_accuracy: 0.9500\n",
            "Epoch 475/600\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.1040 - accuracy: 0.9709 - val_loss: 0.1772 - val_accuracy: 0.9500\n",
            "Epoch 476/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.0807 - accuracy: 0.9832 - val_loss: 0.1772 - val_accuracy: 0.9500\n",
            "Epoch 477/600\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.0986 - accuracy: 0.9735 - val_loss: 0.1772 - val_accuracy: 0.9500\n",
            "Epoch 478/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.1003 - accuracy: 0.9745 - val_loss: 0.1773 - val_accuracy: 0.9500\n",
            "Epoch 479/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0859 - accuracy: 0.9745 - val_loss: 0.1773 - val_accuracy: 0.9500\n",
            "Epoch 480/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1078 - accuracy: 0.9704 - val_loss: 0.1774 - val_accuracy: 0.9500\n",
            "Epoch 481/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.0941 - accuracy: 0.9730 - val_loss: 0.1774 - val_accuracy: 0.9500\n",
            "Epoch 482/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.1015 - accuracy: 0.9714 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 483/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.0921 - accuracy: 0.9770 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 484/600\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.0980 - accuracy: 0.9760 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 485/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0915 - accuracy: 0.9750 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 486/600\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.0882 - accuracy: 0.9770 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 487/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.0934 - accuracy: 0.9740 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 488/600\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.1013 - accuracy: 0.9730 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 489/600\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.1009 - accuracy: 0.9714 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 490/600\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.0938 - accuracy: 0.9770 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 491/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.0910 - accuracy: 0.9745 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 492/600\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.1004 - accuracy: 0.9719 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 493/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.1007 - accuracy: 0.9730 - val_loss: 0.1776 - val_accuracy: 0.9500\n",
            "Epoch 494/600\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.0864 - accuracy: 0.9796 - val_loss: 0.1775 - val_accuracy: 0.9512\n",
            "Epoch 495/600\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.0932 - accuracy: 0.9755 - val_loss: 0.1775 - val_accuracy: 0.9512\n",
            "Epoch 496/600\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.0960 - accuracy: 0.9770 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 497/600\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.1026 - accuracy: 0.9699 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 498/600\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.1076 - accuracy: 0.9709 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 499/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0989 - accuracy: 0.9699 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 500/600\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.0971 - accuracy: 0.9709 - val_loss: 0.1776 - val_accuracy: 0.9500\n",
            "Epoch 501/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.1016 - accuracy: 0.9745 - val_loss: 0.1776 - val_accuracy: 0.9500\n",
            "Epoch 502/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.0838 - accuracy: 0.9781 - val_loss: 0.1776 - val_accuracy: 0.9500\n",
            "Epoch 503/600\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.0990 - accuracy: 0.9699 - val_loss: 0.1776 - val_accuracy: 0.9500\n",
            "Epoch 504/600\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.1017 - accuracy: 0.9740 - val_loss: 0.1777 - val_accuracy: 0.9500\n",
            "Epoch 505/600\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.0867 - accuracy: 0.9740 - val_loss: 0.1777 - val_accuracy: 0.9500\n",
            "Epoch 506/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0822 - accuracy: 0.9765 - val_loss: 0.1777 - val_accuracy: 0.9500\n",
            "Epoch 507/600\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.0886 - accuracy: 0.9755 - val_loss: 0.1778 - val_accuracy: 0.9500\n",
            "Epoch 508/600\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.0944 - accuracy: 0.9750 - val_loss: 0.1778 - val_accuracy: 0.9500\n",
            "Epoch 509/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0983 - accuracy: 0.9730 - val_loss: 0.1779 - val_accuracy: 0.9500\n",
            "Epoch 510/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.1103 - accuracy: 0.9699 - val_loss: 0.1780 - val_accuracy: 0.9500\n",
            "Epoch 511/600\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.1048 - accuracy: 0.9689 - val_loss: 0.1780 - val_accuracy: 0.9500\n",
            "Epoch 512/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.0930 - accuracy: 0.9755 - val_loss: 0.1780 - val_accuracy: 0.9500\n",
            "Epoch 513/600\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.0866 - accuracy: 0.9791 - val_loss: 0.1781 - val_accuracy: 0.9500\n",
            "Epoch 514/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.1010 - accuracy: 0.9745 - val_loss: 0.1781 - val_accuracy: 0.9500\n",
            "Epoch 515/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.0891 - accuracy: 0.9791 - val_loss: 0.1781 - val_accuracy: 0.9500\n",
            "Epoch 516/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.0989 - accuracy: 0.9745 - val_loss: 0.1781 - val_accuracy: 0.9500\n",
            "Epoch 517/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.1013 - accuracy: 0.9735 - val_loss: 0.1782 - val_accuracy: 0.9500\n",
            "Epoch 518/600\n",
            "1/1 [==============================] - 1s 995ms/step - loss: 0.0891 - accuracy: 0.9745 - val_loss: 0.1782 - val_accuracy: 0.9500\n",
            "Epoch 519/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.1040 - accuracy: 0.9735 - val_loss: 0.1782 - val_accuracy: 0.9500\n",
            "Epoch 520/600\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.0918 - accuracy: 0.9745 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 521/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.0973 - accuracy: 0.9709 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 522/600\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.1037 - accuracy: 0.9724 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 523/600\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.1122 - accuracy: 0.9709 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 524/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.1026 - accuracy: 0.9709 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 525/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.1040 - accuracy: 0.9673 - val_loss: 0.1784 - val_accuracy: 0.9488\n",
            "Epoch 526/600\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.1120 - accuracy: 0.9714 - val_loss: 0.1784 - val_accuracy: 0.9488\n",
            "Epoch 527/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0982 - accuracy: 0.9714 - val_loss: 0.1784 - val_accuracy: 0.9488\n",
            "Epoch 528/600\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.0956 - accuracy: 0.9719 - val_loss: 0.1784 - val_accuracy: 0.9488\n",
            "Epoch 529/600\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.1011 - accuracy: 0.9709 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 530/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.1076 - accuracy: 0.9719 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 531/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.0963 - accuracy: 0.9719 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 532/600\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.1057 - accuracy: 0.9714 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 533/600\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.1083 - accuracy: 0.9679 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 534/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1067 - accuracy: 0.9673 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 535/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0962 - accuracy: 0.9776 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 536/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.0889 - accuracy: 0.9781 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 537/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0933 - accuracy: 0.9745 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 538/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0964 - accuracy: 0.9673 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 539/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.0950 - accuracy: 0.9745 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 540/600\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.0850 - accuracy: 0.9791 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 541/600\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.0943 - accuracy: 0.9770 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 542/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.1054 - accuracy: 0.9709 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 543/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0906 - accuracy: 0.9765 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 544/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.0909 - accuracy: 0.9770 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 545/600\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.1078 - accuracy: 0.9684 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 546/600\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.0892 - accuracy: 0.9760 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 547/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.0885 - accuracy: 0.9776 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 548/600\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.0926 - accuracy: 0.9791 - val_loss: 0.1786 - val_accuracy: 0.9488\n",
            "Epoch 549/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.0943 - accuracy: 0.9740 - val_loss: 0.1786 - val_accuracy: 0.9488\n",
            "Epoch 550/600\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.1099 - accuracy: 0.9735 - val_loss: 0.1786 - val_accuracy: 0.9488\n",
            "Epoch 551/600\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.0995 - accuracy: 0.9730 - val_loss: 0.1786 - val_accuracy: 0.9488\n",
            "Epoch 552/600\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.1009 - accuracy: 0.9755 - val_loss: 0.1787 - val_accuracy: 0.9488\n",
            "Epoch 553/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0865 - accuracy: 0.9781 - val_loss: 0.1787 - val_accuracy: 0.9488\n",
            "Epoch 554/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0974 - accuracy: 0.9765 - val_loss: 0.1787 - val_accuracy: 0.9500\n",
            "Epoch 555/600\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.1068 - accuracy: 0.9704 - val_loss: 0.1787 - val_accuracy: 0.9500\n",
            "Epoch 556/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.0901 - accuracy: 0.9770 - val_loss: 0.1787 - val_accuracy: 0.9488\n",
            "Epoch 557/600\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.1012 - accuracy: 0.9776 - val_loss: 0.1787 - val_accuracy: 0.9488\n",
            "Epoch 558/600\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0908 - accuracy: 0.9750 - val_loss: 0.1787 - val_accuracy: 0.9488\n",
            "Epoch 559/600\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.1057 - accuracy: 0.9694 - val_loss: 0.1787 - val_accuracy: 0.9488\n",
            "Epoch 560/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.0960 - accuracy: 0.9724 - val_loss: 0.1787 - val_accuracy: 0.9488\n",
            "Epoch 561/600\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.1063 - accuracy: 0.9735 - val_loss: 0.1787 - val_accuracy: 0.9488\n",
            "Epoch 562/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0942 - accuracy: 0.9745 - val_loss: 0.1786 - val_accuracy: 0.9488\n",
            "Epoch 563/600\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.1064 - accuracy: 0.9684 - val_loss: 0.1786 - val_accuracy: 0.9488\n",
            "Epoch 564/600\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.0885 - accuracy: 0.9781 - val_loss: 0.1786 - val_accuracy: 0.9488\n",
            "Epoch 565/600\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.1069 - accuracy: 0.9709 - val_loss: 0.1786 - val_accuracy: 0.9488\n",
            "Epoch 566/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.1008 - accuracy: 0.9714 - val_loss: 0.1786 - val_accuracy: 0.9488\n",
            "Epoch 567/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0978 - accuracy: 0.9714 - val_loss: 0.1786 - val_accuracy: 0.9488\n",
            "Epoch 568/600\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.1022 - accuracy: 0.9714 - val_loss: 0.1786 - val_accuracy: 0.9488\n",
            "Epoch 569/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.0943 - accuracy: 0.9745 - val_loss: 0.1786 - val_accuracy: 0.9488\n",
            "Epoch 570/600\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.1020 - accuracy: 0.9714 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 571/600\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.1023 - accuracy: 0.9755 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 572/600\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.1109 - accuracy: 0.9704 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 573/600\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.0946 - accuracy: 0.9765 - val_loss: 0.1785 - val_accuracy: 0.9488\n",
            "Epoch 574/600\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.0894 - accuracy: 0.9750 - val_loss: 0.1784 - val_accuracy: 0.9488\n",
            "Epoch 575/600\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0896 - accuracy: 0.9760 - val_loss: 0.1784 - val_accuracy: 0.9488\n",
            "Epoch 576/600\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.0891 - accuracy: 0.9724 - val_loss: 0.1784 - val_accuracy: 0.9488\n",
            "Epoch 577/600\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.0929 - accuracy: 0.9724 - val_loss: 0.1784 - val_accuracy: 0.9488\n",
            "Epoch 578/600\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.1037 - accuracy: 0.9704 - val_loss: 0.1784 - val_accuracy: 0.9488\n",
            "Epoch 579/600\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.1005 - accuracy: 0.9714 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 580/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.0991 - accuracy: 0.9709 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 581/600\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.0929 - accuracy: 0.9740 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 582/600\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.0912 - accuracy: 0.9750 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 583/600\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.0964 - accuracy: 0.9730 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 584/600\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.1091 - accuracy: 0.9684 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 585/600\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.0987 - accuracy: 0.9704 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 586/600\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0981 - accuracy: 0.9719 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 587/600\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.0885 - accuracy: 0.9781 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 588/600\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.1060 - accuracy: 0.9694 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 589/600\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.0842 - accuracy: 0.9770 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 590/600\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.0905 - accuracy: 0.9765 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 591/600\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.0919 - accuracy: 0.9755 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 592/600\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.0863 - accuracy: 0.9776 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 593/600\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.0977 - accuracy: 0.9724 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 594/600\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.1031 - accuracy: 0.9745 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 595/600\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.0968 - accuracy: 0.9760 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 596/600\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.1013 - accuracy: 0.9760 - val_loss: 0.1783 - val_accuracy: 0.9488\n",
            "Epoch 597/600\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1077 - accuracy: 0.9714 - val_loss: 0.1784 - val_accuracy: 0.9488\n",
            "Epoch 598/600\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.0846 - accuracy: 0.9765 - val_loss: 0.1784 - val_accuracy: 0.9488\n",
            "Epoch 599/600\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.1023 - accuracy: 0.9740 - val_loss: 0.1783 - val_accuracy: 0.9500\n",
            "Epoch 600/600\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.0903 - accuracy: 0.9730 - val_loss: 0.1783 - val_accuracy: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ZMaN39njeAmT",
        "outputId": "a4a76006-e8df-4fa1-dacb-c515372ba499"
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}