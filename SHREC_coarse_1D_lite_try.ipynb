{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "v0o7qmHmvVfV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from keras.optimizers import *\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.convolutional import *\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fRUfSxfEw4nJ"
   },
   "outputs": [],
   "source": [
    "# Temple resizing function\n",
    "import numpy as np\n",
    "#mport os\n",
    "#import pandas as pd\n",
    "#import random\n",
    "import scipy.ndimage.interpolation as inter\n",
    "from scipy.signal import medfilt \n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# utils.py\n",
    "###################################################################################\n",
    "    \n",
    "    \n",
    "#Rescale to be 64 frames\n",
    "def zoom(p,target_l=64,joints_num=25,joints_dim=3):\n",
    "    l = p.shape[0]\n",
    "    p_new = np.empty([target_l,joints_num,joints_dim]) \n",
    "    for m in range(joints_num):\n",
    "        for n in range(joints_dim):\n",
    "            p[:,m,n] = medfilt(p[:,m,n],3)\n",
    "            p_new[:,m,n] = inter.zoom(p[:,m,n],target_l/l)[:target_l]         \n",
    "    return p_new\n",
    "\n",
    "def sampling_frame(p,C):\n",
    "    full_l = p.shape[0] # full length\n",
    "    if random.uniform(0,1)<0.5: # aligment sampling\n",
    "        valid_l = np.round(np.random.uniform(0.9,1)*full_l)\n",
    "        s = random.randint(0, full_l-int(valid_l))\n",
    "        e = s+valid_l # sample end point\n",
    "        p = p[int(s):int(e),:,:]    \n",
    "    else: # without aligment sampling\n",
    "        valid_l = np.round(np.random.uniform(0.9,1)*full_l)\n",
    "        index = np.sort(np.random.choice(range(0,full_l),int(valid_l),replace=False))\n",
    "        p = p[index,:,:]\n",
    "    p = zoom(p,C.frame_l,C.joint_n,C.joint_d)\n",
    "    return p\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "def get_CG(p,C):\n",
    "    M = []\n",
    "    iu = np.triu_indices(C.joint_n,1,C.joint_n)\n",
    "    for f in range(C.frame_l):\n",
    "        #distance max \n",
    "        d_m = cdist(p[f],np.concatenate([p[f],np.zeros([1,C.joint_d])]),'euclidean')       \n",
    "        d_m = d_m[iu] \n",
    "        M.append(d_m)\n",
    "    M = np.stack(M)   \n",
    "    return M\n",
    "\n",
    "def normlize_range(p):\n",
    "    # normolize to start point, use the center for hand case\n",
    "    p[:,:,0] = p[:,:,0]-np.mean(p[:,:,0])\n",
    "    p[:,:,1] = p[:,:,1]-np.mean(p[:,:,1])\n",
    "    p[:,:,2] = p[:,:,2]-np.mean(p[:,:,2])\n",
    "    return p\n",
    "\n",
    "def cm_analysis(y_true, y_pred, filename, labels, ymap=None, figsize=(8,8)):\n",
    "    \"\"\"\n",
    "    Generate matrix plot of confusion matrix with pretty annotations.\n",
    "    The plot image is saved to disk.\n",
    "    args: \n",
    "      y_true:    true label of the data, with shape (nsamples,)\n",
    "      y_pred:    prediction of the data, with shape (nsamples,)\n",
    "      filename:  filename of figure file to save\n",
    "      labels:    string array, name the order of class labels in the confusion matrix.\n",
    "                 use `clf.classes_` if using scikit-learn models.\n",
    "                 with shape (nclass,).\n",
    "      ymap:      dict: any -> string, length == nclass.\n",
    "                 if not None, map the labels & ys to more understandable strings.\n",
    "                 Caution: original y_true, y_pred and labels must align.\n",
    "      figsize:   the size of the figure plotted.\n",
    "    \"\"\"\n",
    "    if ymap is not None:\n",
    "        y_pred = [ymap[yi] for yi in y_pred]\n",
    "        y_true = [ymap[yi] for yi in y_true]\n",
    "        labels = [ymap[yi] for yi in labels]\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                #annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "                annot[i, j] = '%.1f' % (p)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                #annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "                annot[i, j] = '%.1f' % (p)\n",
    "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, annot=annot, fmt='', ax=ax, cbar=False, cmap=\"YlGnBu\")\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8LpToZqSxRNs"
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "--BRM1B4yFIy"
   },
   "outputs": [],
   "source": [
    "\n",
    "random.seed(123)\n",
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.frame_l = 32 # the length of frames\n",
    "        self.joint_n = 12 # the number of joints\n",
    "        self.joint_n = 22 # the number of joints\n",
    "        self.joint_d = 3 # the dimension of joints\n",
    "        self.clc_coarse = 14 # the number of coarse class\n",
    "        self.clc_fine = 28 # the number of fine-grained class\n",
    "        self.feat_d = 231\n",
    "        self.filters = 16 # ?? In the python notebook is 64, here is 16...\n",
    "        self.data_dir = '/content/SHREC'\n",
    "C = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PV1BcKY7yKlw"
   },
   "outputs": [],
   "source": [
    "def poses_diff(x):\n",
    "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
    "    x = tf.subtract(x[:,1:,...],x[:,:-1,...]) #tensorflow method \n",
    "    x = tf.image.resize(x,size=[H,W]) \n",
    "    return x\n",
    "\n",
    "#calculate M_k_slow and M_k_fast\n",
    "def pose_motion(P,frame_l):\n",
    "    print(\"P type is:\")\n",
    "    print(type(P))\n",
    "    P_diff_slow = Lambda(lambda x: poses_diff(x))(P)\n",
    "    P_diff_slow = Reshape((frame_l,-1))(P_diff_slow)  #M_slow_[1,2,...,K - 1]\n",
    "    P_fast = Lambda(lambda x: x[:,::2,...])(P) # S_0, S_2, S_5 ,... is P 1D?\n",
    "    P_diff_fast = Lambda(lambda x: poses_diff(x))(P_fast)\n",
    "    P_diff_fast = Reshape((int(frame_l/2),-1))(P_diff_fast) #M_fast_[1,2,...,K/2 - 1]\n",
    "    return P_diff_slow,P_diff_fast\n",
    "    \n",
    "def c1D(x,filters,kernel):\n",
    "    x = Conv1D(filters, kernel_size=kernel,padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def block(x,filters):\n",
    "    x = c1D(x,filters,3)\n",
    "    x = c1D(x,filters,3)\n",
    "    return x\n",
    "    \n",
    "def d1D(x,filters):\n",
    "    x = Dense(filters,use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def build_FM(frame_l=32,joint_n=22,joint_d=2,feat_d=231,filters=16):   \n",
    "    M = Input(shape=(frame_l,feat_d))\n",
    "    P = Input(shape=(frame_l,joint_n,joint_d))\n",
    "    \n",
    "    diff_slow,diff_fast = pose_motion(P,frame_l)\n",
    "    \n",
    "    # Modeling Joint Correlations by an Embedding\n",
    "    x = c1D(M,filters*2,1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x,filters,3)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x,filters,1)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x_d_slow = c1D(diff_slow,filters*2,1)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,3)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,1)\n",
    "    x_d_slow = MaxPool1D(2)(x_d_slow)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "        \n",
    "    x_d_fast = c1D(diff_fast,filters*2,1)\n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,3) \n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,1) \n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "   \n",
    "    x = concatenate([x,x_d_slow,x_d_fast])\n",
    "    x = block(x,filters*2)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = block(x,filters*4)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = block(x,filters*8)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    return Model(inputs=[M,P],outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yis-lhRAZq0X"
   },
   "outputs": [],
   "source": [
    "def build_DD_Net(frame_l=32,joint_n=22,joint_d=3,feat_d=231,clc_num=14,filters=16):\n",
    "    M = Input(name='M', shape=(frame_l,feat_d))  \n",
    "    P = Input(name='P', shape=(frame_l,joint_n,joint_d)) \n",
    "    \n",
    "    FM = build_FM(frame_l,joint_n,joint_d,feat_d,filters)\n",
    "    \n",
    "    x = FM([M,P])\n",
    "\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    \n",
    "    x = d1D(x,128)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = d1D(x,128)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(clc_num, activation='softmax')(x)\n",
    "    \n",
    "    ######################Self-supervised part\n",
    "    model = Model(inputs=[M,P],outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rllCl_sHZwzz",
    "outputId": "ece0726e-d5c2-41f0-9b37-4c1c9337bf74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P type is:\n",
      "<class 'tensorflow.python.keras.engine.keras_tensor.KerasTensor'>\n"
     ]
    }
   ],
   "source": [
    "DD_Net = build_DD_Net(C.frame_l,C.joint_n,C.joint_d,C.feat_d,C.clc_coarse,C.filters)\n",
    "# DD_Net.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "XzIu88krdjnR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Train = pickle.load(open(\"SHREC/train.pkl\", \"rb\"))\n",
    "Test = pickle.load(open(\"SHREC/test.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnY_tmNDdrIc",
    "outputId": "5f6929d7-fcd9-4550-f8e3-f124179d8ced"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:13<00:00, 143.53it/s]\n"
     ]
    }
   ],
   "source": [
    "X_0 = []\n",
    "X_1 = []\n",
    "Y = []\n",
    "for i in tqdm(range(len(Train['pose']))): \n",
    "    p = np.copy(Train['pose'][i]).reshape([-1,22,3])\n",
    "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "    p = normlize_range(p)\n",
    "    \n",
    "    label = np.zeros(C.clc_coarse)\n",
    "    label[Train['coarse_label'][i]-1] = 1   \n",
    "\n",
    "    M = get_CG(p,C)\n",
    "\n",
    "    X_0.append(M)\n",
    "    X_1.append(p)\n",
    "    Y.append(label)\n",
    "\n",
    "X_0 = np.stack(X_0)  \n",
    "X_1 = np.stack(X_1) \n",
    "Y = np.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8EpSMN-d2Hj",
    "outputId": "4531bf83-9f5c-47a1-bdcc-5dec9281e0f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [00:05<00:00, 141.17it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_0 = []\n",
    "X_test_1 = []\n",
    "Y_test = []\n",
    "for i in tqdm(range(len(Test['pose']))): \n",
    "    p = np.copy(Test['pose'][i]).reshape([-1,22,3])\n",
    "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "    p = normlize_range(p)\n",
    "    \n",
    "    label = np.zeros(C.clc_coarse)\n",
    "    label[Test['coarse_label'][i]-1] = 1   \n",
    "\n",
    "    M = get_CG(p,C)\n",
    "\n",
    "    X_test_0.append(M)\n",
    "    X_test_1.append(p)\n",
    "    Y_test.append(label)\n",
    "\n",
    "X_test_0 = np.stack(X_test_0) \n",
    "X_test_1 = np.stack(X_test_1)  \n",
    "Y_test = np.stack(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U9rUOVUNd_WC",
    "outputId": "680d4cf2-7dd2-4ae8-c823-1dd24fc2b42c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3.1639 - accuracy: 0.0628 - val_loss: 2.6388 - val_accuracy: 0.0786\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 2.9297 - accuracy: 0.0893 - val_loss: 2.6389 - val_accuracy: 0.0655\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 2.8158 - accuracy: 0.1128 - val_loss: 2.6393 - val_accuracy: 0.0655\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 2.6761 - accuracy: 0.1296 - val_loss: 2.6397 - val_accuracy: 0.0655\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 2.6167 - accuracy: 0.1434 - val_loss: 2.6404 - val_accuracy: 0.0655\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 2.5849 - accuracy: 0.1536 - val_loss: 2.6413 - val_accuracy: 0.0655\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 2.5082 - accuracy: 0.1658 - val_loss: 2.6424 - val_accuracy: 0.0655\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 2.4426 - accuracy: 0.1852 - val_loss: 2.6438 - val_accuracy: 0.0655\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 2.4053 - accuracy: 0.1918 - val_loss: 2.6455 - val_accuracy: 0.0655\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 2.3660 - accuracy: 0.2071 - val_loss: 2.6476 - val_accuracy: 0.0655\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 2.3074 - accuracy: 0.2163 - val_loss: 2.6499 - val_accuracy: 0.0655\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 2.2416 - accuracy: 0.2526 - val_loss: 2.6526 - val_accuracy: 0.0940\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 2.1945 - accuracy: 0.2832 - val_loss: 2.6558 - val_accuracy: 0.0607\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 2.1610 - accuracy: 0.2730 - val_loss: 2.6593 - val_accuracy: 0.0607\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 2.1284 - accuracy: 0.2944 - val_loss: 2.6631 - val_accuracy: 0.0607\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 2.0714 - accuracy: 0.3051 - val_loss: 2.6673 - val_accuracy: 0.0607\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 2.0229 - accuracy: 0.3235 - val_loss: 2.6716 - val_accuracy: 0.0607\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 1.9437 - accuracy: 0.3556 - val_loss: 2.6765 - val_accuracy: 0.0607\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 1.9002 - accuracy: 0.3801 - val_loss: 2.6820 - val_accuracy: 0.0607\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 1.8682 - accuracy: 0.3954 - val_loss: 2.6881 - val_accuracy: 0.0607\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 1.8037 - accuracy: 0.4092 - val_loss: 2.6951 - val_accuracy: 0.0607\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 1.7667 - accuracy: 0.4240 - val_loss: 2.7033 - val_accuracy: 0.0607\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 1.6838 - accuracy: 0.4556 - val_loss: 2.7128 - val_accuracy: 0.0607\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.6571 - accuracy: 0.4724 - val_loss: 2.7235 - val_accuracy: 0.0607\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.5911 - accuracy: 0.4888 - val_loss: 2.7354 - val_accuracy: 0.0607\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 1.5660 - accuracy: 0.5082 - val_loss: 2.7483 - val_accuracy: 0.0607\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 1.4632 - accuracy: 0.5388 - val_loss: 2.7624 - val_accuracy: 0.0607\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 1.4177 - accuracy: 0.5454 - val_loss: 2.7775 - val_accuracy: 0.0607\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 1.3833 - accuracy: 0.5796 - val_loss: 2.7940 - val_accuracy: 0.0607\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 1.3347 - accuracy: 0.5954 - val_loss: 2.8114 - val_accuracy: 0.0607\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 1.2747 - accuracy: 0.6138 - val_loss: 2.8299 - val_accuracy: 0.0607\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 1.2316 - accuracy: 0.6224 - val_loss: 2.8486 - val_accuracy: 0.0607\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 1.1966 - accuracy: 0.6429 - val_loss: 2.8671 - val_accuracy: 0.0607\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 1.1369 - accuracy: 0.6617 - val_loss: 2.8867 - val_accuracy: 0.0607\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 1.1010 - accuracy: 0.6750 - val_loss: 2.9070 - val_accuracy: 0.0607\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 1.0740 - accuracy: 0.6755 - val_loss: 2.9284 - val_accuracy: 0.0607\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 1.0496 - accuracy: 0.6842 - val_loss: 2.9512 - val_accuracy: 0.0607\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.0380 - accuracy: 0.6898 - val_loss: 2.9749 - val_accuracy: 0.0631\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.9945 - accuracy: 0.6954 - val_loss: 2.9992 - val_accuracy: 0.0750\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.9545 - accuracy: 0.7204 - val_loss: 3.0252 - val_accuracy: 0.0929\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.9164 - accuracy: 0.7163 - val_loss: 3.0529 - val_accuracy: 0.1036\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.9101 - accuracy: 0.7194 - val_loss: 3.0819 - val_accuracy: 0.1083\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.8758 - accuracy: 0.7403 - val_loss: 3.1115 - val_accuracy: 0.1024\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.8287 - accuracy: 0.7602 - val_loss: 3.1402 - val_accuracy: 0.0976\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.8257 - accuracy: 0.7454 - val_loss: 3.1668 - val_accuracy: 0.0905\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.7830 - accuracy: 0.7704 - val_loss: 3.1932 - val_accuracy: 0.0845\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.7886 - accuracy: 0.7633 - val_loss: 3.2186 - val_accuracy: 0.0845\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.7484 - accuracy: 0.7837 - val_loss: 3.2402 - val_accuracy: 0.0845\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.7337 - accuracy: 0.7806 - val_loss: 3.2632 - val_accuracy: 0.0821\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.7149 - accuracy: 0.7908 - val_loss: 3.2838 - val_accuracy: 0.0821\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.6726 - accuracy: 0.8107 - val_loss: 3.3063 - val_accuracy: 0.0821\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.6701 - accuracy: 0.7995 - val_loss: 3.3285 - val_accuracy: 0.0845\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.6754 - accuracy: 0.7964 - val_loss: 3.3501 - val_accuracy: 0.0857\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.6689 - accuracy: 0.7918 - val_loss: 3.3728 - val_accuracy: 0.0905\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.6237 - accuracy: 0.8209 - val_loss: 3.3960 - val_accuracy: 0.1024\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.6208 - accuracy: 0.8276 - val_loss: 3.4156 - val_accuracy: 0.1048\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.6013 - accuracy: 0.8301 - val_loss: 3.4344 - val_accuracy: 0.1095\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.5837 - accuracy: 0.8255 - val_loss: 3.4498 - val_accuracy: 0.1071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.6203 - accuracy: 0.8138 - val_loss: 3.4616 - val_accuracy: 0.1036\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.5700 - accuracy: 0.8372 - val_loss: 3.4751 - val_accuracy: 0.1000\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.5606 - accuracy: 0.8418 - val_loss: 3.4888 - val_accuracy: 0.0845\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.5632 - accuracy: 0.8316 - val_loss: 3.5023 - val_accuracy: 0.0845\n",
      "Epoch 63/600\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.5263 - accuracy: 0.8566 - val_loss: 3.5197 - val_accuracy: 0.0821\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.5281 - accuracy: 0.8469 - val_loss: 3.5377 - val_accuracy: 0.0798\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.4929 - accuracy: 0.8566 - val_loss: 3.5601 - val_accuracy: 0.0798\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.4848 - accuracy: 0.8658 - val_loss: 3.5865 - val_accuracy: 0.0786\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.4570 - accuracy: 0.8770 - val_loss: 3.6096 - val_accuracy: 0.0786\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.4457 - accuracy: 0.8684 - val_loss: 3.6337 - val_accuracy: 0.0786\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.4280 - accuracy: 0.8714 - val_loss: 3.6628 - val_accuracy: 0.0798\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.4339 - accuracy: 0.8740 - val_loss: 3.6930 - val_accuracy: 0.0821\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.4707 - accuracy: 0.8638 - val_loss: 3.7307 - val_accuracy: 0.0833\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.4472 - accuracy: 0.8673 - val_loss: 3.7624 - val_accuracy: 0.0833\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.4297 - accuracy: 0.8755 - val_loss: 3.7877 - val_accuracy: 0.0881\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.4136 - accuracy: 0.8837 - val_loss: 3.8096 - val_accuracy: 0.0976\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.4036 - accuracy: 0.8821 - val_loss: 3.8258 - val_accuracy: 0.1024\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.3939 - accuracy: 0.8847 - val_loss: 3.8388 - val_accuracy: 0.1071\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.3712 - accuracy: 0.8949 - val_loss: 3.8531 - val_accuracy: 0.1071\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.3687 - accuracy: 0.8959 - val_loss: 3.8605 - val_accuracy: 0.1071\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.3585 - accuracy: 0.9005 - val_loss: 3.8646 - val_accuracy: 0.1060\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.3625 - accuracy: 0.8985 - val_loss: 3.8748 - val_accuracy: 0.1048\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.3485 - accuracy: 0.9077 - val_loss: 3.8838 - val_accuracy: 0.1048\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.3603 - accuracy: 0.8995 - val_loss: 3.8978 - val_accuracy: 0.1048\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.3466 - accuracy: 0.9036 - val_loss: 3.9174 - val_accuracy: 0.1071\n",
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.3276 - accuracy: 0.9020 - val_loss: 3.9322 - val_accuracy: 0.1071\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.3314 - accuracy: 0.9031 - val_loss: 3.9406 - val_accuracy: 0.1095\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.3234 - accuracy: 0.9051 - val_loss: 3.9444 - val_accuracy: 0.1107\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.3263 - accuracy: 0.9107 - val_loss: 3.9476 - val_accuracy: 0.1119\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.3477 - accuracy: 0.9092 - val_loss: 3.9483 - val_accuracy: 0.1143\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.3171 - accuracy: 0.9087 - val_loss: 3.9419 - val_accuracy: 0.1155\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.2947 - accuracy: 0.9148 - val_loss: 3.9294 - val_accuracy: 0.1179\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.3030 - accuracy: 0.9179 - val_loss: 3.9167 - val_accuracy: 0.1202\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.3108 - accuracy: 0.9061 - val_loss: 3.9041 - val_accuracy: 0.1202\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.3010 - accuracy: 0.9173 - val_loss: 3.9014 - val_accuracy: 0.1202\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.2867 - accuracy: 0.9230 - val_loss: 3.9084 - val_accuracy: 0.1202\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.2722 - accuracy: 0.9265 - val_loss: 3.9262 - val_accuracy: 0.1190\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.2603 - accuracy: 0.9286 - val_loss: 3.9572 - val_accuracy: 0.1143\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.2726 - accuracy: 0.9235 - val_loss: 3.9899 - val_accuracy: 0.1071\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.2743 - accuracy: 0.9224 - val_loss: 4.0152 - val_accuracy: 0.1048\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.2364 - accuracy: 0.9367 - val_loss: 4.0337 - val_accuracy: 0.1036\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.2608 - accuracy: 0.9270 - val_loss: 4.0361 - val_accuracy: 0.1036\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.2634 - accuracy: 0.9255 - val_loss: 4.0366 - val_accuracy: 0.1036\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.2506 - accuracy: 0.9296 - val_loss: 4.0325 - val_accuracy: 0.1036\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.2317 - accuracy: 0.9352 - val_loss: 4.0253 - val_accuracy: 0.1036\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.2507 - accuracy: 0.9337 - val_loss: 4.0197 - val_accuracy: 0.1071\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.2566 - accuracy: 0.9265 - val_loss: 4.0142 - val_accuracy: 0.1095\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.2386 - accuracy: 0.9388 - val_loss: 4.0006 - val_accuracy: 0.1107\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.2332 - accuracy: 0.9367 - val_loss: 3.9940 - val_accuracy: 0.1107\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.2450 - accuracy: 0.9301 - val_loss: 3.9917 - val_accuracy: 0.1095\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.2378 - accuracy: 0.9327 - val_loss: 3.9957 - val_accuracy: 0.1083\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.2343 - accuracy: 0.9352 - val_loss: 4.0016 - val_accuracy: 0.1095\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.2342 - accuracy: 0.9342 - val_loss: 4.0111 - val_accuracy: 0.1095\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.2303 - accuracy: 0.9398 - val_loss: 4.0223 - val_accuracy: 0.1095\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.2209 - accuracy: 0.9423 - val_loss: 4.0371 - val_accuracy: 0.1095\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.2114 - accuracy: 0.9372 - val_loss: 4.0508 - val_accuracy: 0.1107\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.2358 - accuracy: 0.9311 - val_loss: 4.0571 - val_accuracy: 0.1143\n",
      "Epoch 116/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 436ms/step - loss: 0.2203 - accuracy: 0.9408 - val_loss: 4.0656 - val_accuracy: 0.1167\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.2104 - accuracy: 0.9429 - val_loss: 4.0788 - val_accuracy: 0.1167\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.2321 - accuracy: 0.9352 - val_loss: 4.0861 - val_accuracy: 0.1155\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.1980 - accuracy: 0.9434 - val_loss: 4.0880 - val_accuracy: 0.1143\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.2064 - accuracy: 0.9383 - val_loss: 4.0906 - val_accuracy: 0.1095\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.1972 - accuracy: 0.9459 - val_loss: 4.0894 - val_accuracy: 0.1095\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.2009 - accuracy: 0.9413 - val_loss: 4.0842 - val_accuracy: 0.1095\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1909 - accuracy: 0.9469 - val_loss: 4.0833 - val_accuracy: 0.1095\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.2234 - accuracy: 0.9383 - val_loss: 4.0839 - val_accuracy: 0.1095\n",
      "Epoch 125/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.2034 - accuracy: 0.9418 - val_loss: 4.0782 - val_accuracy: 0.1095\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1916 - accuracy: 0.9510 - val_loss: 4.0749 - val_accuracy: 0.1095\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.2020 - accuracy: 0.9474 - val_loss: 4.0697 - val_accuracy: 0.1095\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.1907 - accuracy: 0.9439 - val_loss: 4.0669 - val_accuracy: 0.1095\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1934 - accuracy: 0.9429 - val_loss: 4.0476 - val_accuracy: 0.1143\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.1874 - accuracy: 0.9520 - val_loss: 4.0288 - val_accuracy: 0.1167\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.2143 - accuracy: 0.9357 - val_loss: 4.0153 - val_accuracy: 0.1202\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1890 - accuracy: 0.9500 - val_loss: 4.0058 - val_accuracy: 0.1214\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.2043 - accuracy: 0.9413 - val_loss: 3.9970 - val_accuracy: 0.1214\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.1859 - accuracy: 0.9495 - val_loss: 3.9932 - val_accuracy: 0.1214\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.2026 - accuracy: 0.9439 - val_loss: 3.9861 - val_accuracy: 0.1226\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.2060 - accuracy: 0.9408 - val_loss: 3.9830 - val_accuracy: 0.1226\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.1850 - accuracy: 0.9531 - val_loss: 3.9850 - val_accuracy: 0.1226\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.1799 - accuracy: 0.9510 - val_loss: 3.9884 - val_accuracy: 0.1226\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.2004 - accuracy: 0.9429 - val_loss: 3.9897 - val_accuracy: 0.1238\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.1891 - accuracy: 0.9444 - val_loss: 3.9915 - val_accuracy: 0.1238\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1907 - accuracy: 0.9459 - val_loss: 3.9923 - val_accuracy: 0.1238\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.1668 - accuracy: 0.9571 - val_loss: 3.9974 - val_accuracy: 0.1238\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1752 - accuracy: 0.9571 - val_loss: 4.0057 - val_accuracy: 0.1274\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1807 - accuracy: 0.9474 - val_loss: 4.0118 - val_accuracy: 0.1286\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1689 - accuracy: 0.9592 - val_loss: 4.0175 - val_accuracy: 0.1321\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.1622 - accuracy: 0.9582 - val_loss: 4.0245 - val_accuracy: 0.1321\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1799 - accuracy: 0.9520 - val_loss: 4.0291 - val_accuracy: 0.1321\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.1760 - accuracy: 0.9541 - val_loss: 4.0341 - val_accuracy: 0.1321\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.1664 - accuracy: 0.9531 - val_loss: 4.0468 - val_accuracy: 0.1310\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.1736 - accuracy: 0.9526 - val_loss: 4.0603 - val_accuracy: 0.1286\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1805 - accuracy: 0.9551 - val_loss: 4.0616 - val_accuracy: 0.1286\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.1709 - accuracy: 0.9566 - val_loss: 4.0662 - val_accuracy: 0.1274\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.1810 - accuracy: 0.9469 - val_loss: 4.0730 - val_accuracy: 0.1274\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.1681 - accuracy: 0.9566 - val_loss: 4.0731 - val_accuracy: 0.1274\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.1778 - accuracy: 0.9520 - val_loss: 4.0740 - val_accuracy: 0.1286\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1709 - accuracy: 0.9541 - val_loss: 4.0720 - val_accuracy: 0.1310\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.1672 - accuracy: 0.9520 - val_loss: 4.0728 - val_accuracy: 0.1310\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.1685 - accuracy: 0.9556 - val_loss: 4.0746 - val_accuracy: 0.1310\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.1751 - accuracy: 0.9485 - val_loss: 4.0775 - val_accuracy: 0.1310\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.1657 - accuracy: 0.9541 - val_loss: 4.0800 - val_accuracy: 0.1321\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1539 - accuracy: 0.9633 - val_loss: 4.0803 - val_accuracy: 0.1321\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1870 - accuracy: 0.9485 - val_loss: 4.0791 - val_accuracy: 0.1321\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.1707 - accuracy: 0.9526 - val_loss: 4.0788 - val_accuracy: 0.1321\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.1657 - accuracy: 0.9520 - val_loss: 4.0797 - val_accuracy: 0.1321\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.1613 - accuracy: 0.9566 - val_loss: 4.0833 - val_accuracy: 0.1321\n",
      "Epoch 166/600\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.1755 - accuracy: 0.9505 - val_loss: 4.0856 - val_accuracy: 0.1333\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.1587 - accuracy: 0.9582 - val_loss: 4.0897 - val_accuracy: 0.1333\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.1579 - accuracy: 0.9617 - val_loss: 4.0917 - val_accuracy: 0.1333\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.1666 - accuracy: 0.9531 - val_loss: 4.0936 - val_accuracy: 0.1345\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1595 - accuracy: 0.9577 - val_loss: 4.0931 - val_accuracy: 0.1357\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1595 - accuracy: 0.9515 - val_loss: 4.0926 - val_accuracy: 0.1393\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.1522 - accuracy: 0.9612 - val_loss: 4.0919 - val_accuracy: 0.1393\n",
      "Epoch 173/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1599 - accuracy: 0.9622 - val_loss: 4.0908 - val_accuracy: 0.1393\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.1539 - accuracy: 0.9617 - val_loss: 4.0891 - val_accuracy: 0.1393\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1644 - accuracy: 0.9571 - val_loss: 4.0870 - val_accuracy: 0.1393\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1561 - accuracy: 0.9607 - val_loss: 4.0838 - val_accuracy: 0.1393\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.1598 - accuracy: 0.9607 - val_loss: 4.0805 - val_accuracy: 0.1393\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1782 - accuracy: 0.9495 - val_loss: 4.0768 - val_accuracy: 0.1381\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1616 - accuracy: 0.9510 - val_loss: 4.0740 - val_accuracy: 0.1393\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1725 - accuracy: 0.9490 - val_loss: 4.0702 - val_accuracy: 0.1393\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1567 - accuracy: 0.9536 - val_loss: 4.0662 - val_accuracy: 0.1405\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1538 - accuracy: 0.9612 - val_loss: 4.0623 - val_accuracy: 0.1417\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1702 - accuracy: 0.9546 - val_loss: 4.0584 - val_accuracy: 0.1440\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1640 - accuracy: 0.9551 - val_loss: 4.0548 - val_accuracy: 0.1440\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1608 - accuracy: 0.9587 - val_loss: 4.0510 - val_accuracy: 0.1452\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1400 - accuracy: 0.9597 - val_loss: 4.0480 - val_accuracy: 0.1452\n",
      "Epoch 187/600\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1598 - accuracy: 0.9546 - val_loss: 4.0449 - val_accuracy: 0.1452\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.1666 - accuracy: 0.9541 - val_loss: 4.0422 - val_accuracy: 0.1452\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.1545 - accuracy: 0.9602 - val_loss: 4.0382 - val_accuracy: 0.1476\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.1803 - accuracy: 0.9474 - val_loss: 4.0345 - val_accuracy: 0.1476\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.1540 - accuracy: 0.9592 - val_loss: 4.0310 - val_accuracy: 0.1488\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.1786 - accuracy: 0.9526 - val_loss: 4.0275 - val_accuracy: 0.1500\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.1667 - accuracy: 0.9536 - val_loss: 4.0233 - val_accuracy: 0.1500\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.1621 - accuracy: 0.9597 - val_loss: 4.0189 - val_accuracy: 0.1500\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.1619 - accuracy: 0.9551 - val_loss: 4.0139 - val_accuracy: 0.1500\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.1566 - accuracy: 0.9612 - val_loss: 4.0088 - val_accuracy: 0.1512\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.1719 - accuracy: 0.9515 - val_loss: 4.0040 - val_accuracy: 0.1512\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.1450 - accuracy: 0.9622 - val_loss: 3.9989 - val_accuracy: 0.1512\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.1497 - accuracy: 0.9602 - val_loss: 3.9934 - val_accuracy: 0.1512\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.1559 - accuracy: 0.9597 - val_loss: 3.9883 - val_accuracy: 0.1512\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.1529 - accuracy: 0.9628 - val_loss: 3.9837 - val_accuracy: 0.1512\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.1584 - accuracy: 0.9597 - val_loss: 3.9788 - val_accuracy: 0.1512\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.1536 - accuracy: 0.9571 - val_loss: 3.9738 - val_accuracy: 0.1512\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.1551 - accuracy: 0.9541 - val_loss: 3.9688 - val_accuracy: 0.1524\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.1618 - accuracy: 0.9592 - val_loss: 3.9634 - val_accuracy: 0.1524\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1709 - accuracy: 0.9474 - val_loss: 3.9575 - val_accuracy: 0.1524\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.1655 - accuracy: 0.9551 - val_loss: 3.9520 - val_accuracy: 0.1524\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.1637 - accuracy: 0.9515 - val_loss: 3.9464 - val_accuracy: 0.1536\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.1722 - accuracy: 0.9546 - val_loss: 3.9409 - val_accuracy: 0.1536\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.1657 - accuracy: 0.9531 - val_loss: 3.9350 - val_accuracy: 0.1536\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.1820 - accuracy: 0.9526 - val_loss: 3.9290 - val_accuracy: 0.1548\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1593 - accuracy: 0.9541 - val_loss: 3.9234 - val_accuracy: 0.1548\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.1549 - accuracy: 0.9622 - val_loss: 3.9177 - val_accuracy: 0.1548\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.1706 - accuracy: 0.9490 - val_loss: 3.9118 - val_accuracy: 0.1560\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.1558 - accuracy: 0.9622 - val_loss: 3.9054 - val_accuracy: 0.1560\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.1461 - accuracy: 0.9679 - val_loss: 3.8996 - val_accuracy: 0.1560\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.1604 - accuracy: 0.9546 - val_loss: 3.8931 - val_accuracy: 0.1560\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1768 - accuracy: 0.9520 - val_loss: 3.8863 - val_accuracy: 0.1571\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.1581 - accuracy: 0.9617 - val_loss: 3.8796 - val_accuracy: 0.1571\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.1714 - accuracy: 0.9582 - val_loss: 3.8731 - val_accuracy: 0.1571\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.1696 - accuracy: 0.9551 - val_loss: 3.8664 - val_accuracy: 0.1571\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.1604 - accuracy: 0.9597 - val_loss: 3.8598 - val_accuracy: 0.1571\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.1419 - accuracy: 0.9628 - val_loss: 3.8529 - val_accuracy: 0.1583\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.1676 - accuracy: 0.9571 - val_loss: 3.8462 - val_accuracy: 0.1583\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.1684 - accuracy: 0.9546 - val_loss: 3.8390 - val_accuracy: 0.1583\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.1621 - accuracy: 0.9556 - val_loss: 3.8315 - val_accuracy: 0.1595\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.1598 - accuracy: 0.9566 - val_loss: 3.8245 - val_accuracy: 0.1595\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.1740 - accuracy: 0.9490 - val_loss: 3.8168 - val_accuracy: 0.1595\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.1663 - accuracy: 0.9546 - val_loss: 3.8091 - val_accuracy: 0.1595\n",
      "Epoch 230/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1592 - accuracy: 0.9566 - val_loss: 3.8017 - val_accuracy: 0.1595\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.1562 - accuracy: 0.9577 - val_loss: 3.7940 - val_accuracy: 0.1607\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.1638 - accuracy: 0.9587 - val_loss: 3.7860 - val_accuracy: 0.1619\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.1790 - accuracy: 0.9531 - val_loss: 3.7778 - val_accuracy: 0.1631\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.1651 - accuracy: 0.9556 - val_loss: 3.7697 - val_accuracy: 0.1631\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.1542 - accuracy: 0.9633 - val_loss: 3.7611 - val_accuracy: 0.1643\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.1548 - accuracy: 0.9571 - val_loss: 3.7528 - val_accuracy: 0.1655\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.1556 - accuracy: 0.9587 - val_loss: 3.7440 - val_accuracy: 0.1655\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.1593 - accuracy: 0.9546 - val_loss: 3.7350 - val_accuracy: 0.1655\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.1547 - accuracy: 0.9541 - val_loss: 3.7265 - val_accuracy: 0.1655\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.1470 - accuracy: 0.9612 - val_loss: 3.7168 - val_accuracy: 0.1655\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.1795 - accuracy: 0.9490 - val_loss: 3.7072 - val_accuracy: 0.1667\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.1651 - accuracy: 0.9561 - val_loss: 3.6981 - val_accuracy: 0.1690\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1549 - accuracy: 0.9602 - val_loss: 3.6885 - val_accuracy: 0.1690\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.1489 - accuracy: 0.9622 - val_loss: 3.6791 - val_accuracy: 0.1690\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.1450 - accuracy: 0.9638 - val_loss: 3.6696 - val_accuracy: 0.1690\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.1457 - accuracy: 0.9602 - val_loss: 3.6595 - val_accuracy: 0.1714\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.1535 - accuracy: 0.9582 - val_loss: 3.6490 - val_accuracy: 0.1714\n",
      "Epoch 248/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1502 - accuracy: 0.9607 - val_loss: 3.6388 - val_accuracy: 0.1714\n",
      "Epoch 249/600\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.1721 - accuracy: 0.9526 - val_loss: 3.6284 - val_accuracy: 0.1726\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.1601 - accuracy: 0.9515 - val_loss: 3.6182 - val_accuracy: 0.1726\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.1801 - accuracy: 0.9510 - val_loss: 3.6079 - val_accuracy: 0.1738\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.1783 - accuracy: 0.9469 - val_loss: 3.5972 - val_accuracy: 0.1738\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.1604 - accuracy: 0.9617 - val_loss: 3.5865 - val_accuracy: 0.1762\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.1760 - accuracy: 0.9526 - val_loss: 3.5756 - val_accuracy: 0.1762\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.1665 - accuracy: 0.9556 - val_loss: 3.5642 - val_accuracy: 0.1762\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1629 - accuracy: 0.9551 - val_loss: 3.5528 - val_accuracy: 0.1774\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.1584 - accuracy: 0.9592 - val_loss: 3.5419 - val_accuracy: 0.1798\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.1443 - accuracy: 0.9643 - val_loss: 3.5309 - val_accuracy: 0.1798\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.1627 - accuracy: 0.9480 - val_loss: 3.5198 - val_accuracy: 0.1798\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.1573 - accuracy: 0.9577 - val_loss: 3.5085 - val_accuracy: 0.1810\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.1628 - accuracy: 0.9571 - val_loss: 3.4974 - val_accuracy: 0.1821\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.1576 - accuracy: 0.9556 - val_loss: 3.4854 - val_accuracy: 0.1833\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.1623 - accuracy: 0.9556 - val_loss: 3.4736 - val_accuracy: 0.1833\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.1566 - accuracy: 0.9582 - val_loss: 3.4620 - val_accuracy: 0.1869\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.1678 - accuracy: 0.9531 - val_loss: 3.4497 - val_accuracy: 0.1869\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.1613 - accuracy: 0.9561 - val_loss: 3.4373 - val_accuracy: 0.1869\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.1596 - accuracy: 0.9582 - val_loss: 3.4251 - val_accuracy: 0.1905\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.1627 - accuracy: 0.9520 - val_loss: 3.4125 - val_accuracy: 0.1905\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.1451 - accuracy: 0.9587 - val_loss: 3.3997 - val_accuracy: 0.1929\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.1635 - accuracy: 0.9602 - val_loss: 3.3873 - val_accuracy: 0.1929\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.1554 - accuracy: 0.9597 - val_loss: 3.3747 - val_accuracy: 0.1952\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.1601 - accuracy: 0.9582 - val_loss: 3.3619 - val_accuracy: 0.1988\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.1523 - accuracy: 0.9551 - val_loss: 3.3491 - val_accuracy: 0.2000\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.1547 - accuracy: 0.9617 - val_loss: 3.3359 - val_accuracy: 0.2012\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.1705 - accuracy: 0.9520 - val_loss: 3.3225 - val_accuracy: 0.2024\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.1487 - accuracy: 0.9602 - val_loss: 3.3099 - val_accuracy: 0.2036\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1495 - accuracy: 0.9628 - val_loss: 3.2971 - val_accuracy: 0.2048\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1500 - accuracy: 0.9617 - val_loss: 3.2840 - val_accuracy: 0.2048\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.1634 - accuracy: 0.9582 - val_loss: 3.2707 - val_accuracy: 0.2048\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.1387 - accuracy: 0.9633 - val_loss: 3.2573 - val_accuracy: 0.2060\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.1722 - accuracy: 0.9515 - val_loss: 3.2439 - val_accuracy: 0.2083\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1519 - accuracy: 0.9577 - val_loss: 3.2304 - val_accuracy: 0.2095\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.1750 - accuracy: 0.9520 - val_loss: 3.2163 - val_accuracy: 0.2119\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.1671 - accuracy: 0.9551 - val_loss: 3.2026 - val_accuracy: 0.2131\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.1704 - accuracy: 0.9520 - val_loss: 3.1887 - val_accuracy: 0.2155\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1620 - accuracy: 0.9597 - val_loss: 3.1751 - val_accuracy: 0.2167\n",
      "Epoch 287/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1777 - accuracy: 0.9520 - val_loss: 3.1615 - val_accuracy: 0.2179\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1483 - accuracy: 0.9561 - val_loss: 3.1474 - val_accuracy: 0.2190\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.1602 - accuracy: 0.9566 - val_loss: 3.1332 - val_accuracy: 0.2226\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.1517 - accuracy: 0.9602 - val_loss: 3.1191 - val_accuracy: 0.2250\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.1534 - accuracy: 0.9648 - val_loss: 3.1050 - val_accuracy: 0.2286\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.1546 - accuracy: 0.9577 - val_loss: 3.0910 - val_accuracy: 0.2310\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1665 - accuracy: 0.9551 - val_loss: 3.0769 - val_accuracy: 0.2345\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1480 - accuracy: 0.9628 - val_loss: 3.0626 - val_accuracy: 0.2357\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.1632 - accuracy: 0.9536 - val_loss: 3.0487 - val_accuracy: 0.2381\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.1548 - accuracy: 0.9597 - val_loss: 3.0344 - val_accuracy: 0.2405\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.1627 - accuracy: 0.9531 - val_loss: 3.0204 - val_accuracy: 0.2417\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.1616 - accuracy: 0.9607 - val_loss: 3.0060 - val_accuracy: 0.2429\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.1477 - accuracy: 0.9597 - val_loss: 2.9916 - val_accuracy: 0.2464\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.1478 - accuracy: 0.9633 - val_loss: 2.9773 - val_accuracy: 0.2488\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.1738 - accuracy: 0.9546 - val_loss: 2.9634 - val_accuracy: 0.2488\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.1497 - accuracy: 0.9648 - val_loss: 2.9489 - val_accuracy: 0.2524\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.1623 - accuracy: 0.9531 - val_loss: 2.9344 - val_accuracy: 0.2571\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.1545 - accuracy: 0.9571 - val_loss: 2.9196 - val_accuracy: 0.2595\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.1705 - accuracy: 0.9551 - val_loss: 2.9052 - val_accuracy: 0.2619\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.1563 - accuracy: 0.9561 - val_loss: 2.8902 - val_accuracy: 0.2667\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1613 - accuracy: 0.9597 - val_loss: 2.8751 - val_accuracy: 0.2679\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1538 - accuracy: 0.9597 - val_loss: 2.8606 - val_accuracy: 0.2690\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1511 - accuracy: 0.9622 - val_loss: 2.8462 - val_accuracy: 0.2726\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.1403 - accuracy: 0.9658 - val_loss: 2.8311 - val_accuracy: 0.2750\n",
      "Epoch 311/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1563 - accuracy: 0.9571 - val_loss: 2.8163 - val_accuracy: 0.2786\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1540 - accuracy: 0.9607 - val_loss: 2.8013 - val_accuracy: 0.2786\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.1537 - accuracy: 0.9495 - val_loss: 2.7869 - val_accuracy: 0.2833\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1700 - accuracy: 0.9546 - val_loss: 2.7720 - val_accuracy: 0.2845\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.1542 - accuracy: 0.9597 - val_loss: 2.7568 - val_accuracy: 0.2893\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.1645 - accuracy: 0.9577 - val_loss: 2.7416 - val_accuracy: 0.2905\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.1594 - accuracy: 0.9607 - val_loss: 2.7267 - val_accuracy: 0.2929\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.1427 - accuracy: 0.9658 - val_loss: 2.7112 - val_accuracy: 0.2952\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.1575 - accuracy: 0.9582 - val_loss: 2.6961 - val_accuracy: 0.2964\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.1516 - accuracy: 0.9612 - val_loss: 2.6817 - val_accuracy: 0.3012\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.1578 - accuracy: 0.9531 - val_loss: 2.6666 - val_accuracy: 0.3060\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.1607 - accuracy: 0.9571 - val_loss: 2.6514 - val_accuracy: 0.3060\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.1549 - accuracy: 0.9571 - val_loss: 2.6360 - val_accuracy: 0.3095\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.1565 - accuracy: 0.9587 - val_loss: 2.6211 - val_accuracy: 0.3119\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.1651 - accuracy: 0.9531 - val_loss: 2.6055 - val_accuracy: 0.3143\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1476 - accuracy: 0.9597 - val_loss: 2.5905 - val_accuracy: 0.3179\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1635 - accuracy: 0.9587 - val_loss: 2.5751 - val_accuracy: 0.3190\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1746 - accuracy: 0.9515 - val_loss: 2.5600 - val_accuracy: 0.3262\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1682 - accuracy: 0.9541 - val_loss: 2.5450 - val_accuracy: 0.3286\n",
      "Epoch 330/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1695 - accuracy: 0.9541 - val_loss: 2.5300 - val_accuracy: 0.3333\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1675 - accuracy: 0.9495 - val_loss: 2.5152 - val_accuracy: 0.3345\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1634 - accuracy: 0.9531 - val_loss: 2.5006 - val_accuracy: 0.3381\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1584 - accuracy: 0.9602 - val_loss: 2.4863 - val_accuracy: 0.3429\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1592 - accuracy: 0.9551 - val_loss: 2.4712 - val_accuracy: 0.3440\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.1640 - accuracy: 0.9515 - val_loss: 2.4565 - val_accuracy: 0.3476\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1746 - accuracy: 0.9515 - val_loss: 2.4413 - val_accuracy: 0.3512\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1631 - accuracy: 0.9561 - val_loss: 2.4264 - val_accuracy: 0.3512\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.1486 - accuracy: 0.9638 - val_loss: 2.4108 - val_accuracy: 0.3536\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.1492 - accuracy: 0.9617 - val_loss: 2.3955 - val_accuracy: 0.3536\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.1623 - accuracy: 0.9561 - val_loss: 2.3801 - val_accuracy: 0.3583\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.1669 - accuracy: 0.9587 - val_loss: 2.3650 - val_accuracy: 0.3631\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.1528 - accuracy: 0.9597 - val_loss: 2.3494 - val_accuracy: 0.3655\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1606 - accuracy: 0.9510 - val_loss: 2.3348 - val_accuracy: 0.3679\n",
      "Epoch 344/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 423ms/step - loss: 0.1671 - accuracy: 0.9582 - val_loss: 2.3200 - val_accuracy: 0.3726\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1605 - accuracy: 0.9566 - val_loss: 2.3051 - val_accuracy: 0.3738\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1727 - accuracy: 0.9480 - val_loss: 2.2902 - val_accuracy: 0.3750\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1647 - accuracy: 0.9592 - val_loss: 2.2755 - val_accuracy: 0.3798\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.1602 - accuracy: 0.9587 - val_loss: 2.2606 - val_accuracy: 0.3857\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1500 - accuracy: 0.9668 - val_loss: 2.2461 - val_accuracy: 0.3869\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1567 - accuracy: 0.9592 - val_loss: 2.2312 - val_accuracy: 0.3869\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1532 - accuracy: 0.9546 - val_loss: 2.2163 - val_accuracy: 0.3881\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1431 - accuracy: 0.9612 - val_loss: 2.2019 - val_accuracy: 0.3905\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1580 - accuracy: 0.9638 - val_loss: 2.1873 - val_accuracy: 0.4000\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1589 - accuracy: 0.9561 - val_loss: 2.1724 - val_accuracy: 0.4036\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.1432 - accuracy: 0.9643 - val_loss: 2.1579 - val_accuracy: 0.4071\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.1714 - accuracy: 0.9541 - val_loss: 2.1436 - val_accuracy: 0.4131\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1659 - accuracy: 0.9592 - val_loss: 2.1294 - val_accuracy: 0.4143\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1549 - accuracy: 0.9592 - val_loss: 2.1147 - val_accuracy: 0.4155\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1546 - accuracy: 0.9582 - val_loss: 2.1000 - val_accuracy: 0.4202\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.1452 - accuracy: 0.9561 - val_loss: 2.0857 - val_accuracy: 0.4226\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1538 - accuracy: 0.9617 - val_loss: 2.0712 - val_accuracy: 0.4262\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1463 - accuracy: 0.9617 - val_loss: 2.0566 - val_accuracy: 0.4298\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1647 - accuracy: 0.9551 - val_loss: 2.0422 - val_accuracy: 0.4381\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1752 - accuracy: 0.9459 - val_loss: 2.0276 - val_accuracy: 0.4417\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1533 - accuracy: 0.9617 - val_loss: 2.0133 - val_accuracy: 0.4476\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1559 - accuracy: 0.9597 - val_loss: 1.9991 - val_accuracy: 0.4524\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1541 - accuracy: 0.9597 - val_loss: 1.9847 - val_accuracy: 0.4583\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1440 - accuracy: 0.9597 - val_loss: 1.9704 - val_accuracy: 0.4619\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1610 - accuracy: 0.9582 - val_loss: 1.9563 - val_accuracy: 0.4655\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1639 - accuracy: 0.9602 - val_loss: 1.9421 - val_accuracy: 0.4690\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1527 - accuracy: 0.9607 - val_loss: 1.9278 - val_accuracy: 0.4738\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1468 - accuracy: 0.9622 - val_loss: 1.9138 - val_accuracy: 0.4762\n",
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.1595 - accuracy: 0.9520 - val_loss: 1.8999 - val_accuracy: 0.4810\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1631 - accuracy: 0.9566 - val_loss: 1.8860 - val_accuracy: 0.4845\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1551 - accuracy: 0.9582 - val_loss: 1.8723 - val_accuracy: 0.4881\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1561 - accuracy: 0.9551 - val_loss: 1.8582 - val_accuracy: 0.4917\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1501 - accuracy: 0.9592 - val_loss: 1.8443 - val_accuracy: 0.5000\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1575 - accuracy: 0.9582 - val_loss: 1.8307 - val_accuracy: 0.5000\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1575 - accuracy: 0.9577 - val_loss: 1.8170 - val_accuracy: 0.5048\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1676 - accuracy: 0.9566 - val_loss: 1.8032 - val_accuracy: 0.5060\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1559 - accuracy: 0.9566 - val_loss: 1.7898 - val_accuracy: 0.5131\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1599 - accuracy: 0.9566 - val_loss: 1.7766 - val_accuracy: 0.5155\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.1586 - accuracy: 0.9577 - val_loss: 1.7632 - val_accuracy: 0.5179\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1607 - accuracy: 0.9536 - val_loss: 1.7499 - val_accuracy: 0.5262\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1611 - accuracy: 0.9536 - val_loss: 1.7365 - val_accuracy: 0.5286\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.1667 - accuracy: 0.9531 - val_loss: 1.7230 - val_accuracy: 0.5310\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1623 - accuracy: 0.9577 - val_loss: 1.7094 - val_accuracy: 0.5321\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1525 - accuracy: 0.9536 - val_loss: 1.6963 - val_accuracy: 0.5321\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1603 - accuracy: 0.9592 - val_loss: 1.6832 - val_accuracy: 0.5381\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1543 - accuracy: 0.9592 - val_loss: 1.6697 - val_accuracy: 0.5381\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1772 - accuracy: 0.9526 - val_loss: 1.6563 - val_accuracy: 0.5405\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.1458 - accuracy: 0.9643 - val_loss: 1.6431 - val_accuracy: 0.5464\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1539 - accuracy: 0.9607 - val_loss: 1.6299 - val_accuracy: 0.5500\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1598 - accuracy: 0.9587 - val_loss: 1.6172 - val_accuracy: 0.5571\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1591 - accuracy: 0.9577 - val_loss: 1.6042 - val_accuracy: 0.5583\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1611 - accuracy: 0.9561 - val_loss: 1.5912 - val_accuracy: 0.5619\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1555 - accuracy: 0.9587 - val_loss: 1.5784 - val_accuracy: 0.5643\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1546 - accuracy: 0.9617 - val_loss: 1.5659 - val_accuracy: 0.5667\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1573 - accuracy: 0.9566 - val_loss: 1.5531 - val_accuracy: 0.5714\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1549 - accuracy: 0.9622 - val_loss: 1.5402 - val_accuracy: 0.5774\n",
      "Epoch 401/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1557 - accuracy: 0.9582 - val_loss: 1.5276 - val_accuracy: 0.5810\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1549 - accuracy: 0.9582 - val_loss: 1.5151 - val_accuracy: 0.5821\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1745 - accuracy: 0.9526 - val_loss: 1.5027 - val_accuracy: 0.5857\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1598 - accuracy: 0.9577 - val_loss: 1.4901 - val_accuracy: 0.5893\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1550 - accuracy: 0.9628 - val_loss: 1.4780 - val_accuracy: 0.5905\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1635 - accuracy: 0.9556 - val_loss: 1.4657 - val_accuracy: 0.5929\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1469 - accuracy: 0.9602 - val_loss: 1.4534 - val_accuracy: 0.5952\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.1578 - accuracy: 0.9561 - val_loss: 1.4410 - val_accuracy: 0.5964\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1606 - accuracy: 0.9566 - val_loss: 1.4286 - val_accuracy: 0.5988\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1672 - accuracy: 0.9597 - val_loss: 1.4162 - val_accuracy: 0.6024\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1714 - accuracy: 0.9480 - val_loss: 1.4041 - val_accuracy: 0.6036\n",
      "Epoch 412/600\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.1532 - accuracy: 0.9561 - val_loss: 1.3920 - val_accuracy: 0.6048\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.1524 - accuracy: 0.9607 - val_loss: 1.3802 - val_accuracy: 0.6131\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1588 - accuracy: 0.9592 - val_loss: 1.3683 - val_accuracy: 0.6155\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.1482 - accuracy: 0.9571 - val_loss: 1.3563 - val_accuracy: 0.6179\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1670 - accuracy: 0.9546 - val_loss: 1.3448 - val_accuracy: 0.6179\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1751 - accuracy: 0.9490 - val_loss: 1.3332 - val_accuracy: 0.6214\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1456 - accuracy: 0.9571 - val_loss: 1.3217 - val_accuracy: 0.6226\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1471 - accuracy: 0.9617 - val_loss: 1.3104 - val_accuracy: 0.6262\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.1526 - accuracy: 0.9571 - val_loss: 1.2991 - val_accuracy: 0.6333\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1480 - accuracy: 0.9653 - val_loss: 1.2875 - val_accuracy: 0.6369\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1470 - accuracy: 0.9668 - val_loss: 1.2763 - val_accuracy: 0.6417\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1450 - accuracy: 0.9612 - val_loss: 1.2650 - val_accuracy: 0.6440\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1638 - accuracy: 0.9556 - val_loss: 1.2537 - val_accuracy: 0.6452\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1436 - accuracy: 0.9628 - val_loss: 1.2429 - val_accuracy: 0.6476\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1536 - accuracy: 0.9561 - val_loss: 1.2320 - val_accuracy: 0.6500\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1490 - accuracy: 0.9658 - val_loss: 1.2211 - val_accuracy: 0.6560\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1585 - accuracy: 0.9577 - val_loss: 1.2104 - val_accuracy: 0.6583\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1671 - accuracy: 0.9556 - val_loss: 1.1999 - val_accuracy: 0.6607\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.1545 - accuracy: 0.9582 - val_loss: 1.1893 - val_accuracy: 0.6607\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1476 - accuracy: 0.9607 - val_loss: 1.1788 - val_accuracy: 0.6631\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1642 - accuracy: 0.9577 - val_loss: 1.1684 - val_accuracy: 0.6679\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1607 - accuracy: 0.9546 - val_loss: 1.1580 - val_accuracy: 0.6702\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.1516 - accuracy: 0.9633 - val_loss: 1.1477 - val_accuracy: 0.6726\n",
      "Epoch 435/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1600 - accuracy: 0.9531 - val_loss: 1.1375 - val_accuracy: 0.6726\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1490 - accuracy: 0.9612 - val_loss: 1.1273 - val_accuracy: 0.6750\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1533 - accuracy: 0.9566 - val_loss: 1.1172 - val_accuracy: 0.6762\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.1497 - accuracy: 0.9561 - val_loss: 1.1072 - val_accuracy: 0.6762\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1465 - accuracy: 0.9597 - val_loss: 1.0971 - val_accuracy: 0.6762\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1476 - accuracy: 0.9633 - val_loss: 1.0871 - val_accuracy: 0.6762\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1493 - accuracy: 0.9612 - val_loss: 1.0770 - val_accuracy: 0.6810\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1785 - accuracy: 0.9500 - val_loss: 1.0671 - val_accuracy: 0.6845\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1480 - accuracy: 0.9638 - val_loss: 1.0573 - val_accuracy: 0.6869\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1517 - accuracy: 0.9607 - val_loss: 1.0476 - val_accuracy: 0.6929\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.1379 - accuracy: 0.9689 - val_loss: 1.0380 - val_accuracy: 0.6976\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.1642 - accuracy: 0.9515 - val_loss: 1.0285 - val_accuracy: 0.7012\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1463 - accuracy: 0.9577 - val_loss: 1.0191 - val_accuracy: 0.7036\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1428 - accuracy: 0.9566 - val_loss: 1.0099 - val_accuracy: 0.7048\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1737 - accuracy: 0.9556 - val_loss: 1.0009 - val_accuracy: 0.7060\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1457 - accuracy: 0.9628 - val_loss: 0.9918 - val_accuracy: 0.7095\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1753 - accuracy: 0.9510 - val_loss: 0.9830 - val_accuracy: 0.7131\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1520 - accuracy: 0.9638 - val_loss: 0.9742 - val_accuracy: 0.7143\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1636 - accuracy: 0.9536 - val_loss: 0.9652 - val_accuracy: 0.7167\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.1693 - accuracy: 0.9495 - val_loss: 0.9563 - val_accuracy: 0.7167\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1539 - accuracy: 0.9602 - val_loss: 0.9475 - val_accuracy: 0.7167\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1463 - accuracy: 0.9622 - val_loss: 0.9389 - val_accuracy: 0.7202\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1573 - accuracy: 0.9551 - val_loss: 0.9302 - val_accuracy: 0.7214\n",
      "Epoch 458/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1661 - accuracy: 0.9577 - val_loss: 0.9216 - val_accuracy: 0.7262\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1531 - accuracy: 0.9592 - val_loss: 0.9131 - val_accuracy: 0.7310\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1696 - accuracy: 0.9551 - val_loss: 0.9047 - val_accuracy: 0.7345\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.1480 - accuracy: 0.9597 - val_loss: 0.8964 - val_accuracy: 0.7345\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1677 - accuracy: 0.9566 - val_loss: 0.8880 - val_accuracy: 0.7369\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1684 - accuracy: 0.9520 - val_loss: 0.8795 - val_accuracy: 0.7393\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1549 - accuracy: 0.9602 - val_loss: 0.8712 - val_accuracy: 0.7417\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1654 - accuracy: 0.9561 - val_loss: 0.8629 - val_accuracy: 0.7476\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.1484 - accuracy: 0.9633 - val_loss: 0.8549 - val_accuracy: 0.7488\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1474 - accuracy: 0.9597 - val_loss: 0.8470 - val_accuracy: 0.7488\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1480 - accuracy: 0.9653 - val_loss: 0.8391 - val_accuracy: 0.7512\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1566 - accuracy: 0.9577 - val_loss: 0.8313 - val_accuracy: 0.7560\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1496 - accuracy: 0.9622 - val_loss: 0.8236 - val_accuracy: 0.7583\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1549 - accuracy: 0.9582 - val_loss: 0.8157 - val_accuracy: 0.7607\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1582 - accuracy: 0.9577 - val_loss: 0.8081 - val_accuracy: 0.7607\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.1595 - accuracy: 0.9541 - val_loss: 0.8005 - val_accuracy: 0.7631\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1469 - accuracy: 0.9602 - val_loss: 0.7931 - val_accuracy: 0.7655\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.1490 - accuracy: 0.9612 - val_loss: 0.7856 - val_accuracy: 0.7679\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1442 - accuracy: 0.9617 - val_loss: 0.7781 - val_accuracy: 0.7714\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1486 - accuracy: 0.9633 - val_loss: 0.7708 - val_accuracy: 0.7738\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1450 - accuracy: 0.9602 - val_loss: 0.7634 - val_accuracy: 0.7750\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1511 - accuracy: 0.9612 - val_loss: 0.7562 - val_accuracy: 0.7762\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1535 - accuracy: 0.9628 - val_loss: 0.7492 - val_accuracy: 0.7774\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.1528 - accuracy: 0.9587 - val_loss: 0.7423 - val_accuracy: 0.7786\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1392 - accuracy: 0.9653 - val_loss: 0.7354 - val_accuracy: 0.7810\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1352 - accuracy: 0.9668 - val_loss: 0.7285 - val_accuracy: 0.7845\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.1633 - accuracy: 0.9561 - val_loss: 0.7219 - val_accuracy: 0.7869\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1541 - accuracy: 0.9536 - val_loss: 0.7152 - val_accuracy: 0.7893\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1569 - accuracy: 0.9582 - val_loss: 0.7088 - val_accuracy: 0.7917\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.1637 - accuracy: 0.9582 - val_loss: 0.7024 - val_accuracy: 0.7940\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1652 - accuracy: 0.9515 - val_loss: 0.6959 - val_accuracy: 0.7940\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1488 - accuracy: 0.9561 - val_loss: 0.6893 - val_accuracy: 0.7952\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1474 - accuracy: 0.9597 - val_loss: 0.6830 - val_accuracy: 0.7964\n",
      "Epoch 491/600\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.1500 - accuracy: 0.9617 - val_loss: 0.6769 - val_accuracy: 0.7976\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1603 - accuracy: 0.9622 - val_loss: 0.6706 - val_accuracy: 0.7976\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1547 - accuracy: 0.9592 - val_loss: 0.6643 - val_accuracy: 0.8000\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.1701 - accuracy: 0.9556 - val_loss: 0.6582 - val_accuracy: 0.8000\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1605 - accuracy: 0.9597 - val_loss: 0.6521 - val_accuracy: 0.8000\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1599 - accuracy: 0.9592 - val_loss: 0.6461 - val_accuracy: 0.8036\n",
      "Epoch 497/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1465 - accuracy: 0.9597 - val_loss: 0.6402 - val_accuracy: 0.8060\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1632 - accuracy: 0.9577 - val_loss: 0.6342 - val_accuracy: 0.8095\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1571 - accuracy: 0.9582 - val_loss: 0.6285 - val_accuracy: 0.8107\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1601 - accuracy: 0.9566 - val_loss: 0.6227 - val_accuracy: 0.8131\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.1682 - accuracy: 0.9556 - val_loss: 0.6170 - val_accuracy: 0.8131\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1528 - accuracy: 0.9612 - val_loss: 0.6114 - val_accuracy: 0.8143\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1530 - accuracy: 0.9582 - val_loss: 0.6057 - val_accuracy: 0.8143\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1588 - accuracy: 0.9587 - val_loss: 0.6001 - val_accuracy: 0.8143\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1346 - accuracy: 0.9673 - val_loss: 0.5946 - val_accuracy: 0.8155\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.1546 - accuracy: 0.9546 - val_loss: 0.5892 - val_accuracy: 0.8179\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.1636 - accuracy: 0.9490 - val_loss: 0.5838 - val_accuracy: 0.8179\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.1547 - accuracy: 0.9612 - val_loss: 0.5786 - val_accuracy: 0.8202\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1598 - accuracy: 0.9612 - val_loss: 0.5734 - val_accuracy: 0.8202\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.1771 - accuracy: 0.9510 - val_loss: 0.5682 - val_accuracy: 0.8238\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1581 - accuracy: 0.9582 - val_loss: 0.5631 - val_accuracy: 0.8250\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1477 - accuracy: 0.9592 - val_loss: 0.5581 - val_accuracy: 0.8262\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1570 - accuracy: 0.9607 - val_loss: 0.5531 - val_accuracy: 0.8310\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.1540 - accuracy: 0.9592 - val_loss: 0.5480 - val_accuracy: 0.8310\n",
      "Epoch 515/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1582 - accuracy: 0.9546 - val_loss: 0.5430 - val_accuracy: 0.8310\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1616 - accuracy: 0.9582 - val_loss: 0.5381 - val_accuracy: 0.8345\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1489 - accuracy: 0.9577 - val_loss: 0.5334 - val_accuracy: 0.8369\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1534 - accuracy: 0.9628 - val_loss: 0.5286 - val_accuracy: 0.8381\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1690 - accuracy: 0.9541 - val_loss: 0.5239 - val_accuracy: 0.8381\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1606 - accuracy: 0.9515 - val_loss: 0.5194 - val_accuracy: 0.8381\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1639 - accuracy: 0.9536 - val_loss: 0.5146 - val_accuracy: 0.8405\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1546 - accuracy: 0.9602 - val_loss: 0.5099 - val_accuracy: 0.8417\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1509 - accuracy: 0.9561 - val_loss: 0.5053 - val_accuracy: 0.8417\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1394 - accuracy: 0.9668 - val_loss: 0.5009 - val_accuracy: 0.8429\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1623 - accuracy: 0.9536 - val_loss: 0.4964 - val_accuracy: 0.8440\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1747 - accuracy: 0.9520 - val_loss: 0.4920 - val_accuracy: 0.8476\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1627 - accuracy: 0.9546 - val_loss: 0.4878 - val_accuracy: 0.8488\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.1523 - accuracy: 0.9551 - val_loss: 0.4835 - val_accuracy: 0.8500\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1536 - accuracy: 0.9536 - val_loss: 0.4794 - val_accuracy: 0.8500\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1575 - accuracy: 0.9526 - val_loss: 0.4753 - val_accuracy: 0.8524\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1560 - accuracy: 0.9551 - val_loss: 0.4710 - val_accuracy: 0.8536\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1428 - accuracy: 0.9643 - val_loss: 0.4670 - val_accuracy: 0.8536\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1417 - accuracy: 0.9617 - val_loss: 0.4630 - val_accuracy: 0.8583\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1532 - accuracy: 0.9612 - val_loss: 0.4590 - val_accuracy: 0.8583\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1506 - accuracy: 0.9602 - val_loss: 0.4551 - val_accuracy: 0.8595\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.1413 - accuracy: 0.9633 - val_loss: 0.4513 - val_accuracy: 0.8607\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1679 - accuracy: 0.9515 - val_loss: 0.4475 - val_accuracy: 0.8607\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1603 - accuracy: 0.9628 - val_loss: 0.4438 - val_accuracy: 0.8619\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1469 - accuracy: 0.9561 - val_loss: 0.4401 - val_accuracy: 0.8631\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1622 - accuracy: 0.9587 - val_loss: 0.4366 - val_accuracy: 0.8643\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.1644 - accuracy: 0.9556 - val_loss: 0.4330 - val_accuracy: 0.8667\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1569 - accuracy: 0.9577 - val_loss: 0.4296 - val_accuracy: 0.8667\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1533 - accuracy: 0.9566 - val_loss: 0.4262 - val_accuracy: 0.8667\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1657 - accuracy: 0.9556 - val_loss: 0.4229 - val_accuracy: 0.8690\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.1608 - accuracy: 0.9531 - val_loss: 0.4196 - val_accuracy: 0.8702\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.1651 - accuracy: 0.9556 - val_loss: 0.4163 - val_accuracy: 0.8702\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.1534 - accuracy: 0.9561 - val_loss: 0.4130 - val_accuracy: 0.8702\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1568 - accuracy: 0.9505 - val_loss: 0.4098 - val_accuracy: 0.8714\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.1547 - accuracy: 0.9602 - val_loss: 0.4066 - val_accuracy: 0.8726\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1484 - accuracy: 0.9628 - val_loss: 0.4035 - val_accuracy: 0.8750\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1701 - accuracy: 0.9520 - val_loss: 0.4004 - val_accuracy: 0.8774\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1603 - accuracy: 0.9577 - val_loss: 0.3974 - val_accuracy: 0.8786\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1693 - accuracy: 0.9536 - val_loss: 0.3944 - val_accuracy: 0.8786\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1532 - accuracy: 0.9592 - val_loss: 0.3915 - val_accuracy: 0.8798\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1488 - accuracy: 0.9628 - val_loss: 0.3886 - val_accuracy: 0.8798\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1685 - accuracy: 0.9520 - val_loss: 0.3856 - val_accuracy: 0.8798\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1546 - accuracy: 0.9602 - val_loss: 0.3828 - val_accuracy: 0.8821\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1514 - accuracy: 0.9602 - val_loss: 0.3799 - val_accuracy: 0.8821\n",
      "Epoch 559/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1451 - accuracy: 0.9582 - val_loss: 0.3771 - val_accuracy: 0.8833\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1586 - accuracy: 0.9592 - val_loss: 0.3743 - val_accuracy: 0.8857\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1515 - accuracy: 0.9622 - val_loss: 0.3716 - val_accuracy: 0.8869\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1679 - accuracy: 0.9515 - val_loss: 0.3688 - val_accuracy: 0.8881\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1456 - accuracy: 0.9607 - val_loss: 0.3661 - val_accuracy: 0.8881\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1600 - accuracy: 0.9531 - val_loss: 0.3635 - val_accuracy: 0.8881\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1394 - accuracy: 0.9658 - val_loss: 0.3609 - val_accuracy: 0.8881\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1460 - accuracy: 0.9648 - val_loss: 0.3583 - val_accuracy: 0.8881\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1549 - accuracy: 0.9612 - val_loss: 0.3558 - val_accuracy: 0.8893\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1664 - accuracy: 0.9551 - val_loss: 0.3533 - val_accuracy: 0.8917\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1506 - accuracy: 0.9582 - val_loss: 0.3508 - val_accuracy: 0.8917\n",
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.1741 - accuracy: 0.9485 - val_loss: 0.3484 - val_accuracy: 0.8917\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1477 - accuracy: 0.9577 - val_loss: 0.3460 - val_accuracy: 0.8917\n",
      "Epoch 572/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1607 - accuracy: 0.9505 - val_loss: 0.3436 - val_accuracy: 0.8929\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1705 - accuracy: 0.9561 - val_loss: 0.3413 - val_accuracy: 0.8929\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1582 - accuracy: 0.9566 - val_loss: 0.3390 - val_accuracy: 0.8929\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1470 - accuracy: 0.9622 - val_loss: 0.3367 - val_accuracy: 0.8940\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1421 - accuracy: 0.9638 - val_loss: 0.3345 - val_accuracy: 0.8964\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1456 - accuracy: 0.9612 - val_loss: 0.3323 - val_accuracy: 0.8976\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1443 - accuracy: 0.9628 - val_loss: 0.3300 - val_accuracy: 0.8988\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.1679 - accuracy: 0.9505 - val_loss: 0.3278 - val_accuracy: 0.8988\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.1621 - accuracy: 0.9566 - val_loss: 0.3255 - val_accuracy: 0.8988\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1495 - accuracy: 0.9582 - val_loss: 0.3234 - val_accuracy: 0.9000\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.1453 - accuracy: 0.9587 - val_loss: 0.3214 - val_accuracy: 0.9012\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1480 - accuracy: 0.9612 - val_loss: 0.3193 - val_accuracy: 0.9024\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.1501 - accuracy: 0.9577 - val_loss: 0.3174 - val_accuracy: 0.9024\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.1492 - accuracy: 0.9607 - val_loss: 0.3154 - val_accuracy: 0.9036\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.1639 - accuracy: 0.9515 - val_loss: 0.3135 - val_accuracy: 0.9036\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.1387 - accuracy: 0.9638 - val_loss: 0.3116 - val_accuracy: 0.9048\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1656 - accuracy: 0.9556 - val_loss: 0.3097 - val_accuracy: 0.9060\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.1451 - accuracy: 0.9628 - val_loss: 0.3078 - val_accuracy: 0.9107\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.1565 - accuracy: 0.9556 - val_loss: 0.3060 - val_accuracy: 0.9119\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1495 - accuracy: 0.9597 - val_loss: 0.3041 - val_accuracy: 0.9119\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.1577 - accuracy: 0.9612 - val_loss: 0.3023 - val_accuracy: 0.9119\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.1545 - accuracy: 0.9571 - val_loss: 0.3004 - val_accuracy: 0.9119\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.1414 - accuracy: 0.9633 - val_loss: 0.2987 - val_accuracy: 0.9131\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.1405 - accuracy: 0.9622 - val_loss: 0.2969 - val_accuracy: 0.9131\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.1621 - accuracy: 0.9541 - val_loss: 0.2952 - val_accuracy: 0.9131\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1605 - accuracy: 0.9526 - val_loss: 0.2935 - val_accuracy: 0.9143\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1530 - accuracy: 0.9582 - val_loss: 0.2918 - val_accuracy: 0.9143\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.1667 - accuracy: 0.9571 - val_loss: 0.2900 - val_accuracy: 0.9167\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1614 - accuracy: 0.9571 - val_loss: 0.2883 - val_accuracy: 0.9179\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=keras.optimizers.Adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DD_Net.save(\"DD_Net.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "ZMaN39njeAmT",
    "outputId": "a4a76006-e8df-4fa1-dacb-c515372ba499"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA+1klEQVR4nO3dd3iUVdr48e+dXkkICS0BQq8qSBMVCwgC6toLVlz72lh/6tp21dfV13Vd313Lioq9sSIWRFRsgC6igCC9t4QA6Y30zPn9cSZhEgIkkMkzk7k/15WLeco8cx8Icz/nnOecI8YYlFJKBa4gpwNQSinlLE0ESikV4DQRKKVUgNNEoJRSAU4TgVJKBThNBEopFeA0EaiAISKpImJEJKQR504RkR9bIi6lnKaJQPkkEdkuIhUiklhv/wr3l3mqQ6Ep1epoIlC+bBswuWZDRI4BIp0Lxzc0pkajVFNoIlC+7G3gao/ta4C3PE8QkTgReUtEskRkh4g8JCJB7mPBIvK0iGSLyFbgrAbe+6qI7BaRXSLyVxEJbkxgIjJTRPaISIGILBSRgR7HIkXkH+54CkTkRxGJdB87WUQWiUi+iKSJyBT3/vkicr3HNeo0TblrQbeKyCZgk3vfv9zXKBSRZSIy2uP8YBF5QES2iEiR+3gXEXlBRP5RryyficjUxpRbtU6aCJQvWwy0EZH+7i/oS4F36p3zHBAH9ABOxSaOa93HbgDOBoYAw4CL6r33TaAK6OU+ZzxwPY3zBdAbaA/8CrzrcexpYChwIpAA3Au4RKSr+33PAUnAYGBFIz8P4DxgJDDAvb3EfY0E4D1gpohEuI/dha1NTQLaAL8HSrBlnuyRLBOBscD7TYhDtTbGGP3RH5/7AbYDZwAPAf8LTAC+BkIAA6QCwUA5MMDjfTcB892vvwNu9jg23v3eEKCD+72RHscnA9+7X08BfmxkrPHu68Zhb65KgeMaOO9+4OODXGM+cL3Hdp3Pd19/zGHiyKv5XGADcO5BzlsHjHO/vg2Y6/S/t/44+6NtjcrXvQ0sBLpTr1kISATCgB0e+3YAye7XnYG0esdqdANCgd0iUrMvqN75DXLXTh4HLsbe2bs84gkHIoAtDby1y0H2N1ad2ETk/2FrMJ2xiaKNO4bDfdabwJXYxHol8K+jiEm1Ato0pHyaMWYHttN4EvBRvcPZQCX2S71GV2CX+/Vu7Bei57EaadgaQaIxJt7908YYM5DDuxw4F1tjicPWTgDEHVMZ0LOB96UdZD/APiDKY7tjA+fUThXs7g/4E3AJ0NYYEw8UuGM43Ge9A5wrIscB/YFPDnKeChCaCJQ/uA7bLLLPc6cxphr4AHhcRGJFpBu2bbymH+ED4A4RSRGRtsB9Hu/dDcwD/iEibUQkSER6isipjYgnFptEcrBf3k94XNcFvAY8IyKd3Z22o0QkHNuPcIaIXCIiISLSTkQGu9+6ArhARKJEpJe7zIeLoQrIAkJE5C/YGkGN6cBjItJbrGNFpJ07xnRs/8LbwCxjTGkjyqxaMU0EyucZY7YYY5Ye5PDt2LvprcCP2E7T19zHXgG+An7DdujWr1FcjW1aWottX/8Q6NSIkN7CNjPtcr93cb3jdwOrsF+2ucDfgCBjzE5szeb/ufevAI5zv+f/gApgL7bp5l0O7Stsx/NGdyxl1G06egabCOcBhcCr1H309k3gGGwyUAFOjNGFaZQKNCJyCrbmlOquxagApjUCpQKMiIQCdwLTNQko0ESgVEARkf5APrYJ7J+OBqN8hjYNKaVUgNMagVJKBTivDSgTkdeww/szjTGDGjgu2IEsk7BD36cYY3493HUTExNNampqM0erlFKt27Jly7KNMUkNHfPmyOI3gOc5cDRojYnYuVp6Y+dPedH95yGlpqaydOnBniRUSinVEBHZcbBjXmsaMsYsxD4rfTDnAm8ZazEQLyKNeYZbKaVUM3KyjyCZugNg0tk/R0wdInKjiCwVkaVZWVktEpxSSgUKJxOBNLCvwUeYjDEvG2OGGWOGJSU12MSllFLqCDk5+2g6dScESwEyjuRClZWVpKenU1ZW1iyB+bKIiAhSUlIIDQ11OhSlVCvhZCKYDdwmIjOwncQF7onAmiw9PZ3Y2FhSU1PxmFK41THGkJOTQ3p6Ot27d3c6HKVUK+HNx0ffB04DEkUkHXgYO/87xphpwFzso6ObsY+PXtvwlQ6vrKys1ScBABGhXbt2aD+JUqo5eS0RGGMmH+a4AW5trs9r7UmgRqCUUynVcnRksfJpmzOLqKzWedF8WVOmqVmRls+yHYd6qtx7n523r6LZPre10UTQDHJychg8eDCDBw+mY8eOJCcn125XVBz6l2/p0qXccccdLRTp0duWvY+yyuoD9ldVu3C5mjZvlTGG8qpqSisOvJ4xhrUZhZzxzEKmzd9Su6+orPKAcyuqXGzOLKqzr6iskvkbMhv8oli6PZdlO/IOG19WUTmFZZXszCk5ILbpP2xlTUYB+SX237eq2sUPm7J47ttNVLv/HlalF3DF9MW15+zMKeHyVxazu+Dw68D8si2XgtK6ZZ22YAu9H5xLVlE5X6/dy6crdh3k3XVjPZy1GYV8vyGzzntq/i3z9lUc8t/1gY9XMeyv37A1q5iHPlnFB0vTaq+xfk9hndebM4s574X/cuGLP9Vee8HGLCqrXQ3GuW53Ifd/tJLf0vJr9xWUVrJxbxH5JRVMnbGcEU98S6HH70TVQa71w6Yshjz2Nf/dnH3AsfKq6trfqz9/sppjHv6q9lhmYRlzV+2mrLKajXuLKCg58PfPGENOcTkAxeVVtf8/ql12PeAX52/h1vd+rf09APs7+/XavewpqPuAS2ZRGct25NX+22/JKm7wM5ub3006N2zYMFN/ZPG6devo37+/QxHV9cgjjxATE8Pdd99du6+qqoqQkOZrhfNmeedvyGRQchyJMeEHHMvbV8GQx77m8pFdeeL8Y/jPkp28vXgHD0zqz41vLaO4vIqh3dpy6+k96RQXyRNz13H3+L6s2lVAbEQIufsqOKlXIp8s38V/lqSR475D65oQxfOXDyE0OIj+newiW/fM/I2Zy9JrP3tot7aEBQexOqOARfeNITYiFGMMG/cW88ai7bz/y06mXz2M+Rsz6RQXybuLd5BRUEb72HD+59yB9GofwxXTf+b1KSOY9OwPAGx5YhIuY6isdlFZbViwMYu1GYXsK6/iw2XpVFS7ar/Utzwxid0FpaxKLyA2IpQrX/25NrbJI7ry/i87a7c/+sOJFJZWMuX1JQCIwGvXDOf295dTXF4FwI9/Op28fZWsSM/nlN6JdGsXzeKtOezMLeG4lHjO/OdCwoKDeOjs/pzcK5HYiFCGP/7NAf8md47tTWRYMP/+fjOj+ySxaW8Ro3snsaewjKXbc5kwsCN/OL0Xy3fmMbRbAkmx4bhchqAgodpl+GL1bm57bzkA/7nxBOZvzOLF+VvoFBfBc5OHcNG0n0iMCeMflwwmv6SCVekFHJMSx6RjOjHumQVsr5ckAe4Y25sFG7P4LS2fiNAgrhmVyksLt9Y5Z9YtJ3Lhi4sAGNCpDWm5JdwzoS9xkaFEh4Xw7frMOn+n95zZl/LKal7+YStllXVriP+6bDDDUxNYsDGLRz9bw7BuCYzunUh4SBCn9Eni85W7+cfXGwGICgume2I014xKZemOXCYe04lHZq8hu6icN38/goum2ST121/GExcVys1vL+PLNXvqfN5HfziRY5PjCAm299H3fvgbHyxNZ94fT2H8/y10/0504eu1mWS7EwTAOcd15skLjiEqLJi7Z65k1q/29/vfVxzPlsxiXl64lSL37wdAj8RotmbvIyY8hO/vPo24yFDCQo783l1ElhljhjV4TBNB86pJBKtXryYhIYHly5dz/PHHc+mllzJ16lRKS0uJjIzk9ddfp2/fvsyfP5+nn36aOXPm8Mgjj7Bz5062bt3Kzp07mTp1aoO1heYsrzEGEeHprzbw/Peba/d/fsfJfLoig5lL0xjRPYHxAzoyc1kai7fm0ikugt4dYlm4seFO61P7JOEyhh82HXj3dTiPnTeIfh1judj9H7IhHdqEk9oummqXYelB7uyjwoIxBkorqwkSuGF0jwO+jMLd/6nKq7zT9CQCjf3v9e71I7liuk0ulwxL4YOl6Yd5R9MFBwld2kaSkV/GXeP78OQX64/4WiltI0nPa/kVLk/ulcjewjI2ZRZ79XOuPSmVvh1ieXreBrKLG67Vj+yeQHR4CN+tz2zw+OHER4WS38S7/TvG9OKu8X2P6PMOlQicfHzUKx79bA1rMwqb9ZoDOrfh4XMas6Z5XRs3buSbb74hODiYwsJCFi5cSEhICN988w0PPPAAs2bNOuA969ev5/vvv6eoqIi+fftyyy23NMuYgU9X7KJNRCi/peeTXVzOuYPtIO7fv76EqeP6MHNZWp3zz3r2x9rXX63Zy1dr9tZu7y4oY3e9Km1YcBD/umwwL/+wlQUeCaJNRAglFdVUHaR5YfuTZ/HBkjTunbUSsFXzgxncJZ4uCVF89lsGewvtndbAzm1Yk1HI4C7xrPBoQrj2pFTuHNuHuz5YwZyVuw9IAtBwAph586jaJDSqRzsuG9GFO2esOOC8l64aylNfrmdLll1GuVu7KHblldaWc2i3trx6zTB+2pLDLe/auRRvPKUHV4zsyql/n3/A9WqSAMAHS9MZntqWnkkxzFhS99/lplN78NaiHUw8piMf/bqLvh1iGZbalvzSSj5faZ++Xv/YBFbtKmDxlpzaO+HzBncmuW0kWzL3sT2n5IAkcPWobsSEh1BYVklkaDDVLnjtv9sACBI70rMmqZ0/JJmPl9tmqcfOHUjfjm246e2l9O0YS1hIMP06xvLJ8l1kFtl/o7H92hMWEsQXq/fQp0MMG/c2/CWeHB9JXkkFJe6mwvOHJHP/xH4sT8vn5YVbWbYjj+cvH0J8VBgul2FPYRl3z/yNRVtyaq/xy4NjefqrDXSOj+SkXonM35DJj5uyuXxkV95YtIN1u/d/N7x3w0huensZPZJi6jQ/Abz+3+21r5+++DhG905k5BPf1u4b2LkNP287eF/HH07ryebMYuattf9vpp7Rm39+s6n2eFhwEF//8dTaWt7TFx/Hut2FvPqj/TsXgfsn9iMsOIhHPlsL2CQ4uGv8QT/zaLS6ROBLLr74YoKDgwEoKCjgmmuuYdOmTYgIlZUN3wmcddZZhIeHEx4eTvv27dm7dy8pKSlH9PmFZZW8OH8LewrKav/j1nhn8f5q92Nz1tY59ofTehIaHMSu/FI+dDfPJMdHsit//x1gSJDQMymG+yb148Ol6Vw6vAun9EmirKqa5TvzAXj7uhGM7N4OlzHcOWM5X63ZS4+kaN68dgQLNmbhcn+zXDK8Cwjc+6FNBleM7ErbqDCe/34zV57QlYSoMC4Z3oWUtlEYY3jorP6MfOJbRvVox8tXD2Xp9jxO65tEaWU1D3+6hpnL0pkwsBNhIUH87cJjiY0I4f1f7BfqO9eNZHdBKfd8uJKpZ/TmjjG9mb8xk/JKFwWllQxPTWDz4xN55uuNXD6yK53iIlm4MZuC0gqMgdDgIG4b04tByXGcObAjm/YWsSOnhIHJbUiKCWd5Wj4dYiPo2i4KgInHdKpt1npgkq3FfTl1NFXVhvCQILKKy5m1bBdzV+2m2hj+fPYA5vyWwZ/PHsCg5DhG9WzHywu3siajkKHd2nLfhH7cNa4P4SHB3D+xP20iQwgPCSazsKw2EUSEBjM8NYEeidEUlFbyx3F9iA7f/189s7CM+RuyaBMZSp8OMSzYmMVFQ1OIjdh/w2GMITUxivEDOtIxLoLcfRUc/9jXJMdH8tBZ/fl4+S5O7ZPEVaNSAVj+l/F1fofuHt+XDXuKiAoPpmdSDEu35/LF6j08eNYAPliaxkNn9Wfuqj38Z8lONu4t5l+XDa69OVm8NYfVuwq4fnQPAM4c2JGx/dqTXVxBfFQYAEFBQuf4SF6bMpztOfuYvSKDPh1iaR8bwVMXHVcbx/DUBO45074WhHtnreS4lDiGpyZwYs9Efv3zOEKDg3j/l52s3lXAn88ewLfrMtmcWcyQrvHsyi/lwuOTERGmnJjKmQM7MqpnOwAWbc5m/Z4iXv1xG1eN6kZ0WDAjurdj1q/p3DG2N4VllQQHCaN7J3HZ8C70ah9T2wz3/o0nkBQbzl3j+rBgYxYXHp9MlaszBaWVXHdy99omUoDju7Vlw54iLh7mOf62eWnTUDPzbBo6++yzueiiiwCYMmUKxx9/PHfccQfbt2/ntNNOY/v27Qc0DXn2LwwaNIg5c+ZQf9rtg5V36fZc5qzczZCu8Tw8e02Tq533TuhL+9gILhpqE095VTX3f7SKm07pSd+OsXy3fi9dE6LYXVDG6N4NT/VhjCEtt5TCskoGJcfV7s8vqeDf87dw17g+RIQGH/C+8qpqnpm3ketH9yAp1vZPrN5VQN+OsYQGH9guun5PIV3aRtX5ggOorHaxfncRx6TE1dn/wvebSYoN55JhXaisdvH2Tzu4fGTXBmNpbgWl9gshJvzg910VVS7KqqppE9Fw7e+DpWmc3CuRzvGRDR4HOOvZHxg3oANTz+hz1DE3ZNaydEZ0T6BLQhSb9hbRIS7ioPE2pLLa1eC/ZUZ+KZ3iIrz+aLQxhhVp+QzuEu/IY9gul+HLNXsYP6BDbf9CSwqopiFfVVBQQHKyveN54403jvg6FVXVlFZWU+0yFJZWcvv7yxmUHMc1J3ar7eh6Y1HD733xiuNrmylqnNSrHYM6x3HOcZ3rfHEDhIcE88wlg2u3x/TrAECv9rEHjU9Eau+GPcVHhdXeETckPCSY++sdrx+Pp34d2zS4PzQ46IAkAHDr6b3qnPP7k1tuZHZc5OG/LMNCgg7ZEXhJI+4GP79jdJPiaqoLh+6vmfbucPDfgYNpKAkAh0xuzUlEGNK1bYt8VkOCgoRJx/jmBMuaCFrIvffeyzXXXMMzzzzDmDFjjvg627L3kVNcwWNz1vLGou0A/Lg5m2kLtjR4/jvXjSQ9r4R2MeGMG9CBl68ayo1vL+O9G0YyIjUBESE4SAepKRXItGnIT1RVu9hTWEbuvgr27tzKDbPrTssUHRbM7WN7k19SybQFW5hx4wn07RBL2+iwA661t7CMDm0iWip0pZQP0KYhP2eMYWduSe0z6DVqnsB4+7oR9OkQS4c2ERhjmHJiKh3jDv5Fr0lAKeVJE4GPq6hykV9aQXF5FZFhwZRWVNMmMoS3rxvBqB7tyC2poH3s/i92ETlkElBK+SGXC1bPgvb9oeMBS8AfNU0EPszl2j9MP1iEnokxiMD6olD6u5/a8UwCSqlWoqwQyosgcy3kbYcV70HGrzDiJpj0VLN/nCYCH+JyGQx2BGhOcTkZHoO2QoKFIO3UVar1+20GfHobuDwe/45KhPGPwwl/8MpHaiLwIVuyiymtqKZX+xh2F5TVmTzLieeOlVItqHA3bJ0P8x6CpH4w/DqIaQ/tB0B8Vwjy3pgXTQQ+orC0snYWzs2ZxYjYkbuRocFkFpWTEK1LUyrVqhgDGctt08+iZ+1rgLbd4fxpXukLOBhNBM0gJyeHsWPHArBnzx6Cg4NJSrJt+L/88gthYQc+wulp3jffsqe4isHDRgIQGRpMSttIIsPsP492/irVyhSkw8wpkG5nqCW+K5z+IHQ/BZKHQnDL3vhpImgG7dq1Y8WKFUDD01AfzpyvviU0PJJzxp1OXFQoQboKmVKtS94O+O4xKM23nb4luRAWA2c9Ax0GQufjIeTQN4zepInAS5YtW8Zdd91FcXExiYmJvPHGG3Tq1Ilnn32WadOmERISwoABA3jiif/lvTdfJTQkmG/nzOK5555j9GjvThWglPKyylJY+Hf7tE9VOZQX2qagDgMh9WRo1wuOvQySvDMvVFO1vkTwxX2wZ1XzXrPjMTDxyUafbozh9ttv59NPPyUpKYn//Oc/PPjgg7z22ms8+eSTbNu2jfDwcPZm5bC3PJiLr7yW5KS2PHT/n5o3bqVUyyrOhNUfwYp37PdQ37OgTWcICYehUyCxt9MRNqj1JQIfUF5ezurVqxk3bhwA1dXVdOpkJ5saOOgYLpt8ORdecD4njZkA2AVSwo9i5SGllIOMgcX/hl9eth2/AG2S4aLXYNCFjobWWK0vETThzt1bjDEMHDiQn346cJWtp155j2U/L+Lb777iz488ytwFvxAfFebItLhKqaPgqrZNPgufhp+ehy4nwJArIbEv9Dsbgvzn5q71JQIfEB4eTlZWFj/99BOjRo2isrKSjRs30rN3X/Zk7GLEiaMZMvwEZs/6gKCqcmJjYyksbN5V1ZRSXpK7DTZ/A/OfhBL3cqxDr7Udv3705e9JE4EXBAUF8eGHH3LHHXdQUFBAVVUVU6dOpX1KKg/ceSPFhUUY4+LK62+hS6dEzjnnHC666CI+/fRT7SxWyldVlsHSV+Hrh+2o3w6DYNSttvO3ywinozsqOg11CzHGkJFfRl5JBQM7t2FvYTkGQ6e4pi/K4Q/lVarVWPsprJoJG74AVxV0PxVOuhO6nQihLbOoTnPQaah9wMa9RZRXuYgJD9EZQpXyB9WVdsTvt/9jt4ddBwPPs4O+WhlNBC2kvMoFcMAau0opH1NdZWsAi56DzDUQmQC3L4OoBKcj85pW861kjPHZJ288m9+OdrF0f2vKU8qvuFww+3b47T2I7Ww7gI+bDGEHrsPdmrSKRBAREUFOTg7t2rXzyWSwI6cEsEmgTcSR/5UbY8jJySEiQpuVlGo2xkBZvn0KaN1nULjL9gGc8Sj44PeJN7SKRJCSkkJ6ejpZWVlOh3KAiioXmUXlALSLDmN97tHVCCIiIkhJSWmO0JRS+Wkw43LYs9Ju9xoH4/4HBl4QMEkAWkkiCA0NpXv37k6HcYC03BJm/5bB37/aDsDb143gePfKYkopB1VX2UdBf30L8nfCafdDyjDodYbTkTmiVSQCX7Q2o5BJz/5Quz2iewKDu8Q7F5BSar+lr8IX90JIJFw4Hfqf7XREjtJE4CVvLtpeZ/uDm0Y5E4hSar+qCvjkZrsQfJeRcO0XXl35y1/453hoP7BgYxa92sc4HYZSqsbKmfCvY20SGH4DXD1bk4Cb1giamTEGYyC7uJxzB3dmc2ax0yEpFbhWzoTf3ofsjVCQZh8JPedZOzmcJoFaXk0EIjIB+BcQDEw3xjxZ73gc8A7Q1R3L08aY170Zk7d1v38uk47pSJXLkBQbzr0T+tIzSWsGSrW4z++GJa9AZFvocbpdDP6EWx1dCcxXeS0RiEgw8AIwDkgHlojIbGPMWo/TbgXWGmPOEZEkYIOIvGuMqfBWXN5UVmkXn5+7ag8ACdFhXHC8PuqpVItb+ppNAkOnwKSnW3wNYH/jzRrBCGCzMWYrgIjMAM4FPBOBAWLFjgKLAXKBKi/G5FUZ+aV1tttG652HUi2mugrWz4Hlb8PWBXZMgCaBRvFmIkgG0jy204GR9c55HpgNZACxwKXGGFf9C4nIjcCNAF27dvVKsM0hI7+sznY7TQRKeV9Jrh0P8OubkLsVwuOg31lw1j80CTSSNxNBQ8Py6k+UcyawAhgD9AS+FpEfjDF1VmkxxrwMvAx2GurmD7V57MovqbOdoIlAKe8qyYU3z4G9q6HDMXD+S9BnAkTGOx2ZX/FmIkgHunhsp2Dv/D1dCzxp7Exqm0VkG9AP+MWLcXlFtcvww6ZsIkODWXDPaXy7PpPkeP+Zq1wpv1OaB2+dC9mb4PIPoPf4gJoWojl5cxzBEqC3iHQXkTDgMmwzkKedwFgAEekA9AW2ejEmr3nv5x3MWbmbhOgw2reJYPKIrj45AZ5SrYIx8NlUyFwHl70Hfc7UJHAUvFYjMMZUichtwFfYx0dfM8asEZGb3cenAY8Bb4jIKmxT0p+MMdneismblqflA3DLaT2dDUSp1m7bQvjucUhbDGc8Ar0Dc36g5uTVcQTGmLnA3Hr7pnm8zgDGezOGllBaUc1vafn0bh/DlSd0czocpVqvLx+AxS9AbCc4+5/28VB11HRkcTN48ot1bMnaR7+OsU6HolTrtepDmwSGXQdnPgGhui5Hc9FE0Aw2Z9lpJHL2+eU4OKV8W3UVrHgXPr/LThQ34UkdHdzMNBEcpee/28R/N+cA8OxlQxyORqlWprIU3rsUti2A5KFwxUxNAl6gieAoTVtgH3JKjAlnVM92DkejVCvz9cO2c3jMQ3DCHyAs2umIWiVNBEcpMiyY4vIqCksrnQ5FqdZjXzYs/DssmW5nCj3lHqcjatU0ERylyFA7lW3MUSxKr5SqZ+49sOYjSB1tF5FXXqXfXkepwF0TeO+G+tMoKaWOyM7FsO4zGHkLTHzy8Oero6YrlB2FkooqCkoruXdCX/p1bON0OEr5N5cLFk+Dty+Att1g9F1ORxQwNBEchZrZRjvH6ZxCSh21Za/Dl3+CmPZwzWf2T9UitGnoKOwusOsPdNbJ5ZQ6OpWlsOBv0O0kmPK5zhvUwjQRHKHs4nJmLUsHoFOcjnBU6ogZA9/9FYr3woWvahJwgCaCI/TXOWv5ZIWdVbtDG00ESh2RjfNg+Vu2c7j/7yD1ZKcjCkiaCI5QSYVdn/iRcwYQFqJdLUo12cK/21lEQ8LhmEvsojJaG3CEJoIjVFpZzeAu8Uw5qbvToSjlf3b+bJNAv7Pggpd1xLDD9Fb2CGUVlZMUG+50GEr5F2NgwVPw5tkQlwLnvahJwAdoIjhC2cWaCJRqspUfwPePQ7+z4fdfQYSOv/EF2jR0BEoqqsjZV0FijCYCpRqtugq+e8zOInrhdAgKdjoi5aY1giMwe0UGxsDo3olOh6KU/9jwORSkwcl3aRLwMZoImsgYw1s/7aBfx1iGdWvrdDhK+YeSXPjmEYjvBn0nOh2NqkcTQRNty97H2t2FXDa8C6KPuinVOPMegvydcP40rQ34IO0jaAJjDE9+sR6A0/rqPChKHVLRXpsAsjfAnlV2YZluJzodlWqAJoImyCgoY97avfRMiqZbuyinw1HKdy19HeZMheBw6D4aBpxn+waUT9JE0ATrdxcC8LcLj9VmIaUOZst3Ngl0GQkT/waddS1vX6eJoAnW7ykCoE/HWIcjUcpHbf8R5twFcV3h6tkQqvNw+QNNBE2wPXsf7WPDaRMR6nQoSvmeVR/CrOshKAQmz9Ak4Ec0ETTBrvxSUtrq2gNKHaBiH3w21TYHTX4fohKcjkg1gT4+2gQZ+aW6CI1S9RljJ5CrKIIzHtEk4Ic0ETSSy2XIyC8jWWsESu1XWQr/uRIWvwDDr4euJzgdkToC2jTUSNnF5VRUu0jWGoFS+y18GtbPgbEPw0lTdT0BP6WJoJF25dv1iTURKOWWvxMWv2jHCIzWMQL+TJuGGqkmEWgfgVJuP78E1RUw7n+cjkQdJU0EjZRRUyPQPgKloLIM1nwCPU+Htt2cjkYdJU0EjbQjp4TY8BAdQ6BUaT68diYUpsMJtzgdjWoG2kfQSIu35jBEp51WgS5jBbw+CSr3wTnPQs8xTkekmoFXawQiMkFENojIZhG57yDnnCYiK0RkjYgs8GY8Ryq7uJwtWfs4qWc7p0NRyjlVFfDuxRAZD5fPhKHXOB2RaiZeqxGISDDwAjAOSAeWiMhsY8xaj3PigX8DE4wxO0XEJ+d23p69D9A5hlSAS/8F9mXCpe9An/FOR6Oa0WFrBCJytogcSc1hBLDZGLPVGFMBzADOrXfO5cBHxpidAMaYzCP4HK/bkVMCQLcEnXpaBajN38IHV0NoFHQ/1eloVDNrzBf8ZcAmEXlKRPo34drJQJrHdrp7n6c+QFsRmS8iy0Tk6iZcv8XsyC0hSCClrSYCFYD2rIKPb4KoRJjyOUS0cToi1cwOmwiMMVcCQ4AtwOsi8pOI3Cgih2snaWiIoam3HQIMBc4CzgT+LCJ9DriQ/bylIrI0KyvrcCE3u505++gUF0lYiD5kpQLMhi/h5dPtfEKXvg3JxzsdkfKCRn2zGWMKgVnY5p1OwPnAryJy+yHelg508dhOATIaOOdLY8w+Y0w2sBA4roHPf9kYM8wYMywpKakxITerHbkluiKZCjy/vAIzJkOHgXDrz5DU1+mIlJc0po/gHBH5GPgOCAVGGGMmYr+w7z7EW5cAvUWku4iEYZuYZtc751NgtIiEiEgUMBJYdwTl8KqdOZoIVIDZswq+etD2B1z9KUQnOh2R8qLGPDV0MfB/xpiFnjuNMSUi8vuDvckYUyUitwFfAcHAa8aYNSJys/v4NGPMOhH5ElgJuIDpxpjVR1oYbyguryJnXwVdE6KdDkWplpG9GV6bAGHRcP5L9nFR1ao1JhE8DOyu2RCRSKCDMWa7MebbQ73RGDMXmFtv37R6238H/t7oiFtYVlE5AB3jwh2ORKkW8t1jIMFw3dcQ28HpaFQLaEwfwUzs3XqNave+gJBfUgFAXKROLaECQOFuWP85DLkSEns5HY1qIY1JBCHucQAAuF+HeS8k31JQWglAXGTAFFkFKpcL5j0IxgUjrnc6GtWCGpMIskTkdzUbInIukO29kHzL/kSgNQLVyn3zF1g9C06/HxJ6OB2NakGN6SO4GXhXRJ7Hjg1IA3xy4Jc31CSC+ChNBKoVW/Q8LHoOhl4Lp9zjdDSqhR02ERhjtgAniEgMIMaYIu+H5TvyS7RGoFo5lwsW/xuSh8KEJ52ORjmgUZPOichZwEAgQtxrkhpjAmJZooLSSqLCggkN1lHFqpVa8xEU7oIzHoXQCKejUQ5ozICyacClwO3YpqGLgYBZkmh79j7ax+qjo6qVMgYWPAUdj4VBFzgdjXJIY25zTzTGXA3kGWMeBUZRd+qIVquorJKFm7I4o78+S61aodJ8eONsyN4AI2+CoGCnI1IOaUwiKHP/WSIinYFKoLv3QvIdGfllVFYbBneNdzoUpZpXaT7Mug52/AjHXwPHTXY6IuWgxvQRfOZeQObvwK/YGURf8WZQviJ3nx0+kRClYwhUK1K0xy43mbsFUkfD7551OiLlsEMmAveCNN8aY/KBWSIyB4gwxhS0RHBOqxlV3DZaE4FqRWbfYZPBVZ9A91Ocjkb5gEM2DRljXMA/PLbLAyUJAOS6E0GCJgLVWlTsg63fw9Ap0PN07RdQQOP6COaJyIVS89xoAMlzNw3pYDLVKrhc8MW9UF0BfSc4HY3yIY3pI7gLiAaqRKQM+wipMca0+vXq8koqiQ4LJjxE75pUK7DpK1j+jh05rE1CykNjRhYfbknKViunuFz7B1TrUFkGP/wDIuLh1D85HY3yMYdNBCLS4K1D/YVqWqP0vFJS2kY6HYZSR6eqHD64CtKXwPjHIVibOlVdjWka8pyBKgIYASwDxnglIh+yI7eE0/u2/BrJSjWrNR/DpnnQ4zQ48Tano1E+qDFNQ+d4botIF+Apr0XkI0orqskqKqdrgq5VrPzcpnkQEQdXfuR0JMpHHclMaunAoOYOxNek5ZUA0EUTgfJnu361NYJjL9NHRdVBNaaP4DnsaGKwiWMw8JsXY/IJO3NsItAagfJbVRXw6W0Q0xHGPOh0NMqHNaaPYKnH6yrgfWPMf70Uj8/YmWsTQbd20Q5HotQRWvY6ZK6ByTNs05BSB9GYRPAhUGaMqQYQkWARiTLGlHg3NGftzC0hJjyEtjqYTPmj7E3w3V+h20nQd6LT0Sgf15g+gm8Bz2coI4FvvBOO70jLLaFLQhQBOKBatQbfPWbXGjj/JacjUX6gMYkgwhhTXLPhft3qG8535pbQNUHHECg/tHEerP3UPioaHxBLh6ij1JhEsE9Ejq/ZEJGhQKn3QnKeMcadCFp9vlOtTVkhzJkKSf3g5D86HY3yE43pI5gKzBSRDPd2J+zSla1WVlE55VUuTQTK//zykl1/+PpvIUSXWFWN05gBZUtEpB/QFzvh3HpjTKXXI3PQ3sJyADq00YW8lR+proKlr0OP0yFlmNPRKD/SmMXrbwWijTGrjTGrgBgR+YP3Q3NOfqkuSKP80Ia5tjYw4ganI1F+pjF9BDe4VygDwBiTB7Tq37S8ElvhiY/UR0eVnzAGFr8IcV2gj641oJqmMYkgyHNRGhEJBlr1rXLNEpXxulax8hcbvoCdi+CkO3UqCdVkjeks/gr4QESmYaeauBn4wqtROSxvn7tGoIPJlL9Y9xlEJsCw3zsdifJDjUkEfwJuBG7BdhYvxz451GrllVQQGx5CaPCRzMmnVAvbl2P7B3qdobUBdUQO+03nXsB+MbAVGAaMBdZ5OS5H5ZdUEB+ttQHlB4yBuf/PLko/+i6no1F+6qA1AhHpA1wGTAZygP8AGGNOb5nQnLMjt4TkeB1VrPzAkul2mumxf4EOA52ORvmpQ9UI1mPv/s8xxpxsjHkOqG6ZsJxjjGFzZjG92sc4HYpSh/bLK/DNo3ZiuZO1NqCO3KESwYXAHuB7EXlFRMZi+wgaTUQmiMgGEdksIvcd4rzhIlItIhc15frekFVUTlFZFb2SNBEoH5a3HebeDZ0Hw7kvgE6OqI7CQROBMeZjY8ylQD9gPvBHoIOIvCgi4w93Yfdjpi8AE4EBwGQRGXCQ8/6GfTrJcZsz7fx6vdrHOhyJUofwwzMgQXD+NEjo7nQ0ys81prN4nzHmXWPM2UAKsAI46N29hxHAZmPMVmNMBTADOLeB824HZgGZjY7aizZn1SQCrREoH7X9v/DrmzDqVohLcToa1Qo06flIY0yuMeYlY8yYRpyeDKR5bKe799USkWTgfGDaoS4kIjeKyFIRWZqVldWUkJtsS2YxMeEhdGijE3YpH7XSveLYaQ84HYlqJbz5oHxDjZam3vY/gT/VrH52MMaYl40xw4wxw5KSkporvgZtziqmZ/sYXZBG+SZXNWydD11PhDCdHVc1j8YMKDtS6YDnqhgpQEa9c4YBM9xfuonAJBGpMsZ84sW4DmlzZjEn9/JuslHqiHz/v7D8HShMhzF/djoa1Yp4MxEsAXqLSHdgF3ZMwuWeJxhjanu5ROQNYI6TSaCwrJK9heX0bK8L1isfk7EcFjwJnYfAGQ/DsZc4HZFqRbyWCIwxVSJyG/ZpoGDgNWPMGhG52X38kP0CTtiRXQJAj0TtKFY+5ueXICQSrvoEIuOdjka1Mt6sEWCMmQvMrbevwQRgjJnizVgaI7OoDICOcbogjfIR1VUw8xpYPwdOuFWTgPIKryYCf5NVZFcmS4rVJ4aUj1j+lk0Cp9xjf5TyAk0EHjLdiSAxRtchUD5g8zcw9x7odjKc/qCOHlZeo/Mse8gqKic+KpTwEJ3KVznMVQ1f/AkSesLk9zUJKK/SGoGHrKJyEmO0WUg5rKwQZt8GOZvh4jchoo3TEalWThOBh9ySChJ0wXrlpMz1MP0MqCiC1NHQ/3dOR6QCgCYCD/klFXRP1DEEyiGlefDJzWCqYfIM6DvR6YhUgNA+Ag95JZW01QXrlVNmXW8Hjp33b00CqkVpInAzxlBQUkmcLlivnLB2tn1KaMyfYeD5TkejAowmAreSimoqql1aI1Atb9cyO2gsqZ+dWlqpFqaJwC2/tBKAtlojUC2pshQ+u9NOKz1lLoTqWtmq5WlnsVvevgoA4rVGoFrShrmwZxVc9BpEt3M6GhWgtEbglpFfCkAnnWdItZSCXfDl/RDdHgac53Q0KoBpjcAtLc8mgpS2utiHagEV++xTQmWFcMVMCNLR7Mo5mgjc0vNKiA4L1j4C5X2l+TDjCkhbDBe8At1HOx2RCnCaCNx25pSQ0jZKl6hU3mUMvHUu7F4B4x6DYy5yOiKltI8A7BiClbsKGNBZ53RRXrZpnk0CJ90JJ97udDRKAZoIAMgoKCOrqJwhXeOdDkW1Ztv/a/sF4rvagWNa+1Q+QhMBsCWzGIC+HWIdjkS1Wqs+hHcvhtiOcPlMCNa+KOU7tI8A+HlbDgCd43Uwj/KCzHXw6W2Q2Auu+NAmA6V8SMDXCH7aksML328BoH0bXYtANbPC3fDqePt46EVvaBJQPingawQ1C9YDujKZal4lufDSaCgvhCtm2RqBUj4o4GsE5VUup0NQrZGrGmZcbscMXPgq9D7D6YiUOqiArxEUlNjJ5t67YaTDkahWI3+nHTC2ZyWcN03HCiifF/CJIL+0guAgYVQPnfBLNQNjYN5DkLPFjho+5mKnI1LqsAK+aSi/pJK4yFAdUayax/ePw9pP4eSpcOwlOlZA+YWATwQFpZXER+oz3aoZZG+GH/4Bx02GU+5xOhqlGk0TQakuT6mawdb5MH0shEbDuP/RmoDyKwGfCPJLtEagjtKe1bZzOCQcLpwOMe2djkipJtFEUFqhq5KpI7foOZh2MgSFwHVfQ98JTkekVJPpU0PuzmKlmsQY+OJe+OVlGHAunPV/utSk8lsBnQiqXYaisiritY9ANdXiF20SGDoFJj2tk8gpvxbQiaCw1A4m0z4C1SQ7foKvHoC+Z9maQFDAt7AqPxfQv8H5NYlA+whUYxVmwIzJ0LYbnD9Nk4BqFQK6RpBfUgGgj4+qw3O54Mdn4L//gupK2zEcoSvaqdbBq7czIjJBRDaIyGYRua+B41eIyEr3zyIROc6b8dS3YU8RAF3aRrXkxyp/U5oH714I3z0GqaPhhu8gsbfTUSnVbLxWIxCRYOAFYByQDiwRkdnGmLUep20DTjXG5InIROBloMVmf/tpaw5JseH0TIpuqY9U/iRvB2Rvgk9vhZIcmPgUjLhRB4upVsebTUMjgM3GmK0AIjIDOBeoTQTGmEUe5y8GUrwYzwFW7ypgSJd4nWdI1bV7Jcz/X9gw127HdoLffwkpw5yNSykv8WYiSAbSPLbTOfTd/nXAF16Mp46qahc7c0sYP1BXjFIeFjxlJ46LiIPTHoBOx0K3E+22Uq2UNxNBQ7fZpsETRU7HJoKTD3L8RuBGgK5duzZLcGl5pVRWG3okarOQAoqzYMGTsORVGHg+nP1PiIx3OiqlWoQ3E0E60MVjOwXIqH+SiBwLTAcmGmNyGrqQMeZlbP8Bw4YNazCZNNXynXkA9O0Y2xyXU/6qJBfWz4HP74bqcugzAX73PITHOB2ZUi3Gm4lgCdBbRLoDu4DLgMs9TxCRrsBHwFXGmI1ejOUAc1ftJjk+kkGdtcofkFwuWPsJfH6XfSooMgEu/RhST3I6MqVanNcSgTGmSkRuA74CgoHXjDFrRORm9/FpwF+AdsC/3R22VcaYFumR27C3iKHd2hIUpB3FASVrA3z9MGRvgNyttu3/wlehz5kQrrVDFZi8OqDMGDMXmFtv3zSP19cD13szhoZUuwx7CspIPjaypT9atTSXC/augjWfwLLX7d1/SCR0PQFOfxAGXqCjg1XAC8iRxVlF5VRWG5LjNRG0SjsX20dA134CGcuhssTu73gsjLwZBl8B8V0OeQmlAklAJoJd+faLIbmtJgK/ZwzkbIYV70HhLvulv24OYCA4HAZdCF2GQ+op0K6nDgZTqgEBmQg27CkG0EdH/Y0x9imfvavsSN+KEljyCuz+DSQY4lLsF/3gK+DUeyE6EcL031ipwwnIRLAyPZ/4qFC6JugcQz6nqgKKMmDvGvsFX5oPe1ZBWT6UFdi7fk9tU2H849BvEiT0cCBgpfxfQCaCFWn5HJuiU0u0uOoqSPsZKvZBxq9QVWb3u6ptW355EWSuheqK/e8Jj4PYjnaSt6Bg6HS9/fJvPwAkCBK666IwSh2lgEsEpRXVbMosZtyADk6HEhgKdkH+Tlj3GaybDQUes44Ee6wDEd/NzvE/+ApI7APJQ+0Xfqz+OynlbQGXCNZkFFDtMhybEu90KK1b3g746EZIW7x/X8pwGPcotEmGhJ4Qk+RcfEqpWgGXCDbutR3F/Tvp4KFmUVEC714Ee1bv3ydAWSGEhMNJd9ondqISoPMQfWpHKR8UcIlga1YxEaFBdI7TR0cPYAxsmgfFmbZZJvVk+8VtDBSk28FYe1ba7fIi2L3Ctu1nb7SLuIdE2sc3C9Js087QKfZJHqWUTwu8RJC9j9R20Tq1RH3GwIK/2Xn4a/QcY0ferv4Qts4/8D3RSTZhXPa+fWpHKeWXAi8RZBUzMNAnmnO5oLwAdi1zP8Gz3Lbpr/kI+k6CCU/Ckumw9DXY8p0dmHXSVEjqa5t3wmJsTSG2s07PoFQrEFCJoKLKRVpeKecc19npUBpvyXQ7alaCYPDlMOz3h3+PMfanoS/p7M3wzvn2SZ4aEmynXR50IVww3b5v/GMw5iGbIKITbRu/UqpVCqhEsDN3H9UuQw9/WKO4uhK+fRQWPWfnyKkqgzl3QdcToX2/g7+vcDe8fZ5t0z/hD3Da/fsTQnkRfHitHZg19mFI6gdxyRDXpeEv+pBwSOrjleIppXxHQCWCbdl2jqHuic206Eh1FZTmQkz7ho/vWGTb0RN7N+26GSvgi3vt4KshV8HZ/2efwnmmH/z6Jkxwt+Pn74T5T4KrCjoMtLWAtZ/au/iuI2HhU7aDt2aCtV3LbGfv5R/YaZeVUooASwR7C+1I1k5xEc1zwTl3wvJ34N5tB95RF2bA6xPt6ztX2sFSDcnaCG/9ztYAjrkYCtPt4Kvo9nDei7Y5CCC6HfQcC6tm2g7c0AiYcQXsy7JNOyv/Y88LjYJz/mmv9fJpdi4eT4Mu0iSglKojoBJBVlE5IpAQHXb4kw+nsswmAYCVH8AJN9c9/vFN+19/didc9XHDz9Av+Ju92+99Bvzykt13zCXugVf1+jJOvQfe/B28eobdliC49kvbVJS33Q7SCgnfP+XCjfP3T+NQI1TnV1JK1RVQiSC7uJyEqDBCg5vhSZc9K/e//vVNGHnT/i/68iLY9gOcfBdEtYN5D0LmOugwoO41crfB6ll20NW4R+37jIGINg1/ZvJQuG0p7PwJMNCuF3Q6zh6r+dNTULDOvqmUOqyASgRZReUkxYbX3fn8cDvp2R2/Nu1i6Uvsn6c9APOfsO3vKe5VNvesBgx0GWknTAM76Kp+Itj8jT1v6BS73ZilEtt0gkEXNC1WpZQ6hIB6CDyruIFEkL0Rcrc0/WLZGyEqEU64xTa3LHvdPp8PsOFzQKDzYHvXXnN+fdsW2nl32qY2/fOVUqqZBFyNoHu7ZmoqydtuO4Aj2tjO2+XvwMavIGWETQQDL9hfG4jtDN8/bmsMPcfYPoF5D9rZOEferPPvKKUcFTCJwGxdwD9KHuCniGc8dpojv2DedttmDzDmQZsUVrxrk8CQq+zo3BrnvQCf3w1vnw/tB0JFsX3Ov+dYOPmPRx6DUko1g4BJBCUVVYyUdeSwAzjR7iwr2H9CVbl94qYxqqvsF/lAd1t9m852acRT7rHb9e/we46B6762TwVt+8E+anr2M9DrjKMqk1JKNYeASQRZkT2JBrpUbtu/syRn/+vS/MYvgpK9wQ7iat+/7v5DNfFEt4PTH4DTGxuxUkq1jIBJBHuqY4k2cfTf8AL88327s8pjScTSvMYngowV9s9Og5szRKWUckTAJIKsonI+qJzMI32zaRPpscZt+hLI2QzvXQKhjVyjIHebHR/Qrqd3glVKqRYUMInglN5JdLrxT4Qlx0Fo8P4D5UXwxX1QUdT4i3UYCCNvsQO2lFLKzwVMIoiLCmVYagMzbIbH2qd6lFIqQAXUgDKllFIH0kSglFIBThOBUkoFOE0ESikV4DQRKKVUgNNEoJRSAU4TgVJKBThNBEopFeDEHM1UzA4QkSxgxxG+PRHIbsZwnKRl8U1aFt/TWsoBR1eWbsaYpIYO+F0iOBoistQYM8zpOJqDlsU3aVl8T2spB3ivLNo0pJRSAU4TgVJKBbhASwQvOx1AM9Ky+CYti+9pLeUAL5UloPoIlFJKHSjQagRKKaXq0USglFIBLmASgYhMEJENIrJZRO5zOp7DEZHXRCRTRFZ77EsQka9FZJP7z7Yex+53l22DiJzpTNQHEpEuIvK9iKwTkTUicqd7vz+WJUJEfhGR39xledS93+/KUkNEgkVkuYjMcW/7ZVlEZLuIrBKRFSKy1L3P78oiIvEi8qGIrHf/nxnVIuUwxrT6HyAY2AL0AMKA34ABTsd1mJhPAY4HVnvsewq4z/36PuBv7tcD3GUKB7q7yxrsdBncsXUCjne/jgU2uuP1x7IIEON+HQr8DJzgj2XxKNNdwHvAHH/9HXPHtx1IrLfP78oCvAlc734dBsS3RDkCpUYwAthsjNlqjKkAZgDnOhzTIRljFgK59Xafi/1Fwf3neR77Zxhjyo0x24DN2DI7zhiz2xjzq/t1EbAOSMY/y2KMMcXuzVD3j8EPywIgIinAWcB0j91+WZaD8KuyiEgb7A3gqwDGmApjTD4tUI5ASQTJQJrHdrp7n7/pYIzZDfYLFmjv3u8X5RORVGAI9k7aL8vibkpZAWQCXxtj/LYswD+BewGXxz5/LYsB5onIMhG50b3P38rSA8gCXnc3100XkWhaoByBkgikgX2t6blZny+fiMQAs4CpxpjCQ53awD6fKYsxptoYMxhIAUaIyKBDnO6zZRGRs4FMY8yyxr6lgX0+URa3k4wxxwMTgVtF5JRDnOurZQnBNge/aIwZAuzDNgUdTLOVI1ASQTrQxWM7BchwKJajsVdEOgG4/8x07/fp8olIKDYJvGuM+ci92y/LUsNdZZ8PTMA/y3IS8DsR2Y5tKh0jIu/gn2XBGJPh/jMT+BjbROJvZUkH0t21TIAPsYnB6+UIlESwBOgtIt1FJAy4DJjtcExHYjZwjfv1NcCnHvsvE5FwEekO9AZ+cSC+A4iIYNs81xljnvE45I9lSRKRePfrSOAMYD1+WBZjzP3GmBRjTCr2/8N3xpgr8cOyiEi0iMTWvAbGA6vxs7IYY/YAaSLS171rLLCWliiH073kLfUDTMI+sbIFeNDpeBoR7/vAbqASm/mvA9oB3wKb3H8meJz/oLtsG4CJTsfvEdfJ2OrqSmCF+2eSn5blWGC5uyyrgb+49/tdWeqV6zT2PzXkd2XBtq3/5v5ZU/P/20/LMhhY6v4d+wRo2xLl0CkmlFIqwAVK05BSSqmD0ESglFIBThOBUkoFOE0ESikV4DQRKKVUgNNEoFQ9IlLtnsWy5qfZZqsVkVTxmFFWKV8Q4nQASvmgUmOnkVAqIGiNQKlGcs95/zf3mgS/iEgv9/5uIvKtiKx0/9nVvb+DiHzsXr/gNxE50X2pYBF5xb2mwTz3KGWlHKOJQKkDRdZrGrrU41ihMWYE8Dx29k7cr98yxhwLvAs8697/LLDAGHMcds6YNe79vYEXjDEDgXzgQq+WRqnD0JHFStUjIsXGmJgG9m8Hxhhjtron0ttjjGknItlAJ2NMpXv/bmNMoohkASnGmHKPa6Rip6/u7d7+ExBqjPlrCxRNqQZpjUCppjEHeX2wcxpS7vG6Gu2rUw7TRKBU01zq8edP7teLsDN4AlwB/Oh+/S1wC9QuaNOmpYJUqin0TkSpA0W6VyGr8aUxpuYR0nAR+Rl7EzXZve8O4DURuQe7wtS17v13Ai+LyHXYO/9bsDPKKuVTtI9AqUZy9xEMM8ZkOx2LUs1Jm4aUUirAaY1AKaUCnNYIlFIqwGkiUEqpAKeJQCmlApwmAqWUCnCaCJRSKsD9f4abT591xmwVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SHREC_coarse_1D_lite_try.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
